{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# all_tutorial\n",
    "! [ -e /content ] && pip install -Uqq mrl-pypi  # upgrade mrl on colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial - Model Assisted Combichem\n",
    "\n",
    ">Tutorial on model assisted combichem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows how to use combichem in conjunction with a generative model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Notes\n",
    "\n",
    "Parts of this notebook aare CPU-constrained. If you have a multi-core machine, it is recommended that you uncomment and run the `set_global_pool` cells in the notebook. This will trigger the use of multiprocessing, which will result in 2-4x speedups.\n",
    "\n",
    "This notebook may run slow on Collab due to CPU limitations.\n",
    "\n",
    "If running on Collab, remember to change the runtime to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmai/miniconda3/envs/mrl/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: to-Python converter for boost::shared_ptr<RDKit::FilterCatalogEntry const> already registered; second conversion method ignored.\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from mrl.imports import *\n",
    "from mrl.core import *\n",
    "from mrl.chem import *\n",
    "from mrl.templates.all import *\n",
    "\n",
    "from mrl.torch_imports import *\n",
    "from mrl.torch_core import *\n",
    "from mrl.layers import *\n",
    "from mrl.dataloaders import *\n",
    "from mrl.train.reward import Reward\n",
    "from mrl.train.agent import PredictiveAgent\n",
    "from mrl.model_zoo import *\n",
    "from mrl.combichem import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Assisted Combichem\n",
    "\n",
    "Model-assisted combichem involves using a generative model in conjunction with a combichem process to optimize some score function.\n",
    "\n",
    "Standard combichem consists of the following steps:\n",
    "1. Library generation - create the next iteration of the library\n",
    "2. Library scoring - apply a numeric score to each item in the library\n",
    "3. Library pruning - remove low scoring compounds\n",
    "\n",
    "For more details on library generation, see the <a href=\"/mrl/tutorials.combichem.html\">Combichem Tutorial</a>.\n",
    "\n",
    "Model-assisted combichem incorporates a generative model into the combichem workflow:\n",
    "1. Combichem Library generation - generate compounds with a combichem process\n",
    "2. Model sampling - generate compounds from a generative model\n",
    "3. Library scoring - apply a numeric score to each item in the library\n",
    "4. Library pruning - remove low scoring compounds\n",
    "5. Model training - train the generative model on high scoring compounds\n",
    "\n",
    "We use the generative model to add compounds to the library. After scoring and pruning, we train the generative model on high scoring compounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template\n",
    "\n",
    "We will use the following template to constrain chemical space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smarts = ['[#6](=[#16])(-[#7])-[#7]',\n",
    "        '[#6]=[#6]=[#6]',\n",
    "        '[#7][F,Cl,Br,I]',\n",
    "        '[*]#[Cl,Br]',\n",
    "        '[#6;!R]=[#6;!R]-[#6;!R]=[#6;!R]',\n",
    "        '[#6]#[#6]',\n",
    "        '[#15]',\n",
    "        '[#16]',\n",
    "        '[*]=[#17,#9,#35]',\n",
    "        '[*]=[*]=[*]',\n",
    "        '[*]-[#6]=[#6H2]',\n",
    "        '[#7]~[#8]',\n",
    "        '[#7]~[#7]',\n",
    "        '[*;R]=[*;!R]']\n",
    "\n",
    "template = Template([ValidityFilter(), \n",
    "                     SingleCompoundFilter(), \n",
    "                     RotBondFilter(None, 8),\n",
    "                     HeteroatomFilter(None, 8),\n",
    "                     ChargeFilter(None, 0),\n",
    "                     MaxRingFilter(None, 6),\n",
    "                     MinRingFilter(5, None),\n",
    "                     HBDFilter(None, 5),\n",
    "                     HBAFilter(None, 10),\n",
    "                     MolWtFilter(None, 500),\n",
    "                     LogPFilter(None, 5),\n",
    "                     SAFilter(None, 7),\n",
    "                     BridgeheadFilter(None,0),\n",
    "                     PAINSAFilter(),\n",
    "                     ExclusionFilter(smarts, criteria='any'),\n",
    "                     RotChainFilter(None, 7),\n",
    "                     ChargeFilter(0,0),\n",
    "                     RingFilter(None, 4)\n",
    "                    ],\n",
    "                    [], \n",
    "                    fail_score=-1., log=False, use_lookup=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward\n",
    "\n",
    "For the reward, we will load a scikit-learn linear regression model trained to predict affinity against erbB1 using molecular fingerprints.\n",
    "\n",
    "This score function is extremely simple and won't translate well to affinity. It is used as a lightweight example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FP_Regression_Score():\n",
    "    def __init__(self, fname):\n",
    "        self.model = torch.load(fname)\n",
    "        self.fp_function = partial(failsafe_fp, fp_function=ECFP6)\n",
    "        \n",
    "    def __call__(self, samples):\n",
    "        mols = to_mols(samples)\n",
    "        fps = maybe_parallel(self.fp_function, mols)\n",
    "        fps = [fp_to_array(i) for i in fps]\n",
    "        x_vals = np.stack(fps)\n",
    "        preds = self.model.predict(x_vals)\n",
    "        return preds\n",
    "\n",
    "# if in the repo\n",
    "reward_function = FP_Regression_Score('../files/erbB1_regression.sklearn')\n",
    "df = pd.read_csv('../files/smiles.csv')\n",
    "\n",
    "# if in Collab\n",
    "# download_files()\n",
    "# reward_function = FP_Regression_Score('files/erbB1_regression.sklearn')\n",
    "# df = pd.read_csv('files/smiles.csv')\n",
    "\n",
    "reward = Reward(reward_function, weight=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combichem\n",
    "\n",
    "Here we set up our combichem module with a list of mutators and crossovers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutators = [\n",
    "    ChangeAtom(['6', '7', '8', '9', '17', '35']),\n",
    "    AppendAtomSingle(['C', 'N', 'O', 'F', 'Cl', 'Br']),\n",
    "    AppendAtomsDouble(['C', 'N', 'O']),\n",
    "    AppendAtomsTriple(),\n",
    "    DeleteAtom(),\n",
    "    ChangeBond(),\n",
    "    InsertAtomSingle(['C', 'N', 'O']),\n",
    "    InsertAtomDouble(['C', 'N']),\n",
    "    InsertAtomTriple(),\n",
    "    AddRing(),\n",
    "    ShuffleNitrogen(20)\n",
    "]\n",
    "\n",
    "mc = MutatorCollection(mutators)\n",
    "\n",
    "crossovers = [FragmentCrossover()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbc = CombiChem(mc, crossovers, template=template, rewards=[reward],\n",
    "                prune_percentile=70, max_library_size=400, log=True, p_explore=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbc.add_data(df.smiles.values[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Model\n",
    "\n",
    "We load a pre-trained generative model. This is a LSTM-based language model trained on the ZINC database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = LSTM_LM_Small_ZINC_NC(drop_scale=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(cbc, agent, n_gen, sl):\n",
    "    new_library = cbc.build_generation()\n",
    "    new_library = cbc.clean_library(new_library)\n",
    "    cbc.append_data(new_library)\n",
    "    preds, _ = agent.model.sample_no_grad(n_gen, sl)\n",
    "    smiles = agent.reconstruct(preds)\n",
    "    cbc.append_data(smiles)\n",
    "    cbc.score_library()\n",
    "    cbc.prune_library()\n",
    "    \n",
    "def train_from_cbc(cbc, agent, ds_size, epochs, bs, lr):\n",
    "    df = pd.concat([cbc.library, cbc.old_library])\n",
    "    subset = df.iloc[df.score.nlargest(ds_size).index]\n",
    "    agent.update_dataset_from_inputs(subset.smiles.values)\n",
    "    agent.train_supervised(bs, epochs, lr, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Assisted Combichem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_global_pool(min(48, os.cpu_count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.300824455022813\n",
      "13.433134039044381\n",
      "15.450325035452842\n",
      "16.517450484484435\n",
      "17.25814539551735\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        step(cbc, agent, 1024, 90)\n",
    "        \n",
    "    train_from_cbc(cbc, agent, 6000, 3, 128, 1e-4)\n",
    "    print(cbc.library.score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
