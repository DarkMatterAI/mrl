{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c92780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a774717",
   "metadata": {},
   "source": [
    "# Environment\n",
    "\n",
    "> Environment/Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0482fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8d9b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/mrl/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: to-Python converter for boost::shared_ptr<RDKit::FilterCatalogEntry const> already registered; second conversion method ignored.\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "\n",
    "from mrl.imports import *\n",
    "from mrl.torch_imports import *\n",
    "from mrl.torch_core import *\n",
    "from mrl.chem import *\n",
    "from mrl.templates import *\n",
    "from mrl.agent import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedb8fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Callback():\n",
    "    def __init__(self, name='callback', order=1000):\n",
    "        self.order=order\n",
    "        self.name = name\n",
    "    \n",
    "    def __call__(self, event_name):\n",
    "        \n",
    "        event = getattr(self, event_name, None)\n",
    "        if event is not None:\n",
    "            output = event()\n",
    "        else:\n",
    "            output = None\n",
    "            \n",
    "        return output\n",
    "    \n",
    "class BatchStats(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__(name='stats', order=0)\n",
    "        \n",
    "        self.iterations = 0\n",
    "        self.diversity = []\n",
    "        self.valid = []\n",
    "        self.rewards = []\n",
    "        \n",
    "    def before_train(self):\n",
    "        print('\\t'.join([key for key in list(self.__dict__.keys())]))\n",
    "        \n",
    "    def after_batch(self):\n",
    "        outputs = []\n",
    "        exclude = ['order', 'name']\n",
    "        for k,v in self.__dict__.items():\n",
    "            if not k in exclude:\n",
    "                if type(v) == list:\n",
    "                    val = v[-1]\n",
    "                else:\n",
    "                    val = v\n",
    "                outputs.append(f'{val:.2f}')\n",
    "        print('\\t'.join(outputs))\n",
    "        self.iterations += 1\n",
    "    \n",
    "class Buffer(Callback):\n",
    "    def __init__(self, p_total, max_size=1000000):\n",
    "        super().__init__(name='buffer', order=0)\n",
    "        \n",
    "        self.buffer = []\n",
    "        self.used_buffer = []\n",
    "        self.max_size = max_size\n",
    "        self.p_total = p_total\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "    def add(self, item):\n",
    "        \n",
    "        if is_container(item):\n",
    "            for i in item:\n",
    "                self.add(i)\n",
    "        else:\n",
    "            place_idx = (len(self.buffer)%self.max_size)+1\n",
    "\n",
    "            if place_idx>=len(self.buffer):\n",
    "                self.buffer.append(item)\n",
    "            else:\n",
    "                self.buffer[place_idx-1] = item\n",
    "            \n",
    "    def sample(self, n):\n",
    "        \n",
    "        idxs = np.random.choice(np.arange(len(self.buffer)), n, replace=False)\n",
    "        batch = [self.buffer[i] for i in idxs]\n",
    "        for idx in sorted(idxs, reverse=True):\n",
    "            self.buffer.pop(idx)\n",
    "            \n",
    "        self.used_buffer += batch\n",
    "        self.used_buffer = self.used_buffer[-self.max_size:]\n",
    "        \n",
    "        return batch\n",
    "    \n",
    "    def after_build_buffer(self):\n",
    "        self.buffer = self.environment.template_cb.filter_sequences(self.buffer)\n",
    "    \n",
    "    def sample_batch(self):\n",
    "        bs = int(self.environment.bs * self.p_total)\n",
    "        sample = self.sample(bs)\n",
    "        self.batch_state.samples += sample\n",
    "        self.batch_state.sources += ['buffer']*len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac69353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class SettrDict(dict):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def __setitem__(self, key, item):\n",
    "        super().__setitem__(key, item)\n",
    "        super().__setattr__(key, item)\n",
    "    \n",
    "    def __setattr__(self, key, item):\n",
    "        super().__setitem__(key, item)\n",
    "        super().__setattr__(key, item)\n",
    "        \n",
    "    def update_from_dict(self, update_dict):\n",
    "        for k,v in update_dict.items():\n",
    "            self[k] = v\n",
    "        \n",
    "class BatchState(SettrDict):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.samples = []\n",
    "        self.sources = []\n",
    "        self.rewards = to_device(torch.tensor(0.))\n",
    "        self.rewards_scaled = to_device(torch.tensor(0.))\n",
    "        self.trajectory_rewards = to_device(torch.tensor(0.))\n",
    "        self.loss = to_device(torch.tensor(0.))\n",
    "        self.latent_data = []\n",
    "        \n",
    "#         self.sequence_trajectories = []\n",
    "#         self.x = None\n",
    "#         self.y = None\n",
    "#         self.mask = None\n",
    "#         self.sl = None\n",
    "#         self.model_output = None\n",
    "#         self.model_encoded = None\n",
    "#         self.model_logprobs = None\n",
    "#         self.model_gathered_logprobs = None\n",
    "#         self.y_gumbel = None\n",
    "#         self.vhead_values = None\n",
    "#         self.old_vhead_values = None\n",
    "#         self.ref_output = None\n",
    "#         self.ref_encoded = None\n",
    "#         self.ref_logprobs = None\n",
    "#         self.ref_gathered_logprobs = None\n",
    "#         self.trajectory_rewards = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f7b21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Event():\n",
    "    def __init__(self):\n",
    "        self.setup = 'setup'\n",
    "        self.before_train = 'before_train'\n",
    "        self.build_buffer = 'build_buffer'\n",
    "        self.after_build_buffer = 'after_build_buffer'\n",
    "        self.before_batch = 'before_batch'\n",
    "        self.sample_batch = 'sample_batch'\n",
    "        self.after_sample = 'after_sample'\n",
    "        self.get_model_outputs = 'get_model_outputs'\n",
    "        self.compute_reward = 'compute_reward'\n",
    "        self.after_compute_reward = 'after_compute_reward'\n",
    "        self.compute_loss = 'compute_loss'\n",
    "        self.zero_grad = 'zero_grad'\n",
    "        self.step = 'step'\n",
    "        self.after_batch = 'after_batch'\n",
    "        self.after_train = 'after_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb8f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Environment():\n",
    "    def __init__(self, agent_cb, template=None, samplers=[], reward_cbs=[], loss_cbs=[], cbs=[],\n",
    "                buffer_p_batch=None):\n",
    "        self.agent_cb = agent_cb\n",
    "        self.template_cb = TemplateCallback(template)\n",
    "        self.samplers = samplers\n",
    "        self.reward_cbs = reward_cbs\n",
    "        self.loss_cbs = loss_cbs\n",
    "        self.cbs = []\n",
    "        if buffer_p_batch is None:\n",
    "            buffer_p_batch = 1.\n",
    "            for samp in samplers:\n",
    "                buffer_p_batch -= samp.p_batch\n",
    "        self.buffer = Buffer(buffer_p_batch)\n",
    "        self.batch_state = BatchState()\n",
    "        self.batch_stats = BatchStats()\n",
    "        self.mean_reward = None\n",
    "        \n",
    "        all_cbs = [self.agent_cb] + [self.template_cb] + self.samplers + self.reward_cbs\n",
    "        all_cbs += self.loss_cbs + cbs + [self.buffer] + [self.batch_stats]\n",
    "        \n",
    "        self.register_cbs(all_cbs)\n",
    "        self('setup')\n",
    "        \n",
    "    def __call__(self, event):\n",
    "        for cb in self.cbs:\n",
    "            if hasattr(cb, event):\n",
    "                cb(event)\n",
    "        \n",
    "    def register_cb(self, cb):\n",
    "        if isinstance(cb, type): \n",
    "            cb = cb()\n",
    "        cb.environment = self\n",
    "        setattr(self, cb.name, cb)\n",
    "        self.cbs.append(cb)\n",
    "        \n",
    "    def register_cbs(self, cbs):\n",
    "        for cb in cbs:\n",
    "            self.register_cb(cb)\n",
    "            \n",
    "    def build_buffer(self):\n",
    "        if len(self.buffer) < self.bs:\n",
    "            self('build_buffer')\n",
    "            self('after_build_buffer')\n",
    "            \n",
    "    def sample_batch(self):\n",
    "        self.batch_state = BatchState()\n",
    "        for cb in self.cbs:\n",
    "            cb.batch_state = self.batch_state\n",
    "        self('before_batch') \n",
    "        self('sample_batch') \n",
    "        sequences = self.batch_state.samples\n",
    "        self.batch_stats.diversity.append(len(set(sequences))/len(sequences))\n",
    "        self.batch_stats.valid.append(\n",
    "            len([i for i in sequences if to_mol(i) is not None])/len(sequences))\n",
    "        self('after_sample') \n",
    "        \n",
    "    def compute_rewards(self):\n",
    "        self('compute_rewards')\n",
    "        rewards = self.batch_state.rewards\n",
    "        \n",
    "        if self.mean_reward is None:\n",
    "            self.mean_reward = rewards.mean()\n",
    "        else:\n",
    "            self.mean_reward = (1-self.reward_decay)*rewards.mean() + self.reward_decay*self.mean_reward\n",
    "            \n",
    "        rewards_scaled = rewards - self.mean_reward\n",
    "        self.batch_state.rewards_scaled = rewards_scaled\n",
    "        self.batch_stats.rewards.append(rewards.mean().detach().cpu().numpy())\n",
    "        self('after_compute_rewards')\n",
    "        \n",
    "    def compute_loss(self):\n",
    "        self('compute_loss')\n",
    "        loss = self.batch_state.loss\n",
    "        self('zero_grad')\n",
    "        loss.backward()\n",
    "        self('step')\n",
    "            \n",
    "    def fit(self, bs, sl, iters, buffer_size):\n",
    "        self.bs = bs\n",
    "        self.sl = sl\n",
    "        self.buffer_size = buffer_size\n",
    "        self('before_train')\n",
    "        for step in range(iters):\n",
    "            self.build_buffer()\n",
    "            self.sample_batch()\n",
    "            self('get_model_outputs')\n",
    "            self.compute_rewards()\n",
    "            self.compute_loss()\n",
    "            self('after_batch')\n",
    "        self('after_train')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce85ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Sampler(Callback):\n",
    "    def __init__(self, name, p_buffer=0., p_batch=0.):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.p_buffer = p_buffer\n",
    "        self.p_batch = p_batch\n",
    "        \n",
    "    def setup(self):\n",
    "        if self.p_batch>0.:\n",
    "            bs = self.environment.batch_stats\n",
    "            setattr(bs, f'{self.name}_diversity', [])\n",
    "            setattr(bs, f'{self.name}_valid', [])\n",
    "            setattr(bs, f'{self.name}_rewards', [])\n",
    "#             setattr(bs, f'{self.name}_new', [])\n",
    "        \n",
    "    def build_buffer(self):\n",
    "        pass\n",
    "    \n",
    "    def sample_batch(self):\n",
    "        pass\n",
    "    \n",
    "    def after_compute_reward(self):\n",
    "        if self.p_batch>0:\n",
    "            state = self.environment.batch_state\n",
    "            stats = self.environment.batch_stats\n",
    "            rewards = state.rewards.detach().cpu().numpy()\n",
    "            sources = np.array(state.sources)\n",
    "            if self.name in sources:\n",
    "                getattr(stats, f'{self.name}_rewards').append(rewards[sources==self.name].mean())\n",
    "            else:\n",
    "                getattr(stats, f'{self.name}_rewards').append(0.)\n",
    "                  \n",
    "    \n",
    "class ModelSampler(Sampler):\n",
    "    def __init__(self, agent, model, name, p_buffer, p_batch, genbatch, latent=False):\n",
    "        super().__init__(name, p_buffer, p_batch)\n",
    "        self.agent = agent\n",
    "        self.model = model\n",
    "        self.genbatch = genbatch\n",
    "        self.latent = latent if self.agent.latents is not None else False\n",
    "        \n",
    "    def build_buffer(self):\n",
    "        env = self.environment\n",
    "        bs = int(env.buffer_size * self.p_buffer)\n",
    "        outputs = []\n",
    "        to_generate = bs\n",
    "        \n",
    "        if bs > 0:\n",
    "            for batch in range(int(np.ceil(bs/self.genbatch))):\n",
    "                current_bs = min(self.genbatch, to_generate)\n",
    "                \n",
    "                preds, _ = self.model.sample_no_grad(current_bs, env.sl, multinomial=True)\n",
    "                sequences = self.agent.reconstruct(preds)\n",
    "                sequences = list(set(sequences))\n",
    "                sequences = [i for i in sequences if to_mol(i) is not None]\n",
    "                outputs += sequences\n",
    "                outputs = list(set(outputs))\n",
    "                to_generate = bs - len(outputs)\n",
    "                \n",
    "            env.buffer.add(outputs)\n",
    "            \n",
    "            \n",
    "    def sample_batch(self):\n",
    "        env = self.environment\n",
    "        bs = int(env.bs * self.p_batch)\n",
    "        \n",
    "        if bs > 0:\n",
    "            \n",
    "            if self.latent:\n",
    "                latents = self.agent.latents\n",
    "                latent_idxs = torch.randint(0, latents.shape[0]-1, bs)\n",
    "                sample_latents = latents[latent_idxs]\n",
    "                self.batch_state.latent_data.append([self.name, latent_idxs])\n",
    "            else:\n",
    "                sample_latents=None\n",
    "            \n",
    "            \n",
    "            preds, _ = self.model.sample_no_grad(bs, env.sl, z=sample_latents, multinomial=True)\n",
    "            sequences = self.agent.reconstruct(preds)\n",
    "            diversity = len(set(sequences))/len(sequences)\n",
    "            valid = np.array([to_mol(i) is not None for i in sequences])\n",
    "            getattr(env.batch_stats, f\"{self.name}_diversity\").append(diversity)\n",
    "            getattr(env.batch_stats, f\"{self.name}_valid\").append(valid.mean())\n",
    "            self.batch_state.samples += sequences\n",
    "            self.batch_state.sources += [self.name]*len(sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5189c3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a5d24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class TemplateCallback(Callback):\n",
    "    def __init__(self, template=None):\n",
    "        super().__init__(order=-1)\n",
    "        self.template = template\n",
    "        self.name = 'template'\n",
    "        \n",
    "    def compute_rewards(self):\n",
    "        print('reward')\n",
    "        env = self.environment\n",
    "        state = env.batch_state\n",
    "        \n",
    "        if self.template is not None:\n",
    "            rewards = np.array(self.template.eval_mols(state.samples))\n",
    "            hps = np.array(self.template(state.samples))\n",
    "        else:\n",
    "            rewards = np.array([0.]*len(state.samples))\n",
    "            hps = np.array([0.]*len(state.samples))\n",
    "        \n",
    "        state.template_rewards = rewards\n",
    "        state.template_passes = hps\n",
    "        state.rewards += to_device(torch.from_numpy(rewards).float())\n",
    "        \n",
    "    def filter_sequences(self, sequences):\n",
    "        if self.template is not None:\n",
    "            hp = np.array(self.template(sequences))\n",
    "            sequences = np.array(sequences)[hp]\n",
    "            sequences = list(sequences)\n",
    "            \n",
    "        return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dc5b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04886724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class AgentCallback(Callback):\n",
    "    def __init__(self, agent, name):\n",
    "        super().__init__()\n",
    "        self.agent = agent\n",
    "        self.name = name\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        self.agent.zero_grad()\n",
    "        \n",
    "    def step(self):\n",
    "        self.agent.step()\n",
    "        \n",
    "    def after_sample(self):\n",
    "        # convert samples to tensors\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def get_model_outputs(self):\n",
    "        # get relevant model outputs\n",
    "        raise NotImplementedError\n",
    "        \n",
    "class GenAgentCallback(AgentCallback):\n",
    "    def __init__(self, agent, name, contrastive=False):\n",
    "        super().__init__(agent, name)\n",
    "        self.contrastive = contrastive\n",
    "    \n",
    "    def after_sample(self):\n",
    "        \n",
    "        batch_ds = self.agent.dataset.new(self.batch_state.samples)\n",
    "        batch = batch_ds.collate_function([batch_ds[i] for i in range(len(batch_ds))])\n",
    "        x,y = batch\n",
    "        \n",
    "        self.batch_state.x = x\n",
    "        self.batch_state.y = y\n",
    "        mask = ~(y==self.agent.vocab.stoi['pad'])\n",
    "        self.batch_state.mask = mask\n",
    "        self.batch_state.lengths = mask.sum(-1)\n",
    "        self.batch_state.sl = y.shape[-1]\n",
    "        self.batch_state.sequence_trajectories = self.agent.reconstruct_trajectory(y)\n",
    "        self.batch_state.rewards = to_device(torch.zeros(x.shape[0]))\n",
    "        self.batch_state.rewards_scaled = to_device(torch.zeros(x.shape[0]))\n",
    "        self.batch_state.trajectory_rewards = to_device(torch.zeros(y.shape))\n",
    "        \n",
    "    def get_model_outputs(self):\n",
    "            \n",
    "        x = self.batch_state.x\n",
    "        y = self.batch_state.y\n",
    "        sources = self.batch_state.sources\n",
    "        latent_info = self.batch_state.latent_data\n",
    "        \n",
    "        if latent_info:\n",
    "            latent_sources = []\n",
    "            output_tensors = []\n",
    "            for (latent_source, latent_idxs) in latent_info:\n",
    "                latent_sources.append(latent_source)\n",
    "                latent_mask = torch.tensor([i==latent_source for i in sources]).bool()\n",
    "                latents = self.agent.latents[latent_idxs]\n",
    "                out = self.agent.model.get_rl_tensors(x[latent_mask], y[latent_mask],\n",
    "                                                      latents=latents)\n",
    "                output_tensors.append(out)\n",
    "                \n",
    "            non_latent_mask = torch.tensor([not i in latent_sources for i in sources]).bool()\n",
    "            out = self.agent.model.get_rl_tensors(x[non_latent_mask], y[non_latent_mask])\n",
    "            output_tensors.append(out)\n",
    "            \n",
    "            mo = torch.cat([i[0] for i in output_tensors], 0)\n",
    "            mlp = torch.cat([i[1] for i in output_tensors], 0)\n",
    "            mglp = torch.cat([i[2] for i in output_tensors], 0)\n",
    "            me = torch.cat([i[3] for i in output_tensors], 0)\n",
    "            \n",
    "        else:\n",
    "            mo, mlp, mglp, me = self.agent.model.get_rl_tensors(x,y)\n",
    "            \n",
    "        mprob = mlp.exp()\n",
    "        \n",
    "        self.batch_state.model_output = mo\n",
    "        self.batch_state.model_logprobs = mlp\n",
    "        self.batch_state.model_gathered_logprobs = mglp\n",
    "        self.batch_state.model_encoded = me\n",
    "        self.batch_state.y_gumbel = F.one_hot(y, len(self.agent.vocab.itos)) + mprob - mprob.detach()\n",
    "        \n",
    "        if self.agent.value_head is not None:\n",
    "            value_predictions = self.agent.value_head(me)\n",
    "            with torch.no_grad():\n",
    "                base_value_predictions = self.agent.base_value_head(me)\n",
    "        else:\n",
    "            value_predictions = None\n",
    "            base_value_predictions = None\n",
    "            \n",
    "        self.batch_state.state_values = value_predictions\n",
    "        self.batch_state.ref_state_values = base_value_predictions\n",
    "        \n",
    "        if self.agent.base_model is not None:\n",
    "            with torch.no_grad():\n",
    "                bo, blp, bglp, be = self.agent.base_model.get_rl_tensors(x,y)\n",
    "        else:\n",
    "            bo, blp, bglp, be = None, None, None, None\n",
    "            \n",
    "        self.batch_state.reference_output = bo\n",
    "        self.batch_state.reference_logprobs = blp\n",
    "        self.batch_state.reference_gathered_logprobs = bglp\n",
    "        self.batch_state.reference_encoded = be\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67679d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardCallback(Callback):\n",
    "    def __init__(self, reward_function, name, weight=1.):\n",
    "        super().__init__(order=1)\n",
    "        self.name = name\n",
    "        self.reward_function = reward_function\n",
    "        self.weight = weight\n",
    "        \n",
    "    def setup(self):\n",
    "        bs = self.environment.batch_stats\n",
    "        setattr(bs, self.name, [])\n",
    "        \n",
    "    def compute_reward(self):\n",
    "        rewards, reward_dict = self.reward_function.from_batch_state(self.batch_state)\n",
    "        getattr(self.environment.batch_stats, self.name).append(rewards.mean().detach().cpu().numpy())\n",
    "        rewards = rewards * self.weight\n",
    "        self.batch_state.rewards += rewards\n",
    "        self.batch_state[self.name] = reward_dict\n",
    "\n",
    "class LossCallback(Callback):\n",
    "    def __init__(self, loss_function, name, weight=1.):\n",
    "        super().__init__(order=1)\n",
    "        self.name = name\n",
    "        self.loss_function = loss_function\n",
    "        self.weight = weight\n",
    "        \n",
    "    def setup(self):\n",
    "        bs = self.environment.batch_stats\n",
    "        setattr(bs, self.name, [])\n",
    "        \n",
    "    def compute_reward(self):\n",
    "        loss, loss_dict = self.loss_function.from_batch_state(self.batch_state)\n",
    "        getattr(self.environment.batch_stats, self.name).append(loss.detach().cpu().numpy())\n",
    "        loss = loss * self.loss\n",
    "        self.batch_state.loss += loss\n",
    "        self.batch_state[self.name] = reward_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dcf445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755b467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrl.dataloaders import *\n",
    "from mrl.layers import *\n",
    "from mrl.g_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23582135",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrl.policy_gradient import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c3733c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = CharacterVocab(SMILES_CHAR_VOCAB)\n",
    "\n",
    "ds = TextDataset(['CCC'], vocab)\n",
    "\n",
    "d_vocab = len(vocab.itos)\n",
    "d_embedding = 256\n",
    "d_hidden = 1024\n",
    "n_layers = 3\n",
    "lstm_drop = 0.\n",
    "lin_drop = 0.\n",
    "bos_idx = vocab.stoi['bos']\n",
    "bidir = False\n",
    "tie_weights = True\n",
    "\n",
    "lm_model = LSTM_LM(d_vocab, d_embedding, d_hidden, n_layers,\n",
    "                lstm_drop, lin_drop, bos_idx, bidir, tie_weights)\n",
    "\n",
    "lm_model.load_state_dict(torch.load('untracked_files/lstm_lm_small.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d38eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = GenerativeAgent(lm_model, vocab, CrossEntropy(), ds, value_head=None, opt_kwargs={'lr':1e-4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e95edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_sa(sa):\n",
    "    return (10-sa)/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac00602",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = Template([ValidityFilter(), SingleCompoundFilter()],\n",
    "                    [QEDFilter(None, None, score=PassThroughScore()),\n",
    "                     SAFilter(None, None, \n",
    "                              score=PropertyFunctionScore(scale_sa))], fail_score=-1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328fd2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a92fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_cb = GenAgentCallback(agent, 'generative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808bf0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler1 = ModelSampler(agent, agent.model, 'live', 0.5, 0.5, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f9342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler2 = ModelSampler(agent, agent.base_model, 'base', 0.5, 0., 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d217c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment(agent_cb, template, samplers=[sampler1, sampler2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba09c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.bs = 32\n",
    "env.sl = 90\n",
    "env.buffer_size=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd3d50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order\tname\titerations\tdiversity\tvalid\trewards\tenvironment\tlive_diversity\tlive_valid\tlive_rewards\n"
     ]
    }
   ],
   "source": [
    "env('before_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1001a255",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.build_buffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec257496",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.sample_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6627bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg = PolicyGradient()\n",
    "# pg = TRPO(0.97, 2)\n",
    "# pg = PPO(0.97, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0d8f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env('get_model_outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4939d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward\n"
     ]
    }
   ],
   "source": [
    "env.compute_rewards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45afe27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5091)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.stats.rewards[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7a3657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a92835",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-c6c4374f2868>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_batch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-f929dc1bf64c>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_cb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-b4b02631e163>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, event_name)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-87-b4b02631e163>\u001b[0m in \u001b[0;36mafter_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "env('after_batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e24d847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e63019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45295904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9173d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc72a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def fit(self, bs, sl, iters, buffer_size):\n",
    "        self.bs = bs\n",
    "        self.sl = sl\n",
    "        self.buffer_size = buffer_size\n",
    "        self('before_train')\n",
    "        for step in range(iters):\n",
    "            self.build_buffer()\n",
    "            self.sample_batch()\n",
    "            self.agg_batch()\n",
    "            self('get_model_outputs')\n",
    "            self.compute_rewards()\n",
    "            self('after_batch')\n",
    "        self('after_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54219ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
