{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c92780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a774717",
   "metadata": {},
   "source": [
    "# Environment\n",
    "\n",
    "> Environment/Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0482fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8d9b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/mrl/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: to-Python converter for boost::shared_ptr<RDKit::FilterCatalogEntry const> already registered; second conversion method ignored.\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "\n",
    "from mrl.imports import *\n",
    "from mrl.torch_imports import *\n",
    "from mrl.torch_core import *\n",
    "from mrl.chem import *\n",
    "from mrl.templates import *\n",
    "from mrl.agent import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75ab816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Callback():\n",
    "    def __init__(self, name='callback', order=1000):\n",
    "        self.order=order\n",
    "        self.name = name\n",
    "    \n",
    "    def __call__(self, event_name):\n",
    "        \n",
    "        event = getattr(self, event_name, None)\n",
    "        if event is not None:\n",
    "            output = event()\n",
    "        else:\n",
    "            output = None\n",
    "            \n",
    "        return output\n",
    "    \n",
    "class BatchStats(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__(name='stats', order=0)\n",
    "        \n",
    "        self.pbar = None\n",
    "        self.iterations = 0\n",
    "        self.diversity = []\n",
    "        self.valid = []\n",
    "        self.rewards = []\n",
    "        self.mean_reward = []\n",
    "        self.metric_vals = ['iterations', 'diversity',\n",
    "                            'valid', 'rewards', 'mean_reward']\n",
    "        self.report = 1\n",
    "        \n",
    "    def before_train(self):\n",
    "        if self.pbar is None:\n",
    "            print('\\t'.join([key for key in self.metric_vals]))\n",
    "        else:\n",
    "            self.pbar.write(self.metric_vals, table=True)\n",
    "        \n",
    "    def add_metric(self, name):\n",
    "        setattr(self, name, [])\n",
    "        self.metric_vals.append(name)\n",
    "        \n",
    "    def after_batch(self):\n",
    "        outputs = []\n",
    "        if self.iterations%self.report==0:\n",
    "            for metric in self.metric_vals:\n",
    "                v = getattr(self, metric)\n",
    "                if type(v)==list:\n",
    "                    val = v[-1]\n",
    "                else:\n",
    "                    val = v\n",
    "\n",
    "                if type(val)==int:\n",
    "                    val = f'{val}'\n",
    "                else:\n",
    "                    val = f'{val:.2f}'\n",
    "\n",
    "                outputs.append(val)\n",
    "\n",
    "            if self.pbar is None:\n",
    "                print('\\t'.join(outputs))\n",
    "            else:\n",
    "                self.pbar.write(outputs, table=True)\n",
    "            \n",
    "        self.iterations += 1\n",
    "    \n",
    "class Buffer(Callback):\n",
    "    def __init__(self, p_total, max_size=1000000):\n",
    "        super().__init__(name='buffer', order=0)\n",
    "        \n",
    "        self.buffer = []\n",
    "        self.used_buffer = []\n",
    "        self.max_size = max_size\n",
    "        self.p_total = p_total\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "    def add(self, item):\n",
    "        \n",
    "        if is_container(item):\n",
    "            for i in item:\n",
    "                self.add(i)\n",
    "        else:\n",
    "            place_idx = (len(self.buffer)%self.max_size)+1\n",
    "\n",
    "            if place_idx>=len(self.buffer):\n",
    "                self.buffer.append(item)\n",
    "            else:\n",
    "                self.buffer[place_idx-1] = item\n",
    "            \n",
    "    def sample(self, n):\n",
    "        \n",
    "        idxs = np.random.choice(np.arange(len(self.buffer)), n, replace=False)\n",
    "        batch = [self.buffer[i] for i in idxs]\n",
    "        for idx in sorted(idxs, reverse=True):\n",
    "            self.buffer.pop(idx)\n",
    "            \n",
    "        self.used_buffer += batch\n",
    "        self.used_buffer = self.used_buffer[-self.max_size:]\n",
    "        \n",
    "        return batch\n",
    "    \n",
    "    def after_build_buffer(self):\n",
    "        if self.buffer:\n",
    "            self.buffer = self.environment.template_cb.filter_sequences(self.buffer)\n",
    "    \n",
    "    def sample_batch(self):\n",
    "        bs = int(self.environment.bs * self.p_total)\n",
    "        if bs>0:\n",
    "            sample = self.sample(bs)\n",
    "            self.batch_state.samples += sample\n",
    "            self.batch_state.sources += ['buffer']*len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80c2454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class SettrDict(dict):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def __setitem__(self, key, item):\n",
    "        super().__setitem__(key, item)\n",
    "        super().__setattr__(key, item)\n",
    "    \n",
    "    def __setattr__(self, key, item):\n",
    "        super().__setitem__(key, item)\n",
    "        super().__setattr__(key, item)\n",
    "        \n",
    "    def update_from_dict(self, update_dict):\n",
    "        for k,v in update_dict.items():\n",
    "            self[k] = v\n",
    "        \n",
    "class BatchState(SettrDict):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.samples = []\n",
    "        self.sources = []\n",
    "        self.rewards = to_device(torch.tensor(0.))\n",
    "        self.rewards_scaled = to_device(torch.tensor(0.))\n",
    "        self.trajectory_rewards = to_device(torch.tensor(0.))\n",
    "        self.loss = to_device(torch.tensor(0.))\n",
    "        self.latent_data = []\n",
    "        \n",
    "#         self.sequence_trajectories = []\n",
    "#         self.x = None\n",
    "#         self.y = None\n",
    "#         self.mask = None\n",
    "#         self.sl = None\n",
    "#         self.model_output = None\n",
    "#         self.model_encoded = None\n",
    "#         self.model_logprobs = None\n",
    "#         self.model_gathered_logprobs = None\n",
    "#         self.y_gumbel = None\n",
    "#         self.vhead_values = None\n",
    "#         self.old_vhead_values = None\n",
    "#         self.ref_output = None\n",
    "#         self.ref_encoded = None\n",
    "#         self.ref_logprobs = None\n",
    "#         self.ref_gathered_logprobs = None\n",
    "#         self.trajectory_rewards = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16d0fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Event():\n",
    "    def __init__(self):\n",
    "        self.setup = 'setup'\n",
    "        self.before_train = 'before_train'\n",
    "        self.build_buffer = 'build_buffer'\n",
    "        self.after_build_buffer = 'after_build_buffer'\n",
    "        self.before_batch = 'before_batch'\n",
    "        self.sample_batch = 'sample_batch'\n",
    "        self.after_sample = 'after_sample'\n",
    "        self.get_model_outputs = 'get_model_outputs'\n",
    "        self.compute_reward = 'compute_reward'\n",
    "        self.after_compute_reward = 'after_compute_reward'\n",
    "        self.compute_loss = 'compute_loss'\n",
    "        self.zero_grad = 'zero_grad'\n",
    "        self.before_step = 'before_step'\n",
    "        self.step = 'step'\n",
    "        self.after_batch = 'after_batch'\n",
    "        self.after_train = 'after_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2772909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Environment():\n",
    "    def __init__(self, agent_cb, template=None, samplers=[], reward_cbs=[], loss_cbs=[], cbs=[],\n",
    "                buffer_p_batch=None, reward_decay=0.9):\n",
    "        self.agent_cb = agent_cb\n",
    "        self.template_cb = TemplateCallback(template)\n",
    "        self.samplers = samplers\n",
    "        self.reward_cbs = reward_cbs\n",
    "        self.loss_cbs = loss_cbs\n",
    "        self.cbs = []\n",
    "        if buffer_p_batch is None:\n",
    "            buffer_p_batch = 1.\n",
    "            for samp in samplers:\n",
    "                buffer_p_batch -= samp.p_batch\n",
    "        self.buffer = Buffer(buffer_p_batch)\n",
    "        self.batch_state = BatchState()\n",
    "        self.batch_stats = BatchStats()\n",
    "        self.mean_reward = None\n",
    "        self.reward_decay = reward_decay\n",
    "        \n",
    "        all_cbs = [self.agent_cb] + [self.template_cb] + self.samplers + self.reward_cbs\n",
    "        all_cbs += self.loss_cbs + cbs + [self.buffer] + [self.batch_stats]\n",
    "        \n",
    "        self.register_cbs(all_cbs)\n",
    "        self('setup')\n",
    "        \n",
    "    def __call__(self, event):\n",
    "        for cb in self.cbs:\n",
    "            if hasattr(cb, event):\n",
    "                cb(event)\n",
    "        \n",
    "    def register_cb(self, cb):\n",
    "        if isinstance(cb, type): \n",
    "            cb = cb()\n",
    "        cb.environment = self\n",
    "        setattr(self, cb.name, cb)\n",
    "        self.cbs.append(cb)\n",
    "        \n",
    "    def register_cbs(self, cbs):\n",
    "        for cb in cbs:\n",
    "            self.register_cb(cb)\n",
    "            \n",
    "    def build_buffer(self):\n",
    "        if (len(self.buffer) < self.bs) and (self.buffer_size>0):\n",
    "            self('build_buffer')\n",
    "            self('after_build_buffer')\n",
    "            \n",
    "    def sample_batch(self):\n",
    "        self.batch_state = BatchState()\n",
    "        for cb in self.cbs:\n",
    "            cb.batch_state = self.batch_state\n",
    "        self('before_batch') \n",
    "        self('sample_batch') \n",
    "        sequences = self.batch_state.samples\n",
    "        self.batch_stats.diversity.append(len(set(sequences))/len(sequences))\n",
    "        self.batch_stats.valid.append(\n",
    "            len([i for i in sequences if to_mol(i) is not None])/len(sequences))\n",
    "        self('after_sample') \n",
    "        \n",
    "    def compute_reward(self):\n",
    "        self('compute_reward')\n",
    "        rewards = self.batch_state.rewards\n",
    "        \n",
    "        if self.mean_reward is None:\n",
    "            self.mean_reward = rewards.mean()\n",
    "        else:\n",
    "            self.mean_reward = (1-self.reward_decay)*rewards.mean() + self.reward_decay*self.mean_reward\n",
    "            \n",
    "        rewards_scaled = rewards - self.mean_reward\n",
    "        self.batch_state.rewards_scaled = rewards_scaled\n",
    "        self.batch_stats.rewards.append(rewards.mean().detach().cpu().numpy())\n",
    "        self.batch_stats.mean_reward.append(self.mean_reward.detach().cpu().numpy())\n",
    "        self('after_compute_reward')\n",
    "        \n",
    "    def compute_loss(self):\n",
    "        self('compute_loss')\n",
    "        loss = self.batch_state.loss\n",
    "        self('zero_grad')\n",
    "        loss.backward()\n",
    "        self('before_step')\n",
    "        self('step')\n",
    "            \n",
    "    def fit(self, bs, sl, iters, buffer_size, report):\n",
    "        self.bs = bs\n",
    "        self.sl = sl\n",
    "        self.buffer_size = buffer_size\n",
    "        self.report = report\n",
    "        mb = master_bar(range(1))\n",
    "        self.batch_stats.pbar = mb\n",
    "        self.batch_stats.report = report\n",
    "        self('before_train')\n",
    "        for _ in mb:\n",
    "            for step in progress_bar(range(iters), parent=mb):\n",
    "                self.build_buffer()\n",
    "                self.sample_batch()\n",
    "                self('get_model_outputs')\n",
    "                self.compute_reward()\n",
    "                self.compute_loss()\n",
    "                self('after_batch')\n",
    "            self('after_train')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4775cd77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcec1086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Sampler(Callback):\n",
    "    def __init__(self, name, p_buffer=0., p_batch=0.):\n",
    "        super().__init__()\n",
    "        self.name = name\n",
    "        self.p_buffer = p_buffer\n",
    "        self.p_batch = p_batch\n",
    "        \n",
    "    def setup(self):\n",
    "        if self.p_batch>0.:\n",
    "            bs = self.environment.batch_stats\n",
    "            bs.add_metric(f'{self.name}_diversity')\n",
    "            bs.add_metric(f'{self.name}_valid')\n",
    "            bs.add_metric(f'{self.name}_rewards')\n",
    "#             setattr(bs, f'{self.name}_diversity', [])\n",
    "#             setattr(bs, f'{self.name}_valid', [])\n",
    "#             setattr(bs, f'{self.name}_rewards', [])\n",
    "#             setattr(bs, f'{self.name}_new', [])\n",
    "        \n",
    "    def build_buffer(self):\n",
    "        pass\n",
    "    \n",
    "    def sample_batch(self):\n",
    "        pass\n",
    "    \n",
    "    def after_compute_reward(self):\n",
    "        if self.p_batch>0:\n",
    "            state = self.environment.batch_state\n",
    "            stats = self.environment.batch_stats\n",
    "            rewards = state.rewards.detach().cpu().numpy()\n",
    "            sources = np.array(state.sources)\n",
    "            if self.name in sources:\n",
    "                getattr(stats, f'{self.name}_rewards').append(rewards[sources==self.name].mean())\n",
    "            else:\n",
    "                getattr(stats, f'{self.name}_rewards').append(0.)\n",
    "                  \n",
    "    \n",
    "class ModelSampler(Sampler):\n",
    "    def __init__(self, agent, model, name, p_buffer, p_batch, genbatch, latent=False):\n",
    "        super().__init__(name, p_buffer, p_batch)\n",
    "        self.agent = agent\n",
    "        self.model = model\n",
    "        self.genbatch = genbatch\n",
    "        self.latent = latent if self.agent.latents is not None else False\n",
    "        \n",
    "    def build_buffer(self):\n",
    "        env = self.environment\n",
    "        bs = int(env.buffer_size * self.p_buffer)\n",
    "        outputs = []\n",
    "        to_generate = bs\n",
    "        \n",
    "        if bs > 0:\n",
    "            for batch in range(int(np.ceil(bs/self.genbatch))):\n",
    "                current_bs = min(self.genbatch, to_generate)\n",
    "                \n",
    "                preds, _ = self.model.sample_no_grad(current_bs, env.sl, multinomial=True)\n",
    "                sequences = self.agent.reconstruct(preds)\n",
    "                sequences = list(set(sequences))\n",
    "                sequences = [i for i in sequences if to_mol(i) is not None]\n",
    "                outputs += sequences\n",
    "                outputs = list(set(outputs))\n",
    "                to_generate = bs - len(outputs)\n",
    "                \n",
    "            env.buffer.add(outputs)\n",
    "            \n",
    "            \n",
    "    def sample_batch(self):\n",
    "        env = self.environment\n",
    "        bs = int(env.bs * self.p_batch)\n",
    "        \n",
    "        if bs > 0:\n",
    "            \n",
    "            if self.latent:\n",
    "                latents = self.agent.latents\n",
    "                latent_idxs = torch.randint(0, latents.shape[0]-1, (bs,))\n",
    "                sample_latents = latents[latent_idxs]\n",
    "            else:\n",
    "                sample_latents=None\n",
    "            \n",
    "            \n",
    "            preds, _ = self.model.sample_no_grad(bs, env.sl, z=sample_latents, multinomial=True)\n",
    "            sequences = self.agent.reconstruct(preds)\n",
    "            diversity = len(set(sequences))/len(sequences)\n",
    "            valid = np.array([to_mol(i) is not None for i in sequences])\n",
    "            getattr(env.batch_stats, f\"{self.name}_diversity\").append(diversity)\n",
    "            getattr(env.batch_stats, f\"{self.name}_valid\").append(valid.mean())\n",
    "            \n",
    "            hps = env.template_cb.get_hps(sequences)\n",
    "            sequences = list(np.array(sequences)[hps])\n",
    "            \n",
    "            if sample_latents is not None:\n",
    "                latent_idxs = latent_idxs[hps]\n",
    "                self.batch_state.latent_data.append([self.name, latent_idxs])\n",
    "            \n",
    "            self.batch_state.samples += sequences\n",
    "            self.batch_state.sources += [self.name]*len(sequences)\n",
    "            \n",
    "#             if self.latent:\n",
    "#                 latents = self.agent.latents\n",
    "#                 latent_idxs = torch.randint(0, latents.shape[0]-1, bs)\n",
    "#                 sample_latents = latents[latent_idxs]\n",
    "#                 self.batch_state.latent_data.append([self.name, latent_idxs])\n",
    "#             else:\n",
    "#                 sample_latents=None\n",
    "            \n",
    "            \n",
    "#             preds, _ = self.model.sample_no_grad(bs, env.sl, z=sample_latents, multinomial=True)\n",
    "#             sequences = self.agent.reconstruct(preds)\n",
    "#             diversity = len(set(sequences))/len(sequences)\n",
    "#             valid = np.array([to_mol(i) is not None for i in sequences])\n",
    "#             getattr(env.batch_stats, f\"{self.name}_diversity\").append(diversity)\n",
    "#             getattr(env.batch_stats, f\"{self.name}_valid\").append(valid.mean())\n",
    "#             self.batch_state.samples += sequences\n",
    "#             self.batch_state.sources += [self.name]*len(sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04760a17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50282e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class TemplateCallback(Callback):\n",
    "    def __init__(self, template=None):\n",
    "        super().__init__(order=-1)\n",
    "        self.template = template\n",
    "        self.name = 'template'\n",
    "        \n",
    "    def compute_reward(self):\n",
    "        env = self.environment\n",
    "        state = env.batch_state\n",
    "        \n",
    "        if self.template is not None:\n",
    "            rewards = np.array(self.template.eval_mols(state.samples))\n",
    "            hps = np.array(self.template(state.samples))\n",
    "        else:\n",
    "            rewards = np.array([0.]*len(state.samples))\n",
    "            hps = np.array([0.]*len(state.samples))\n",
    "        \n",
    "        state.template_rewards = rewards\n",
    "        state.template_passes = hps\n",
    "        state.rewards += to_device(torch.from_numpy(rewards).float())\n",
    "        \n",
    "    def get_hps(self, sequences):\n",
    "        if self.template is not None:\n",
    "            hps = np.array(self.template(sequences))\n",
    "        else:\n",
    "            hps = np.array([True]*len(sequences))\n",
    "            \n",
    "        return hps\n",
    "        \n",
    "    def filter_sequences(self, sequences):\n",
    "        \n",
    "        hps = self.get_hps(sequences)\n",
    "        sequences = list(np.array(sequences)[hps])\n",
    "        return sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239de293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782855d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class AgentCallback(Callback):\n",
    "    def __init__(self, agent, name):\n",
    "        super().__init__()\n",
    "        self.agent = agent\n",
    "        self.name = name\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        self.agent.zero_grad()\n",
    "    \n",
    "    def before_step(self):\n",
    "        nn.utils.clip_grad_norm_(self.agent.model.parameters(), 1.)\n",
    "        \n",
    "    def step(self):\n",
    "        self.agent.step()\n",
    "        \n",
    "    def after_sample(self):\n",
    "        # convert samples to tensors\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def get_model_outputs(self):\n",
    "        # get relevant model outputs\n",
    "        raise NotImplementedError\n",
    "        \n",
    "class GenAgentCallback(AgentCallback):\n",
    "    def __init__(self, agent, name, contrastive=False):\n",
    "        super().__init__(agent, name)\n",
    "        self.contrastive = contrastive\n",
    "    \n",
    "    def after_sample(self):\n",
    "        \n",
    "        batch_ds = self.agent.dataset.new(self.batch_state.samples)\n",
    "        batch = batch_ds.collate_function([batch_ds[i] for i in range(len(batch_ds))])\n",
    "        bs = len(batch_ds)\n",
    "        x,y = batch\n",
    "        \n",
    "        self.batch_state.x = x\n",
    "        self.batch_state.y = y\n",
    "        self.batch_state.bs = bs\n",
    "        mask = ~(y==self.agent.vocab.stoi['pad'])\n",
    "        self.batch_state.mask = mask\n",
    "        self.batch_state.lengths = mask.sum(-1)\n",
    "        self.batch_state.sl = y.shape[-1]\n",
    "        self.batch_state.sequence_trajectories = self.agent.reconstruct_trajectory(y)\n",
    "        self.batch_state.rewards = to_device(torch.zeros(bs))\n",
    "        self.batch_state.rewards_scaled = to_device(torch.zeros(bs))\n",
    "        self.batch_state.trajectory_rewards = to_device(torch.zeros(y.shape))\n",
    "        \n",
    "    def subset_tensor(self, x, mask):\n",
    "        if type(x)==list:\n",
    "            x = [i[mask] for i in x]\n",
    "        else:\n",
    "            x = x[mask]\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def get_model_outputs(self):\n",
    "            \n",
    "        x = self.batch_state.x\n",
    "        y = self.batch_state.y\n",
    "        sources = self.batch_state.sources\n",
    "        latent_info = self.batch_state.latent_data\n",
    "        \n",
    "        if latent_info:\n",
    "            latent_sources = []\n",
    "            output_tensors = []\n",
    "            for (latent_source, latent_idxs) in latent_info:\n",
    "                latent_sources.append(latent_source)\n",
    "                latent_mask = torch.tensor([i==latent_source for i in sources]).bool()\n",
    "                latents = self.agent.latents[latent_idxs]\n",
    "                out = self.agent.model.get_rl_tensors(self.subset_tensor(x, latent_mask), \n",
    "                                                      self.subset_tensor(y, latent_mask),\n",
    "                                                      latent=latents)\n",
    "                output_tensors.append(out)\n",
    "                \n",
    "            non_latent_mask = torch.tensor([not i in latent_sources for i in sources]).bool()\n",
    "            out = self.agent.model.get_rl_tensors(self.subset_tensor(x, non_latent_mask), \n",
    "                                                  self.subset_tensor(y, non_latent_mask))\n",
    "            output_tensors.append(out)\n",
    "            \n",
    "            mo = torch.cat([i[0] for i in output_tensors], 0)\n",
    "            mlp = torch.cat([i[1] for i in output_tensors], 0)\n",
    "            mglp = torch.cat([i[2] for i in output_tensors], 0)\n",
    "            me = torch.cat([i[3] for i in output_tensors], 0)\n",
    "            \n",
    "        else:\n",
    "            mo, mlp, mglp, me = self.agent.model.get_rl_tensors(x,y)\n",
    "            \n",
    "        mprob = mlp.exp()\n",
    "        \n",
    "        self.batch_state.model_output = mo\n",
    "        self.batch_state.model_logprobs = mlp\n",
    "        self.batch_state.model_gathered_logprobs = mglp\n",
    "        self.batch_state.model_encoded = me\n",
    "        self.batch_state.y_gumbel = F.one_hot(y, len(self.agent.vocab.itos)) + mprob - mprob.detach()\n",
    "        \n",
    "        if self.agent.value_head is not None:\n",
    "            value_predictions = self.agent.value_head(me)\n",
    "            with torch.no_grad():\n",
    "                base_value_predictions = self.agent.base_value_head(me)\n",
    "        else:\n",
    "            value_predictions = None\n",
    "            base_value_predictions = None\n",
    "            \n",
    "        self.batch_state.state_values = value_predictions\n",
    "        self.batch_state.ref_state_values = base_value_predictions\n",
    "        \n",
    "        if self.agent.base_model is not None:\n",
    "            with torch.no_grad():\n",
    "                bo, blp, bglp, be = self.agent.base_model.get_rl_tensors(x,y)\n",
    "        else:\n",
    "            bo, blp, bglp, be = None, None, None, None\n",
    "            \n",
    "        self.batch_state.reference_output = bo\n",
    "        self.batch_state.reference_logprobs = blp\n",
    "        self.batch_state.reference_gathered_logprobs = bglp\n",
    "        self.batch_state.reference_encoded = be\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb6763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class RewardCallback(Callback):\n",
    "    def __init__(self, reward_function, name, weight=1.):\n",
    "        super().__init__(order=1)\n",
    "        self.name = name\n",
    "        self.reward_function = reward_function\n",
    "        self.weight = weight\n",
    "        \n",
    "    def setup(self):\n",
    "        bs = self.environment.batch_stats\n",
    "        bs.add_metric(self.name)\n",
    "#         setattr(bs, self.name, [])\n",
    "        \n",
    "    def compute_reward(self):\n",
    "        rewards, reward_dict = self.reward_function.from_batch_state(self.batch_state)\n",
    "        getattr(self.environment.batch_stats, self.name).append(rewards.mean().detach().cpu().numpy())\n",
    "        rewards = rewards * self.weight\n",
    "        self.batch_state.rewards += rewards\n",
    "        self.batch_state[self.name] = reward_dict\n",
    "\n",
    "class LossCallback(Callback):\n",
    "    def __init__(self, loss_function, name, weight=1.):\n",
    "        super().__init__(order=1)\n",
    "        self.name = name\n",
    "        self.loss_function = loss_function\n",
    "        self.weight = weight\n",
    "        \n",
    "    def setup(self):\n",
    "        bs = self.environment.batch_stats\n",
    "        bs.add_metric(self.name)\n",
    "#         setattr(bs, self.name, [])\n",
    "        \n",
    "    def compute_loss(self):\n",
    "        loss, loss_dict = self.loss_function.from_batch_state(self.batch_state)\n",
    "        getattr(self.environment.batch_stats, self.name).append(loss.detach().cpu().numpy())\n",
    "        loss = loss * self.weight\n",
    "        self.batch_state.loss += loss\n",
    "        self.batch_state[self.name] = loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a39125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9e7edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrl.dataloaders import *\n",
    "from mrl.layers import *\n",
    "from mrl.g_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2147cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrl.policy_gradient import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a10497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = CharacterVocab(SMILES_CHAR_VOCAB)\n",
    "\n",
    "# ds = TextDataset(['CCC'], vocab)\n",
    "\n",
    "# d_vocab = len(vocab.itos)\n",
    "# d_embedding = 256\n",
    "# d_hidden = 1024\n",
    "# n_layers = 3\n",
    "# lstm_drop = 0.\n",
    "# lin_drop = 0.\n",
    "# bos_idx = vocab.stoi['bos']\n",
    "# bidir = False\n",
    "# tie_weights = True\n",
    "\n",
    "# lm_model = LSTM_LM(d_vocab, d_embedding, d_hidden, n_layers,\n",
    "#                 lstm_drop, lin_drop, bos_idx, bidir, tie_weights)\n",
    "\n",
    "# lm_model.load_state_dict(torch.load('untracked_files/lstm_lm_small.pt'))\n",
    "\n",
    "def vector_reconstruction_collate2(batch, pad_idx, batch_first=True):\n",
    "\n",
    "    x,y = vector_reconstruction_collate(batch, pad_idx, batch_first)\n",
    "    x = x[::-1]\n",
    "    output = (x,y)\n",
    "    return to_device(output)\n",
    "\n",
    "collate = partial(vector_reconstruction_collate2, pad_idx=vocab.stoi['pad'])\n",
    "# ds = Vec_Recon_Dataset(['CCC'], vocab, ECFP6, collate_function=collate)\n",
    "ds = Vec_Recon_Dataset(['CCC'], vocab, partial(failsafe_fp, fp_function=ECFP6), collate_function=collate)\n",
    "\n",
    "d_vocab = len(vocab.itos)\n",
    "d_embedding = 256\n",
    "encoder_d_in = 2048\n",
    "encoder_dims = [1024, 512]\n",
    "encoder_drops = [0.1, 0.1]\n",
    "d_hidden = 1024\n",
    "n_layers = 3\n",
    "d_latent = 512\n",
    "dec_drop=0.0\n",
    "condition_hidden=True\n",
    "condition_output=True\n",
    "prior=None\n",
    "bos_idx=0\n",
    "\n",
    "lm_model = MLP_VAE(d_vocab, d_embedding, encoder_d_in, encoder_dims, encoder_drops,\n",
    "                d_hidden, n_layers, d_latent, dec_drop, condition_hidden, condition_output,\n",
    "                prior, bos_idx)\n",
    "\n",
    "lm_model.load_state_dict(torch.load('untracked_files/fp_vae.pt', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cff0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents = torch.randn((512, lm_model.encoder.d_latent))\n",
    "\n",
    "agent = GenerativeAgent(lm_model, vocab, CrossEntropy(), ds, value_head=None, opt_kwargs={'lr':1e-4},\n",
    "                       latents=latents, lopt_kwargs={'lr':5e-2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a05262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent = GenerativeAgent(lm_model, vocab, CrossEntropy(), ds, value_head=None, opt_kwargs={'lr':1e-4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1462c155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_sa(sa):\n",
    "    return (10-sa)/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f56b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = Template([ValidityFilter(), SingleCompoundFilter()],\n",
    "                    [QEDFilter(None, None, score=PassThroughScore()),\n",
    "                     SAFilter(None, None, \n",
    "                              score=PropertyFunctionScore(scale_sa))], fail_score=-1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abddf5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bdc0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_cb = GenAgentCallback(agent, 'generative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c083b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler1 = ModelSampler(agent, agent.model, 'live', 0.5, 0.5, 128, latent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb44be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler2 = ModelSampler(agent, agent.base_model, 'base', 0.5, 0., 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9697e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pg = PolicyGradient()\n",
    "pg = TRPO(0.97, 2)\n",
    "# pg = PPO(0.97, 0.2)\n",
    "\n",
    "loss1 = LossCallback(pg, 'pg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7cd9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b732972",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment(agent_cb, template, samplers=[sampler1, sampler2], loss_cbs=[loss1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c57fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations  diversity  valid     rewards   mean_reward  live_diversity  live_valid  live_rewards  pg      \n",
      "0           1.00       1.00      1.46      1.46         1.00            1.00        1.49          -0.04     \n",
      "2           1.00       1.00      1.47      1.47         1.00            1.00        1.46          -0.06     \n"
     ]
    }
   ],
   "source": [
    "env.fit(32, 90, 4, 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca19e78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1935,  1.4924, -0.9727,  ...,  0.7760,  1.0539, -0.0467],\n",
       "        [-2.2043, -1.5967,  0.4668,  ...,  1.4769,  0.3255, -1.7293],\n",
       "        [-0.3555,  1.0331, -0.7472,  ..., -2.1751, -0.4008, -0.0151],\n",
       "        ...,\n",
       "        [ 0.3621, -0.2385,  0.8898,  ..., -1.2590, -1.2098, -2.1632],\n",
       "        [-0.2352,  0.1179,  1.0164,  ...,  1.3276,  0.1995, -1.2525],\n",
       "        [ 0.9578, -0.1522, -0.9425,  ...,  0.5103, -0.1675,  0.9462]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9f6758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f51614b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations  diversity  valid     rewards   mean_reward  live_diversity  live_valid  live_rewards  pg      \n",
      "4           1.00       1.00      1.51      1.47         1.00            1.00        1.53          -0.16     \n",
      "6           1.00       1.00      1.53      1.48         1.00            0.94        1.57          -0.22     \n",
      "8           1.00       1.00      1.53      1.49         1.00            1.00        1.52          -0.21     \n",
      "10          1.00       1.00      1.50      1.50         1.00            1.00        1.50          -0.10     \n"
     ]
    }
   ],
   "source": [
    "env.fit(32, 90, 7, 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957c133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d29aeba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1935,  1.4924, -0.9727,  ...,  0.7760,  1.0539, -0.0467],\n",
       "        [-2.2043, -1.5967,  0.4668,  ...,  1.4769,  0.3255, -1.7293],\n",
       "        [-0.2593,  0.9368, -0.8431,  ..., -2.2716, -0.4973, -0.1111],\n",
       "        ...,\n",
       "        [ 0.3621, -0.2385,  0.8898,  ..., -1.2590, -1.2098, -2.1632],\n",
       "        [-0.1352,  0.0240,  1.1168,  ...,  1.2277,  0.2997, -1.3509],\n",
       "        [ 0.9578, -0.1522, -0.9425,  ...,  0.5103, -0.1675,  0.9462]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0d6c62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5822ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9c4028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506f7b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c72f3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.bs = 32\n",
    "env.sl = 90\n",
    "env.buffer_size=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2bda22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations\tdiversity\tvalid\trewards\tlive_diversity\tlive_valid\tlive_rewards\tpg\n"
     ]
    }
   ],
   "source": [
    "env('before_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff19e6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.build_buffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f460c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.sample_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b55e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "env('get_model_outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53c01d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n"
     ]
    }
   ],
   "source": [
    "env.compute_reward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9633d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3644245]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.batch_stats.live_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7279ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.compute_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9826d170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00\t1.00\t0.97\t1.41\t1.00\t0.94\t1.36\t-0.10\n"
     ]
    }
   ],
   "source": [
    "env('after_batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe01acad",
   "metadata": {},
   "outputs": [],
   "source": [
    "env('after_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28826369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations  diversity  valid     rewards   live_diversity  live_valid  live_rewards  pg      \n",
      "0           1.00       1.00      1.53      1.00            1.00        1.55          0.01      \n",
      "1           1.00       1.00      1.50      1.00            1.00        1.52          0.04      \n",
      "2           1.00       1.00      1.51      1.00            1.00        1.55          0.01      \n",
      "3           1.00       1.00      1.51      1.00            1.00        1.55          0.04      \n"
     ]
    }
   ],
   "source": [
    "env.fit(32, 90, 4, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132c5378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastprogress.fastprogress.ConsoleMasterBar at 0x1377145f8>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.batch_stats.pbar.write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52af713c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5         1.00      1.00      1.49      1.00      1.00      1.47      0.04      \n"
     ]
    }
   ],
   "source": [
    "env.batch_stats('after_batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55a5a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9ad443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650871fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
