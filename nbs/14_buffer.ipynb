{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "! [ -e /content ] && pip install -Uqq mrl-pypi  # upgrade mrl on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp train.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buffer\n",
    "\n",
    "> Callbacks for buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "from mrl.imports import *\n",
    "from mrl.core import *\n",
    "from mrl.train.callback import *\n",
    "from mrl.torch_imports import *\n",
    "from mrl.torch_core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buffer\n",
    "\n",
    "The `Buffer` class holds samples generated during the `BuildBuffer` event. Samples added to the buffer can be any python object that is hashable.\n",
    "\n",
    "Sample hashing is used to determine unique samples. For this reason, samples should avoid using containers like pytorch Tensors which are hashed on the tensor object level rather than the numeric level.\n",
    "\n",
    "```\n",
    "set([torch.tensor(0.), torch.tensor(0.)])\n",
    ">> {tensor(0.), tensor(0.)}\n",
    "\n",
    "set([0., 0.])\n",
    ">> {0.0}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Buffer(Callback):\n",
    "    '''\n",
    "    Buffer - training buffer\n",
    "    \n",
    "    Inputs:\n",
    "    \n",
    "    - `p_total float`: batch percentage for `sample_batch`\n",
    "    '''\n",
    "    def __init__(self, p_total):\n",
    "        super().__init__(name='buffer', order=0)\n",
    "        \n",
    "        self.buffer = []\n",
    "        self.buffer_sources = []\n",
    "        self.p_total = p_total\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "    def add(self, item, name=''):\n",
    "        \n",
    "        if type(item)==list:\n",
    "            for i in item:\n",
    "                self.add(i, name=name)\n",
    "        else:\n",
    "            self.buffer.append(item)\n",
    "            self.buffer_sources.append(name+'_buffer')\n",
    "            \n",
    "    def sample(self, n):\n",
    "        \n",
    "        idxs = np.random.choice(np.arange(len(self.buffer)), min(n, len(self.buffer)), \n",
    "                                replace=False)\n",
    "        batch = [self.buffer[i] for i in idxs]\n",
    "        sources = [self.buffer_sources[i] for i in idxs]\n",
    "        for idx in sorted(idxs, reverse=True):\n",
    "            self.buffer.pop(idx)\n",
    "            self.buffer_sources.pop(idx)\n",
    "\n",
    "        return batch, sources\n",
    "    \n",
    "    def _filter_buffer(self, valids):\n",
    "        \n",
    "        self.buffer = [self.buffer[i] for i in range(len(self.buffer)) if valids[i]]\n",
    "        self.buffer_sources = [self.buffer_sources[i] \n",
    "                               for i in range(len(self.buffer_sources)) if valids[i]]\n",
    "        \n",
    "    def filter_buffer(self):\n",
    "        if self.buffer:\n",
    "            seen = set()\n",
    "            unique = []\n",
    "            for item in self.buffer:\n",
    "                if item in seen:\n",
    "                    unique.append(False)\n",
    "                else:\n",
    "                    seen.add(item)\n",
    "                    unique.append(True)\n",
    "                    \n",
    "            self._filter_buffer(np.array(unique))\n",
    "    \n",
    "    def sample_batch(self):\n",
    "        env = self.environment\n",
    "        batch_state = env.batch_state\n",
    "        \n",
    "        bs = int(env.bs * self.p_total)\n",
    "        if bs>0:\n",
    "            sample, sources = self.sample(bs)\n",
    "            batch_state.samples += sample\n",
    "            batch_state.sources += sources\n",
    "        elif bs==-1:\n",
    "            sample = self.buffer\n",
    "            sources = self.buffer_sources\n",
    "            batch_state.samples += sample\n",
    "            batch_state.sources += sources\n",
    "            self.buffer = []\n",
    "            self.buffer_sources = []\n",
    "            \n",
    "    def filter_batch(self):\n",
    "        env = self.environment\n",
    "        batch_state = env.batch_state\n",
    "        samples = batch_state.samples\n",
    "        \n",
    "        unique_samples = set()\n",
    "        unique = []\n",
    "        \n",
    "        for sample in samples:\n",
    "            if sample in unique_samples:\n",
    "                unique.append(False)\n",
    "            else:\n",
    "                unique_samples.add(sample)\n",
    "                unique.append(True)\n",
    "                \n",
    "        unique = np.array(unique)\n",
    "        self._filter_batch(unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class WeightedBuffer(Buffer):\n",
    "    def __init__(self, p_total, pct_argmax=0., track=True):\n",
    "        super().__init__(p_total)\n",
    "        \n",
    "        self.weights = []\n",
    "        self.pct_argmax = pct_argmax\n",
    "        self.track = track\n",
    "        self.name = 'weighted_buffer'\n",
    "        \n",
    "    def setup(self):\n",
    "        if self.track:\n",
    "            log = self.environment.log\n",
    "            log.add_metric(self.name)\n",
    "        \n",
    "    def compute_weights(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def sample(self, n):\n",
    "        print('weight_sampling')\n",
    "        weights = np.array(self.weights)\n",
    "        \n",
    "        all_idxs = np.arange(len(self.buffer))\n",
    "        idxs = []\n",
    "        \n",
    "        if self.pct_argmax>0.:\n",
    "            n_argmax = int(n*self.pct_argmax)\n",
    "            idxs_sorted = np.argsort(weights)\n",
    "            argmax_idxs = idxs_sorted[-n_argmax:]\n",
    "            idxs += list(argmax_idxs)\n",
    "            n = n - n_argmax\n",
    "            all_idxs = idxs_sorted[:-n_argmax]\n",
    "            weights = weights[all_idxs]\n",
    "            \n",
    "        weights = weights - weights.min()\n",
    "        weights = weights / weights.sum()\n",
    "            \n",
    "        sampled_idxs = np.random.choice(all_idxs, min(n, len(all_idxs)), \n",
    "                                        replace=False, p=weights)\n",
    "        idxs += list(sampled_idxs)\n",
    "        \n",
    "#         idxs = np.random.choice(np.arange(len(self.buffer)), min(n, len(self.buffer)), \n",
    "#                                 replace=False, p=weights)\n",
    "        batch = [self.buffer[i] for i in idxs]\n",
    "        sources = [self.buffer_sources[i] for i in idxs]\n",
    "        weights = [self.weights[i] for i in idxs]\n",
    "        for idx in sorted(idxs, reverse=True):\n",
    "            self.buffer.pop(idx)\n",
    "            self.buffer_sources.pop(idx)\n",
    "            self.weights.pop(idx)\n",
    "\n",
    "        return batch, sources, weights\n",
    "    \n",
    "    def after_filter_buffer(self):\n",
    "        weights = self.compute_weights()\n",
    "        weights = list(weights)\n",
    "        self.weights = weights\n",
    "        \n",
    "#     def sample_batch(self):\n",
    "#         super().sample_batch()\n",
    "        \n",
    "#         if self.environment.bs == -1:\n",
    "#             self.weights = []\n",
    "            \n",
    "    def sample_batch(self):\n",
    "        env = self.environment\n",
    "        batch_state = env.batch_state\n",
    "        \n",
    "        bs = int(env.bs * self.p_total)\n",
    "        if bs>0:\n",
    "            sample, sources, weights = self.sample(bs)\n",
    "            batch_state.samples += sample\n",
    "            batch_state.sources += sources\n",
    "            batch_state.buffer_weights = weights\n",
    "        elif bs==-1:\n",
    "            sample = self.buffer\n",
    "            sources = self.buffer_sources\n",
    "            weights = self.weights\n",
    "            batch_state.samples += sample\n",
    "            batch_state.sources += sources\n",
    "            batch_state.buffer_weights = weights\n",
    "            self.buffer = []\n",
    "            self.buffer_sources = []\n",
    "            self.weights = []\n",
    "            \n",
    "        if self.track:\n",
    "            env.log.update_metric(self.name, loss.mean().detach().cpu().numpy())\n",
    "        \n",
    "        \n",
    "class PredictiveBuffer(WeightedBuffer):\n",
    "    def __init__(self, p_total, predictive_agent, pred_bs, pct_argmax=0., track=True):\n",
    "        super().__init__(p_total=p_total, \n",
    "                         pct_argmax=pct_argmax, \n",
    "                         track=track)\n",
    "        \n",
    "        self.predictive_agent = predictive_agent\n",
    "        unfreeze(self.predictive_agent.model)\n",
    "        self.pred_bs = pred_bs\n",
    "        self.track = track\n",
    "        self.name = 'predictive_buffer'\n",
    "        \n",
    "    def setup(self):\n",
    "        if self.track:\n",
    "            log = self.environment.log\n",
    "            log.add_metric(self.name)\n",
    "            log.add_metric(self.name+'_loss')\n",
    "        \n",
    "    def compute_weights(self):\n",
    "        if len(self.buffer) < self.pred_bs:\n",
    "            scores = self.predictive_agent.predict_data(self.buffer).squeeze()\n",
    "            scores = scores.detach().cpu().numpy()\n",
    "        else:\n",
    "            scores = []\n",
    "            chunks = chunk_list(self.buffer, self.pred_bs)\n",
    "            for chunk in chunks:\n",
    "                chunk_scores = self.predictive_agent.predict_data(chunk).squeeze()\n",
    "                chunk_scores = chunk_scores.detach().cpu().numpy()\n",
    "                scores.append(chunk_scores)\n",
    "            \n",
    "            scores = np.concatenate(scores)\n",
    "        return scores\n",
    "    \n",
    "    def compute_loss(self):\n",
    "        env = self.environment\n",
    "        rewards = env.batch_state.rewards\n",
    "        samples = env.batch_state.samples\n",
    "        preds = self.predictive_agent.predict_data(samples)\n",
    "        loss = self.predictive_agent.loss_function(preds, rewards)\n",
    "        \n",
    "        if self.track:\n",
    "            env.log.update_metric(self.name+'_loss', loss.mean().detach().cpu().numpy())\n",
    "            \n",
    "        env.batch_state.loss += loss.mean()\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        self.predictive_agent.zero_grad()\n",
    "        \n",
    "    def before_step(self):\n",
    "        self.predictive_agent.before_step()\n",
    "        \n",
    "    def step(self):\n",
    "        self.predictive_agent.step()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrl",
   "language": "python",
   "name": "mrl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
