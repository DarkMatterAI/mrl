{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp callbacks.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buffer\n",
    "\n",
    "> Callbacks for buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "from mrl.imports import *\n",
    "from mrl.callbacks.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buffer\n",
    "\n",
    "The `Buffer` class holds samples generated during the `BuildBuffer` event. Samples added to the buffer can be any python object that is hashable.\n",
    "\n",
    "Sample hashing is used to determine unique samples. For this reason, samples should avoid using containers like pytorch Tensors which are hashed on the tensor object level rather than the numeric level.\n",
    "\n",
    "```\n",
    "set([torch.tensor(0.), torch.tensor(0.)])\n",
    ">> {tensor(0.), tensor(0.)}\n",
    "\n",
    "set([0., 0.])\n",
    ">> {0.0}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Buffer(Callback):\n",
    "    '''\n",
    "    Buffer - training buffer\n",
    "    \n",
    "    Inputs:\n",
    "    \n",
    "    - `p_total float`: batch percentage for `sample_batch`\n",
    "    '''\n",
    "    def __init__(self, p_total):\n",
    "        super().__init__(name='buffer', order=0)\n",
    "        \n",
    "        self.buffer = []\n",
    "        self.buffer_sources = []\n",
    "        self.p_total = p_total\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "    \n",
    "    def add(self, item, name=''):\n",
    "        \n",
    "        if type(item)==list:\n",
    "            for i in item:\n",
    "                self.add(i, name=name)\n",
    "        else:\n",
    "            self.buffer.append(item)\n",
    "            self.buffer_sources.append(name+'_buffer')\n",
    "            \n",
    "    def sample(self, n):\n",
    "        \n",
    "        idxs = np.random.choice(np.arange(len(self.buffer)), min(n, len(self.buffer)), \n",
    "                                replace=False)\n",
    "        batch = [self.buffer[i] for i in idxs]\n",
    "        sources = [self.buffer_sources[i] for i in idxs]\n",
    "        for idx in sorted(idxs, reverse=True):\n",
    "            self.buffer.pop(idx)\n",
    "            self.buffer_sources.pop(idx)\n",
    "\n",
    "        return batch, sources\n",
    "    \n",
    "    def _filter_buffer(self, valids):\n",
    "        \n",
    "        self.buffer = [self.buffer[i] for i in range(len(self.buffer)) if valids[i]]\n",
    "        self.buffer_sources = [self.buffer_sources[i] \n",
    "                               for i in range(len(self.buffer_sources)) if valids[i]]\n",
    "        \n",
    "    def filter_buffer(self):\n",
    "        if self.buffer:\n",
    "            seen = set()\n",
    "            unique = []\n",
    "            for item in self.buffer:\n",
    "                if item in seen:\n",
    "                    unique.append(False)\n",
    "                else:\n",
    "                    seen.add(item)\n",
    "                    unique.append(True)\n",
    "                    \n",
    "            self._filter_buffer(np.array(unique))\n",
    "    \n",
    "    def sample_batch(self):\n",
    "        env = self.environment\n",
    "        batch_state = env.batch_state\n",
    "        \n",
    "        bs = int(env.bs * self.p_total)\n",
    "        if bs>0:\n",
    "            sample, sources = self.sample(bs)\n",
    "            batch_state.samples += sample\n",
    "            batch_state.sources += sources\n",
    "            \n",
    "    def filter_batch(self):\n",
    "        env = self.environment\n",
    "        batch_state = env.batch_state\n",
    "        samples = batch_state.samples\n",
    "        \n",
    "        unique_samples = set()\n",
    "        unique = []\n",
    "        \n",
    "        for sample in samples:\n",
    "            if sample in unique_samples:\n",
    "                unique.append(False)\n",
    "            else:\n",
    "                unique_samples.add(sample)\n",
    "                unique.append(True)\n",
    "                \n",
    "        unique = np.array(unique)\n",
    "        self._filter_batch(unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mrl)",
   "language": "python",
   "name": "mrl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
