{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp callbacks.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging\n",
    "\n",
    "> Callbacks for logging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "from mrl.imports import *\n",
    "from mrl.core import *\n",
    "from mrl.callbacks.core import *\n",
    "from mrl.torch_imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def log_to_df(log, keys=None):\n",
    "    batch = 0\n",
    "    output_dict = defaultdict(list)\n",
    "    \n",
    "    if keys is None:\n",
    "        keys = list(log.keys())\n",
    "    \n",
    "    items = log[keys[0]]\n",
    "    for item in items:\n",
    "        output_dict['batch'] += [batch]*len(item)\n",
    "        batch += 1\n",
    "        \n",
    "    for key in keys:\n",
    "        output_dict[key] = flatten_list_of_lists(log[key])\n",
    "\n",
    "    return pd.DataFrame(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Log(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__(name='log', order=100)\n",
    "        \n",
    "        self.pbar = None\n",
    "        self.iterations = 0\n",
    "        self.metrics = {}\n",
    "        \n",
    "        self.batch_log = {}\n",
    "        self.timelog = defaultdict(list)\n",
    "        \n",
    "        self.report = 1\n",
    "        self.unique_samples = {}\n",
    "#         self.unique_samples = set()\n",
    "        \n",
    "        self.add_metric('rewards')\n",
    "        self.add_log('samples')\n",
    "        self.add_log('sources')\n",
    "        self.add_log('rewards')\n",
    "        \n",
    "        self.log_df = None\n",
    "        \n",
    "    def setup(self):\n",
    "        self.df = pd.DataFrame(self.batch_log)\n",
    "        \n",
    "    def before_train(self):\n",
    "        cols = ['iterations'] + list(self.metrics.keys())\n",
    "        if self.pbar is None:\n",
    "            print('\\t'.join(cols))\n",
    "        else:\n",
    "            self.pbar.write(cols, table=True)\n",
    "            \n",
    "    def add_metric(self, name):\n",
    "        if not name in self.metrics.keys():\n",
    "            self.metrics[name] = []\n",
    "        \n",
    "    def add_log(self, name):\n",
    "        if not name in self.batch_log.keys():\n",
    "            self.batch_log[name] = []\n",
    "            \n",
    "    def update_metric(self, name, value):\n",
    "        self.metrics[name].append(value)\n",
    "        \n",
    "    def update_log(self):\n",
    "        env = self.environment\n",
    "        batch_state = env.batch_state\n",
    "        samples = batch_state.samples\n",
    "        update_dict = {}\n",
    "\n",
    "        for key in self.batch_log.keys():\n",
    "            items = batch_state[key]\n",
    "            if isinstance(items, torch.Tensor):\n",
    "                items = items.detach().cpu().numpy()\n",
    "            self.batch_log[key].append(items)\n",
    "            update_dict[key] = items\n",
    "            \n",
    "        new_df = pd.DataFrame(update_dict)\n",
    "        repeats = new_df.samples.isin(self.df.samples)\n",
    "        new_df = new_df[~repeats]\n",
    "            \n",
    "        self.df = self.df.append(new_df)\n",
    "        \n",
    "#         if self.iterations%5==0 and self.iterations>0:\n",
    "#             self.df.drop_duplicates(subset='samples', inplace=True)\n",
    "            \n",
    "    def before_compute_reward(self):\n",
    "        env = self.environment\n",
    "        batch_state = env.batch_state\n",
    "        samples = batch_state.samples\n",
    "        batch_state.prescored = []\n",
    "        \n",
    "        for i, sample in enumerate(samples):\n",
    "            if sample in self.unique_samples:\n",
    "                batch_state.prescored.append(True)\n",
    "                batch_state.rewards[i] = torch.tensor(self.unique_samples[sample])\n",
    "            else:\n",
    "                batch_state.prescored.append(False)\n",
    "        \n",
    "            \n",
    "    def after_compute_reward(self):\n",
    "        env = self.environment\n",
    "        batch_state = env.batch_state\n",
    "        samples = batch_state.samples\n",
    "        rewards = batch_state.rewards.detach().cpu().numpy()\n",
    "        for i in range(len(samples)):\n",
    "            if not samples[i] in self.unique_samples:\n",
    "                self.unique_samples[samples[i]] = rewards[i]\n",
    "            \n",
    "    def report_batch(self):\n",
    "        outputs = [f'{self.iterations}']\n",
    "        if self.iterations%self.report==0:\n",
    "            \n",
    "            for k,v in self.metrics.items():\n",
    "                val = v[-1]\n",
    "\n",
    "                if type(val)==int:\n",
    "                    val = f'{val}'\n",
    "                else:\n",
    "                    val = f'{val:.3f}'\n",
    "\n",
    "                outputs.append(val)\n",
    "\n",
    "            if self.pbar is None:\n",
    "                print('\\t'.join(outputs))\n",
    "            else:\n",
    "                self.pbar.write(outputs, table=True)\n",
    "            \n",
    "        self.iterations += 1\n",
    "        \n",
    "    def after_batch(self):\n",
    "        self.update_log()\n",
    "        self.report_batch()\n",
    "        \n",
    "    def get_df(self):\n",
    "        return log_to_df(self.batch_log)\n",
    "    \n",
    "    def plot_metrics(self, cols=4, smooth=True):\n",
    "        self.plot_dict(self.metrics, cols=cols, smooth=smooth)\n",
    "            \n",
    "    def plot_timelog(self, cols=4, smooth=True):\n",
    "        self.plot_dict(self.timelog, cols=cols, smooth=smooth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class StatsCallback(Callback):\n",
    "    # grabs from batch_state based on name\n",
    "    def __init__(self, batch_attribute, grabname=None, name='stats', order=20):\n",
    "        super().__init__(name=name, order=order)\n",
    "        self.grabname = grabname\n",
    "        self.batch_attribute = batch_attribute\n",
    "\n",
    "    def get_values(self):\n",
    "        batch_state = self.environment.batch_state\n",
    "        sources = np.array(batch_state.sources)\n",
    "        values = batch_state[self.batch_attribute]\n",
    "        \n",
    "        if self.grabname is not None:\n",
    "            source_mask = sources==self.grabname\n",
    "            values = values[source_mask]\n",
    "            \n",
    "        if isinstance(values, torch.Tensor):\n",
    "            values = values.detach().cpu().numpy()\n",
    "            \n",
    "        return values\n",
    "    \n",
    "class MaxCallback(StatsCallback):\n",
    "    def __init__(self, batch_attribute, grabname, order=20):\n",
    "        \n",
    "        if grabname is None:\n",
    "            name = f'{batch_attribute}_max'\n",
    "        else:\n",
    "            name = f'{batch_attribute}_{grabname}_max'\n",
    "        \n",
    "        super().__init__(batch_attribute, grabname, name=name)\n",
    "        \n",
    "        \n",
    "    def setup(self):\n",
    "        log = self.environment.log\n",
    "        log.add_metric(self.name)\n",
    "        \n",
    "    def after_compute_reward(self):\n",
    "        \n",
    "        values = self.get_values()\n",
    "        self.environment.log.update_metric(self.name, values.max())\n",
    "        \n",
    "class PercentileCallback(StatsCallback):\n",
    "    def __init__(self, batch_attribute, grabname, percentile, order=20):\n",
    "        \n",
    "        if grabname is None:\n",
    "            name = f'{batch_attribute}_p{percentile}'\n",
    "        else:\n",
    "            name = f'{batch_attribute}_{grabname}_p{percentile}'\n",
    "        \n",
    "        super().__init__(batch_attribute, grabname, name=name)\n",
    "        self.percentile = percentile\n",
    "        \n",
    "    def setup(self):\n",
    "        log = self.environment.log\n",
    "        log.add_metric(self.name)\n",
    "        \n",
    "    def after_compute_reward(self):\n",
    "        \n",
    "        values = self.get_values()\n",
    "        self.environment.log.update_metric(self.name, np.percentile(values, self.percentile))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mrl)",
   "language": "python",
   "name": "mrl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
