{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp callbacks.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging\n",
    "\n",
    "> Callbacks for logging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "from mrl.imports import *\n",
    "from mrl.core import *\n",
    "from mrl.callbacks.core import *\n",
    "from mrl.torch_imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def log_to_df(log, keys=None):\n",
    "    batch = 0\n",
    "    output_dict = defaultdict(list)\n",
    "    \n",
    "    if keys is None:\n",
    "        keys = list(log.keys())\n",
    "    \n",
    "    items = log[keys[0]]\n",
    "    for item in items:\n",
    "        output_dict['batch'] += [batch]*len(item)\n",
    "        batch += 1\n",
    "        \n",
    "    for key in keys:\n",
    "        output_dict[key] = flatten_list_of_lists(log[key])\n",
    "        \n",
    "    return pd.DataFrame(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Log(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__(name='log', order=100)\n",
    "        \n",
    "        self.pbar = None\n",
    "        self.iterations = 0\n",
    "        self.metrics = {}\n",
    "        \n",
    "        self.log = {}\n",
    "        self.timelog = defaultdict(list)\n",
    "        \n",
    "        self.report = 1\n",
    "        self.unique_samples = set()\n",
    "        \n",
    "        self.add_metric('rewards')\n",
    "        self.add_log('samples')\n",
    "        self.add_log('sources')\n",
    "        self.add_log('rewards')\n",
    "        \n",
    "    def before_train(self):\n",
    "        cols = ['iterations'] + list(self.metrics.keys())\n",
    "        if self.pbar is None:\n",
    "            print('\\t'.join(cols))\n",
    "        else:\n",
    "            self.pbar.write(cols, table=True)\n",
    "            \n",
    "    def add_metric(self, name):\n",
    "        if not name in self.metrics.keys():\n",
    "            self.metrics[name] = []\n",
    "        \n",
    "    def add_log(self, name):\n",
    "        if not name in self.log.keys():\n",
    "            self.log[name] = []\n",
    "            \n",
    "    def update_metric(self, name, value):\n",
    "        self.metrics[name].append(value)\n",
    "        \n",
    "    def update_log(self):\n",
    "        env = self.environment\n",
    "        batch_state = env.batch_state\n",
    "        samples = batch_state.samples\n",
    "        self.unique_samples.update(set(samples))\n",
    "\n",
    "        for key in self.log.keys():\n",
    "            try:\n",
    "                items = batch_state[key]\n",
    "                if isinstance(items, torch.Tensor):\n",
    "                    items = items.detach().cpu().numpy()\n",
    "                self.log[key].append(items)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    def report_batch(self):\n",
    "        outputs = [f'{self.iterations}']\n",
    "        if self.iterations%self.report==0:\n",
    "            \n",
    "            for k,v in self.metrics.items():\n",
    "                val = v[-1]\n",
    "\n",
    "                if type(val)==int:\n",
    "                    val = f'{val}'\n",
    "                else:\n",
    "                    val = f'{val:.3f}'\n",
    "\n",
    "                outputs.append(val)\n",
    "\n",
    "            if self.pbar is None:\n",
    "                print('\\t'.join(outputs))\n",
    "            else:\n",
    "                self.pbar.write(outputs, table=True)\n",
    "            \n",
    "        self.iterations += 1\n",
    "        \n",
    "    def after_batch(self):\n",
    "        self.update_log()\n",
    "        self.report_batch()\n",
    "        \n",
    "    def get_df(self):\n",
    "        return log_to_df(self.log)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mrl)",
   "language": "python",
   "name": "mrl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
