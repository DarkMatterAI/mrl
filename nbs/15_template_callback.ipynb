{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp callbacks.template_cb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template Callback\n",
    "\n",
    "> Callbacks for templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmai/miniconda3/envs/mrl/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: to-Python converter for boost::shared_ptr<RDKit::FilterCatalogEntry const> already registered; second conversion method ignored.\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "\n",
    "from mrl.callbacks.core import *\n",
    "from mrl.chem import *\n",
    "from mrl.templates import *\n",
    "from mrl.torch_imports import *\n",
    "from mrl.torch_core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "        \n",
    "class TemplateCallback(Callback):\n",
    "    def __init__(self, template=None, weight=1., track=True, prefilter=True):\n",
    "        super().__init__(order=-1)\n",
    "        self.template = template\n",
    "        self.track = track\n",
    "        self.name = 'template'\n",
    "        self.prefilter = prefilter\n",
    "        self.weight = weight\n",
    "        \n",
    "    def setup(self):\n",
    "        if self.track:\n",
    "            log = self.environment.log\n",
    "            log.add_metric(self.name)\n",
    "            log.add_log(self.name)\n",
    "            log.add_metric(f'valid')\n",
    "            \n",
    "            if isinstance(self.template, BlockTemplate):\n",
    "                log.add_log('samples_fused')\n",
    "\n",
    "    def after_build_buffer(self):\n",
    "        env = self.environment\n",
    "        buffer = env.buffer\n",
    "        if buffer.buffer:\n",
    "            buffer.buffer = self.standardize(buffer.buffer)\n",
    "            buffer.buffer = self.filter_sequences(buffer.buffer)\n",
    "                \n",
    "    def after_sample(self):\n",
    "        env = self.environment\n",
    "        batch_state = env.batch_state\n",
    "        \n",
    "        samples = batch_state.samples\n",
    "        samples = self.standardize(samples)\n",
    "        batch_state.samples = samples\n",
    "        \n",
    "        sources = np.array(batch_state.sources)\n",
    "        valids = self.filter_sequences(samples, return_array=True)\n",
    "        \n",
    "        if valids.mean()<1.:\n",
    "            filtered_samples = [samples[i] for i in range(len(samples)) if valids[i]]\n",
    "            filtered_sources = [sources[i] for i in range(len(sources)) if valids[i]]\n",
    "            filtered_latent_data = {}\n",
    "\n",
    "            for source,latent_idxs in batch_state.latent_data.items():\n",
    "                valid_subset = valids[sources==source]\n",
    "                latent_filtered = latent_idxs[valid_subset]\n",
    "                filtered_latent_data[source] = latent_filtered\n",
    "\n",
    "            batch_state.samples = filtered_samples\n",
    "            batch_state.sources = filtered_sources\n",
    "            batch_state.latent_data = filtered_latent_data\n",
    "        \n",
    "        if self.track:\n",
    "            env.log.update_metric('valid', valids.mean())\n",
    "                \n",
    "    def compute_reward(self):\n",
    "        env = self.environment\n",
    "        state = env.batch_state\n",
    "        \n",
    "        if isinstance(self.template, BlockTemplate):\n",
    "            outputs = self.template.recurse_fragments(state.samples)\n",
    "            rewards = np.array([i[3] for i in outputs])\n",
    "            state.samples_fused = [i[1] for i in outputs]\n",
    "            \n",
    "        elif self.template is not None:\n",
    "            rewards = np.array(self.template.eval_mols(state.samples))\n",
    "            \n",
    "        else:\n",
    "            rewards = np.array([0.]*len(state.samples))\n",
    "        \n",
    "        hps = self.get_hps(state.samples)\n",
    "        state[self.name] = rewards\n",
    "        rewards = rewards*self.weight\n",
    "        \n",
    "        if self.track:\n",
    "            env.log.update_metric(self.name, rewards.mean())\n",
    "            \n",
    "        state.template_passes = hps\n",
    "        state.rewards += to_device(torch.from_numpy(rewards).float())\n",
    "        \n",
    "    def get_hps(self, sequences):\n",
    "        if self.template is not None:\n",
    "            hps = np.array(self.template(sequences))\n",
    "        else:\n",
    "            hps = np.array([True]*len(sequences))\n",
    "            \n",
    "        return hps\n",
    "        \n",
    "    def filter_sequences(self, sequences, return_array=False):\n",
    "        if self.prefilter:\n",
    "            passes = self.get_hps(sequences)\n",
    "        else:\n",
    "            passes = self.validate(sequences)\n",
    "        \n",
    "        if return_array:\n",
    "            output = passes\n",
    "        else:\n",
    "            output  = [sequences[i] for i in range(len(sequences)) if passes[i]]\n",
    "        return output\n",
    "    \n",
    "    def standardize(self, sequences):\n",
    "        if self.template is not None:\n",
    "            sequences = self.template.standardize(sequences)\n",
    "        \n",
    "        return sequences\n",
    "    \n",
    "    def validate(self, sequences):\n",
    "        if self.template is not None:\n",
    "            valid = np.array(self.template.validate(sequences))\n",
    "        else:\n",
    "            valid = np.array([True]*len(sequences))\n",
    "            \n",
    "        return valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "    \n",
    "class ContrastiveTemplate(TemplateCallback):\n",
    "    def __init__(self, similarity_function, max_score=None, template=None, \n",
    "                 weight=1., track=True, prefilter=True):\n",
    "        super().__init__(template=template, weight=weight, track=track, prefilter=prefilter)\n",
    "        self.similarity_function = similarity_function\n",
    "        self.max_score = max_score\n",
    "        \n",
    "    def setup(self):\n",
    "        if self.track:\n",
    "            log = self.environment.log\n",
    "            log.add_metric(self.name)\n",
    "            log.add_metric(self.name+'_temp')\n",
    "            log.add_metric(self.name+'_sim')\n",
    "            log.add_log(self.name)\n",
    "            log.add_log(self.name+'_temp')\n",
    "            log.add_log(self.name+'_sim')\n",
    "            \n",
    "            if isinstance(self.template, BlockTemplate):\n",
    "                log.add_log('samples_fused')\n",
    "        \n",
    "    def compute_reward(self):\n",
    "        env = self.environment\n",
    "        state = env.batch_state\n",
    "        \n",
    "        samples = state.samples\n",
    "        source_samples = [i[0] for i in samples]\n",
    "        target_samples = [i[1] for i in samples]\n",
    "        hps = self.get_hps(samples)\n",
    "        \n",
    "        if self.template is not None:\n",
    "            \n",
    "            if isinstance(self.template, BlockTemplate):\n",
    "                source_outputs = self.template.recurse_fragments(source_samples)\n",
    "                target_outputs = self.template.recurse_fragments(target_samples)\n",
    "                state.samples_fused = [(source_outputs[i][1], target_outputs[i][1])\n",
    "                                      for i in range(len(source_outputs))]\n",
    "                \n",
    "                source_rewards = np.array([i[3] for i in source_outputs])\n",
    "                target_rewards = np.array([i[3] for i in target_outputs])\n",
    "                \n",
    "            else:\n",
    "                source_rewards = np.array(self.template.eval_mols(source_samples))\n",
    "                target_rewards = np.array(self.template.eval_mols(target_samples))\n",
    "            \n",
    "            rewards = target_rewards - source_rewards\n",
    "            if self.max_score is not None:\n",
    "                rewards = rewards / (self.max_score-source_rewards)\n",
    "            \n",
    "        else:\n",
    "            rewards = np.array([0.]*len(state.samples))\n",
    "\n",
    "        sim_scores = self.similarity_function.score(source_samples, target_samples)\n",
    "        \n",
    "        state.template = rewards\n",
    "        state.template_sim = sim_scores\n",
    "        \n",
    "        full_rewards = rewards + sim_scores\n",
    "        full_rewards = full_rewards*self.weight\n",
    "        \n",
    "        if self.track:\n",
    "            env.log.update_metric(self.name, full_rewards.mean())\n",
    "            env.log.update_metric(self.name+'_temp', rewards.mean())\n",
    "            env.log.update_metric(self.name+'_sim', sim_scores.mean())\n",
    "            \n",
    "        state[self.name] = full_rewards\n",
    "        state[self.name+'_temp'] = rewards\n",
    "        state[self.name+'_sim'] = sim_scores\n",
    "            \n",
    "        state.template_passes = hps\n",
    "        state.rewards += to_device(torch.from_numpy(full_rewards).float())\n",
    "        \n",
    "    def standardize(self, sequences):\n",
    "        if self.template is not None:\n",
    "            sources = self.template.standardize([i[0] for i in sequences])\n",
    "            targets = self.template.standardize([i[1] for i in sequences])\n",
    "            sequences = [(sources[i], targets[i]) for i in range(len(sources))]\n",
    "        \n",
    "        return sequences\n",
    "        \n",
    "    def get_hps(self, sequences):\n",
    "        \n",
    "        if type(sequences[0])==str:\n",
    "            hps = super().get_hps(sequences)\n",
    "        else:\n",
    "            source_sequences = [i[0] for i in sequences]\n",
    "            target_sequences = [i[1] for i in sequences]\n",
    "            s_hps = super().get_hps(source_sequences)\n",
    "            t_hps = super().get_hps(target_sequences)\n",
    "            sim_bools = self.similarity_function.bools(source_sequences, target_sequences)\n",
    "            hps = s_hps*t_hps*sim_bools\n",
    "            \n",
    "        return hps\n",
    "    \n",
    "    def validate(self, sequences):\n",
    "        if type(sequences[0])==str:\n",
    "            valid = super().validate(sequences)\n",
    "        else:\n",
    "            s_val = super().validate([i[0] for i in sequences])\n",
    "            t_val = super().validate([i[1] for i in sequences])\n",
    "            valid = s_val*t_val\n",
    "            \n",
    "        return valid\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mrl)",
   "language": "python",
   "name": "mrl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
