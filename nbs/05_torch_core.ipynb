{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp torch_core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Core\n",
    "\n",
    "> Core pytorch functins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from mrl.imports import *\n",
    "from mrl.torch_imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "if USE_CUDA:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = int(os.environ.get('DEFAULT_GPU') or torch.cuda.current_device())\n",
    "    else:\n",
    "        device='cpu'\n",
    "            \n",
    "    device = torch.device(device)\n",
    "    return device\n",
    "\n",
    "def to_device(tensor, device=None):\n",
    "    if device is None:\n",
    "        device = get_device()\n",
    "    else:\n",
    "        device = torch.device(device)\n",
    "    \n",
    "    if hasattr(tensor, 'to'):\n",
    "        output = tensor.to(device)\n",
    "    else:\n",
    "        output = [to_device(i, device) for i in tensor]\n",
    "    \n",
    "    return output\n",
    "\n",
    "def set_device(device):\n",
    "    os.environ['DEFAULT_GPU'] = device\n",
    "    \n",
    "def get_model_device(model):\n",
    "    return next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def x_to_preds(x, multinomial=True):\n",
    "    log_probs = F.log_softmax(x, -1).squeeze(1)\n",
    "    probs = log_probs.detach().exp()\n",
    "    \n",
    "    if multinomial:\n",
    "        idxs = torch.multinomial(probs, 1)\n",
    "    else:\n",
    "        idxs = x.argmax(-1)\n",
    "\n",
    "    lps = torch.gather(log_probs, 1, idxs)\n",
    "    return idxs, lps\n",
    "\n",
    "def gather_lps(lps, y):\n",
    "    return lps.gather(2, y.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "def gumbel_onehot(y, num_classes=-1, probs=None, log_probs=None):\n",
    "    \n",
    "    y_onehot = F.one_hot(y, num_classes)\n",
    "    \n",
    "    if probs is not None:\n",
    "        y_onehot = y_onehot + probs - probs.detach()\n",
    "        \n",
    "    if log_probs is not None:\n",
    "        y_onehot = y_onehot + log_probs - log_probs.detach()\n",
    "\n",
    "    return y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def average_batches(batches):\n",
    "    val = torch.tensor(0.)\n",
    "    c = 0\n",
    "    for batch in batches:\n",
    "        bs = batch.shape[0]\n",
    "        val += batch.mean()*bs\n",
    "        c += bs\n",
    "        \n",
    "    return val/c\n",
    "\n",
    "def smooth_batches(batches, beta=0.98):\n",
    "    \n",
    "    val = torch.tensor(0.)\n",
    "    count = 0\n",
    "    \n",
    "    for batch in batches:\n",
    "        val = torch.lerp(batch.mean(), val, beta)\n",
    "        count += 1\n",
    "        \n",
    "    return val/(1-beta**count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def pad_and_merge(x1, x2, pad_idx, batch_dim=0, pad_dim=1):\n",
    "    \n",
    "    if type(x1)==list:\n",
    "        output = [pad_and_merge(x1[i], x2[i], pad_idx, batch_dim, pad_dim) \n",
    "                  for i in range(len(x1))]\n",
    "    else:\n",
    "        new_bs = x1.shape[batch_dim] + x2.shape[batch_dim]\n",
    "        new_sl = max(x1.shape[pad_dim], x2.shape[pad_dim])\n",
    "\n",
    "        output = torch.zeros((new_bs, new_sl)).long() + pad_idx\n",
    "        output = output.type(x1.dtype)\n",
    "        output = output.to(x1.device)\n",
    "        output[:x1.shape[0], :x1.shape[1]] = x1\n",
    "        output[x1.shape[0]:, :x2.shape[1]] = x2\n",
    "    \n",
    "    return output\n",
    "\n",
    "def merge_weights(sd1, sd2, alpha=0.5):\n",
    "    new_dict = {}\n",
    "    for key in sd1.keys():\n",
    "        if key in sd2.keys():\n",
    "            new_dict[key] = sd1[key]*alpha + sd2[key]*(1-alpha)\n",
    "        else:\n",
    "            new_dict[key] = sd1[key]\n",
    "    return new_dict\n",
    "\n",
    "def merge_models(model1, model2, alpha=0.5):\n",
    "    new_weights = merge_weights(model1.state_dict(), model2.state_dict(), alpha)\n",
    "    model1.load_state_dict(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def freeze(module):\n",
    "    for p in module.parameters():\n",
    "        p.requires_grad_(False)\n",
    "        \n",
    "def unfreeze(module):\n",
    "    for p in module.parameters():\n",
    "        p.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def discount_rewards(rewards, gamma):\n",
    "    discounted = torch.zeros((rewards.shape[0], rewards.shape[1]+1)).to(rewards.device)\n",
    "    \n",
    "    for i in reversed(range(discounted.shape[1]-1)):\n",
    "        discounted[:,i] = rewards[:,i] + gamma*discounted[:,i+1]\n",
    "        \n",
    "    return discounted[:,:-1]\n",
    "\n",
    "# def whiten(values, shift_mean=True):\n",
    "#     mean, var = torch.mean(values), torch.var(values)\n",
    "#     whitened = (values - mean) * torch.rsqrt(var + 1e-8)\n",
    "#     if not shift_mean:\n",
    "#         whitened += mean\n",
    "#     return whitened\n",
    "\n",
    "def whiten(values, shift_mean=True, mask=None):\n",
    "    if mask is None:\n",
    "        mean = values.mean()\n",
    "        var = values.var()\n",
    "    else:\n",
    "        mean = (values*mask).sum()/mask.sum()\n",
    "        var = ((values-mean)*mask).pow(2).sum()/(mask.sum()-1)\n",
    "        \n",
    "    whitened = (values - mean) * torch.rsqrt(var + 1e-8)\n",
    "    \n",
    "    if not shift_mean:\n",
    "        whitened += mean\n",
    "        \n",
    "    if mask is not None:\n",
    "        whitened = whitened*mask\n",
    "        \n",
    "    return whitened\n",
    "\n",
    "def scatter_rewards(rewards, mask):\n",
    "    template = torch.zeros(mask.shape).to(mask.device)\n",
    "    lengths = mask.sum(-1)\n",
    "    template[torch.arange(template.shape[0]), lengths-1]=rewards\n",
    "    return template\n",
    "\n",
    "def compute_advantages(rewards, values, gamma, lam):\n",
    "\n",
    "    advantages = torch.zeros(rewards.shape).to(rewards.device)\n",
    "\n",
    "    for i in reversed(range(rewards.shape[1])):\n",
    "        if i==rewards.shape[1]-1:\n",
    "            v_t1 = 0.\n",
    "            glv = 0.\n",
    "        else:\n",
    "            v_t1 = values[:,i+1]\n",
    "\n",
    "        delta = rewards[:, i] + gamma*v_t1 - values[:, i]\n",
    "        glv = delta + gamma * lam * glv\n",
    "        advantages[:,i] = glv\n",
    "        \n",
    "    return advantages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = torch.zeros((2, 9)).float()\n",
    "rewards[0, 8] = 2\n",
    "rewards[1,7] = 1\n",
    "dr = discount_rewards(rewards, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class CrossEntropy():\n",
    "    def __init__(self):\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def __call__(self, output, target):\n",
    "        output = output.view(-1, output.shape[-1])\n",
    "        target = target.view(-1)\n",
    "        return self.loss(output, target)\n",
    "    \n",
    "class HuberLoss():\n",
    "    def __init__(self, beta=1.):\n",
    "        self.loss = nn.SmoothL1Loss(beta=beta)\n",
    "        \n",
    "    def __call__(self, output, target):\n",
    "        output = output.squeeze(-1)\n",
    "        return self.loss(output, target)\n",
    "    \n",
    "    \n",
    "class MSELoss():\n",
    "    def __init__(self):\n",
    "        self.loss = F.mse_loss\n",
    "        \n",
    "    def __call__(self, output, target):\n",
    "        output = output.squeeze(-1)\n",
    "        return self.loss(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_chem.ipynb.\n",
      "Converted 02_template.filters.ipynb.\n",
      "Converted 03_template.template.ipynb.\n",
      "Converted 04_template.blocks.ipynb.\n",
      "Converted 05_torch_core.ipynb.\n",
      "Converted 06_layers.ipynb.\n",
      "Converted 07_dataloaders.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted template.overview.ipynb.\n",
      "Converted tutorials.ipynb.\n",
      "Converted tutorials.structure_enumeration.ipynb.\n",
      "Converted tutorials.template.advanced.ipynb.\n",
      "Converted tutorials.template.beginner.ipynb.\n",
      "Converted tutorials.template.intermediate.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
