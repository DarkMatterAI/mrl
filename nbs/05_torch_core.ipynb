{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp torch_core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Core\n",
    "\n",
    "> Core pytorch functins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from mrl.imports import *\n",
    "from mrl.torch_imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "if USE_CUDA:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "if USE_CUDA:\n",
    "    os.environ['use_cuda'] = 'cuda'\n",
    "else:\n",
    "    os.environ['use_cuda'] = 'cpu'\n",
    "    \n",
    "def get_device():\n",
    "    if torch.cuda.is_available() and os.environ['use_cuda']=='cuda':\n",
    "        device = torch.cuda.current_device()\n",
    "    else:\n",
    "        device='cpu'\n",
    "            \n",
    "    device = torch.device(device)\n",
    "    return device\n",
    "\n",
    "def to_device(tensor, device=None):\n",
    "    if device is None:\n",
    "        device = get_device()\n",
    "    else:\n",
    "        device = torch.device(device)\n",
    "    \n",
    "    if hasattr(tensor, 'to'):\n",
    "        output = tensor.to(device)\n",
    "    else:\n",
    "        output = [to_device(i, device) for i in tensor]\n",
    "    \n",
    "    return output\n",
    "\n",
    "def set_device(device):\n",
    "    torch.cuda.set_device(device)\n",
    "    \n",
    "def get_model_device(model):\n",
    "    return next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def freeze(module):\n",
    "    for p in module.parameters():\n",
    "        p.requires_grad_(False)\n",
    "        \n",
    "def unfreeze(module):\n",
    "    for p in module.parameters():\n",
    "        p.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def x_to_preds(x, multinomial=True):\n",
    "    log_probs = F.log_softmax(x, -1).squeeze(1)\n",
    "    probs = log_probs.detach().exp()\n",
    "    \n",
    "    if multinomial:\n",
    "        idxs = torch.multinomial(probs, 1)\n",
    "    else:\n",
    "        idxs = x.argmax(-1)\n",
    "\n",
    "    lps = torch.gather(log_probs, 1, idxs)\n",
    "    return idxs, lps\n",
    "\n",
    "def gather_lps(lps, y):\n",
    "    return lps.gather(2, y.unsqueeze(-1)).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "\n",
    "def subset_tensor(x, mask):\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        x = [i[mask] for i in x]\n",
    "    else:\n",
    "        x = x[mask]\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def merge_weights(sd1, sd2, alpha=0.5):\n",
    "    new_dict = {}\n",
    "    for key in sd1.keys():\n",
    "        if key in sd2.keys():\n",
    "            new_dict[key] = sd1[key]*alpha + sd2[key]*(1-alpha)\n",
    "        else:\n",
    "            new_dict[key] = sd1[key]\n",
    "    return new_dict\n",
    "\n",
    "def merge_models(model1, model2, alpha=0.5):\n",
    "    new_weights = merge_weights(model1.state_dict(), model2.state_dict(), alpha)\n",
    "    model1.load_state_dict(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class CrossEntropy():\n",
    "    def __init__(self):\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def __call__(self, output, target):\n",
    "        output = output.view(-1, output.shape[-1])\n",
    "        target = target.view(-1).long()\n",
    "        return self.loss(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mrl)",
   "language": "python",
   "name": "mrl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
