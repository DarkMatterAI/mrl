{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samplers\n",
    "\n",
    "> Sampling callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "from mrl.imports import *\n",
    "from mrl.torch_imports import *\n",
    "from mrl.torch_core import *\n",
    "from mrl.callbacks import *\n",
    "from mrl.chem import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Sampler(Callback):\n",
    "    def __init__(self, name, buffer_size=0, p_batch=0., track=True):\n",
    "        super().__init__(name=name)\n",
    "        self.name = name\n",
    "        self.buffer_size = buffer_size\n",
    "        self.p_batch = p_batch\n",
    "        self.track = track\n",
    "            \n",
    "    def _build_buffer(self):\n",
    "        return []\n",
    "        \n",
    "    def _sample_batch(self):\n",
    "        return []\n",
    "        \n",
    "    def build_buffer(self):\n",
    "        outputs = self._build_buffer()\n",
    "        if outputs:\n",
    "            self.environment.buffer.add(outputs)\n",
    "    \n",
    "    def sample_batch(self):\n",
    "        outputs = self._sample_batch()\n",
    "        if outputs:\n",
    "            self.batch_state.samples += outputs\n",
    "            self.batch_state.sources += [self.name]*len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class DatasetSampler(Sampler):\n",
    "    def __init__(self, data, buffer_size, name):\n",
    "        super().__init__(name, buffer_size, 0.)\n",
    "        self.data = data\n",
    "        \n",
    "    def _build_buffer(self):\n",
    "        idxs = np.random.randint(0, len(self.data), self.buffer_size)\n",
    "        samples = [self.data[i] for i in idxs]\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export          \n",
    "                  \n",
    "class ModelSampler(Sampler):\n",
    "    def __init__(self, vocab, model, name, buffer_size, p_batch, \n",
    "                 genbatch, track=True, temperature=1.):\n",
    "        super().__init__(name, buffer_size, p_batch, track)\n",
    "        \n",
    "        self.vocab = vocab\n",
    "        self.model = model\n",
    "        self.genbatch = genbatch\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def setup(self):\n",
    "        if self.p_batch>0. and self.track:\n",
    "            log = self.environment.log\n",
    "            log.add_metric(f'{self.name}_diversity')\n",
    "            log.add_metric(f'{self.name}_valid')\n",
    "            log.add_metric(f'{self.name}_rewards')\n",
    "            log.add_metric(f'{self.name}_new')\n",
    "        \n",
    "    def _build_buffer(self):\n",
    "        env = self.environment\n",
    "        buffer_size = self.buffer_size\n",
    "        sl = env.sl\n",
    "        outputs = []\n",
    "        to_generate = buffer_size\n",
    "        \n",
    "        if buffer_size > 0:\n",
    "            for batch in range(int(np.ceil(buffer_size/self.genbatch))):\n",
    "                current_bs = min(self.genbatch, to_generate)\n",
    "                \n",
    "                preds, _ = self.model.sample_no_grad(current_bs, sl, multinomial=True,\n",
    "                                                     temperature=self.temperature)\n",
    "                sequences = [self.vocab.reconstruct(i) for i in preds]\n",
    "                sequences = list(set(sequences))\n",
    "                sequences = env.template_cb.filter_sequences(sequences)\n",
    "                outputs += sequences\n",
    "                outputs = list(set(outputs))\n",
    "                to_generate = buffer_size - len(outputs)\n",
    "                \n",
    "        return outputs\n",
    "            \n",
    "            \n",
    "    def _sample_batch(self):\n",
    "        env = self.environment\n",
    "        bs = int(env.bs * self.p_batch)\n",
    "        sequences = []\n",
    "        \n",
    "        if bs > 0:\n",
    "            \n",
    "            preds, _ = self.model.sample_no_grad(bs, env.sl, z=None, multinomial=True,\n",
    "                                                temperature=self.temperature)\n",
    "            \n",
    "            sequences = [self.vocab.reconstruct(i) for i in preds]\n",
    "\n",
    "            env.batch_state[f'{self.name}_raw'] = sequences\n",
    "                \n",
    "        return sequences\n",
    "        \n",
    "    def after_compute_reward(self):\n",
    "        if self.p_batch>0. and self.track:\n",
    "            batch_state = self.environment.batch_state\n",
    "            log = self.environment.log\n",
    "            rewards = batch_state.rewards.detach().cpu().numpy()\n",
    "            sources = np.array(batch_state.sources)\n",
    "            \n",
    "            if self.name in sources:\n",
    "                log.update_metric(f'{self.name}_rewards', rewards[sources==self.name].mean())\n",
    "            else:\n",
    "                log.update_metric(f'{self.name}_rewards', 0.)\n",
    "        \n",
    "    def after_sample(self):\n",
    "        if self.p_batch > 0. and self.track:\n",
    "            log = self.environment.log\n",
    "            batch_state = self.environment.batch_state\n",
    "            samples = batch_state.samples\n",
    "            sources = np.array(batch_state.sources)==self.name\n",
    "\n",
    "            samples = [samples[i] for i in range(len(samples)) if sources[i]]\n",
    "            \n",
    "            if len(samples)>0:\n",
    "                diversity = len(set(samples))/len(samples)\n",
    "            else:\n",
    "                diversity = 0\n",
    "                \n",
    "            valid = len(samples)/len(batch_state[f'{self.name}_raw'])\n",
    "            \n",
    "            used = log.unique_samples\n",
    "            novel = [i for i in samples if not i in used]\n",
    "            percent_novel = len(novel)/len(samples)\n",
    "            log.update_metric(f'{self.name}_new', percent_novel)\n",
    "            log.update_metric(f\"{self.name}_diversity\", diversity)\n",
    "            log.update_metric(f\"{self.name}_valid\", valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export          \n",
    "                  \n",
    "class LatentSampler(ModelSampler):\n",
    "    def __init__(self, vocab, model, latents, name, buffer_size, \n",
    "                 p_batch, genbatch, track=True, \n",
    "                 temperature=1., opt_kwargs={}):\n",
    "        super().__init__(vocab, \n",
    "                         model, \n",
    "                         name, \n",
    "                         buffer_size, \n",
    "                         p_batch, \n",
    "                         genbatch, \n",
    "                         track, \n",
    "                         temperature)\n",
    "        \n",
    "        self.set_latents(latents, opt_kwargs)\n",
    "        \n",
    "    def set_latents(self, latents, opt_kwargs):\n",
    "        self.latents = to_device(latents)\n",
    "        self.latents = nn.Parameter(self.latents)\n",
    "        self.opt = optim.Adam([self.latents], **opt_kwargs)\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        self.opt.zero_grad()\n",
    "        \n",
    "    def step(self):\n",
    "        self.opt.step()\n",
    "        \n",
    "    def _build_buffer(self):\n",
    "        return []\n",
    "    \n",
    "    def _sample_batch(self):\n",
    "        env = self.environment\n",
    "        bs = int(env.bs * self.p_batch)\n",
    "        sequences = []\n",
    "        \n",
    "        if bs > 0:\n",
    "            \n",
    "            latent_idxs = torch.randint(0, self.latents.shape[0]-1, (bs,))\n",
    "            sample_latents = self.latents[latent_idxs]\n",
    "\n",
    "            preds, _ = self.model.sample_no_grad(bs, env.sl, z=sample_latents, multinomial=True,\n",
    "                                                temperature=self.temperature)\n",
    "            sequences = [self.vocab.reconstruct(i) for i in preds]\n",
    "\n",
    "            env.batch_state[f'{self.name}_raw'] = sequences\n",
    "            \n",
    "            env.batch_state.latent_data[self.name] = sample_latents\n",
    "                \n",
    "        return sequences\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class ContrastiveSampler(Sampler):\n",
    "    def __init__(self, base_sampler, vocab, dataset, output_model, bs, repeats=1):\n",
    "        super().__init__(base_sampler.name, base_sampler.buffer_size,\n",
    "                         base_sampler.p_batch, base_sampler.track)\n",
    "        \n",
    "        self.base_sampler = base_sampler\n",
    "        self.vocab = vocab\n",
    "        self.dataset = dataset\n",
    "        self.output_model = output_model\n",
    "        self.bs = bs\n",
    "        self.repeats = repeats\n",
    "        \n",
    "    def __call__(self, event_name):\n",
    "        \n",
    "        event = getattr(self, event_name, None)\n",
    "        \n",
    "        if event is not None:\n",
    "            output = event()\n",
    "        else:\n",
    "            output = None\n",
    "            \n",
    "        if not (event_name in ['build_buffer', 'sample_batch']):\n",
    "            _ = self.base_sampler(event_name)\n",
    "            \n",
    "        return output\n",
    "    \n",
    "    def setup(self):\n",
    "        self.base_sampler.environment = self.environment\n",
    "        \n",
    "    def sample_outputs(self, sequences):   \n",
    "        sequences = list(sequences)\n",
    "        env = self.environment\n",
    "        if self.repeats>1:\n",
    "            sequences = sequences*self.repeats\n",
    "        pairs = [(i,'') for i in sequences]\n",
    "        batch_ds = self.dataset.new(pairs)\n",
    "        \n",
    "        if len(batch_ds)<self.bs:\n",
    "        \n",
    "            batch = batch_ds.collate_function([batch_ds[i] for i in range(len(batch_ds))])\n",
    "            batch = to_device(batch)\n",
    "            x,_ = batch\n",
    "            z = self.output_model.x_to_latent(x)\n",
    "            preds, _ = self.output_model.sample_no_grad(z.shape[0], env.sl, z=z)\n",
    "            new_sequences = [self.vocab.reconstruct(i) for i in preds]\n",
    "            \n",
    "        else:\n",
    "            batch_dl = batch_ds.dataloader(self.bs, shuffle=False)\n",
    "\n",
    "            new_sequences = []\n",
    "\n",
    "            for i, batch in enumerate(batch_dl):\n",
    "                batch = to_device(batch)\n",
    "                x,_ = batch\n",
    "                z = self.output_model.x_to_latent(x)\n",
    "                preds, _ = self.output_model.sample_no_grad(z.shape[0], env.sl, z=z)\n",
    "                new_sequences += [self.vocab.reconstruct(i) for i in preds]\n",
    "        \n",
    "        outputs = [(sequences[i], new_sequences[i]) for i in range(len(sequences))]\n",
    "        env.batch_state[f'{self.name}_raw_contrastive'] = outputs\n",
    "                \n",
    "        return outputs\n",
    "        \n",
    "    def _build_buffer(self):\n",
    "        outputs = self.base_sampler._build_buffer()\n",
    "        if outputs:\n",
    "            outputs = self.sample_outputs(outputs)\n",
    "        return outputs\n",
    "    \n",
    "    def _sample_batch(self):\n",
    "        outputs = self.base_sampler._sample_batch()\n",
    "        if outputs:\n",
    "            outputs = self.sample_outputs(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class LogSampler(Sampler):\n",
    "    def __init__(self, sample_name, start_iter, percentile, buffer_size):\n",
    "        super().__init__(sample_name+'_sample', buffer_size, p_batch=0.)\n",
    "        self.start_iter = start_iter\n",
    "        self.percentile = percentile\n",
    "        self.sample_name = sample_name\n",
    "        \n",
    "    def _build_buffer(self):\n",
    "        env = self.environment\n",
    "        \n",
    "        iterations = self.environment.log.iterations\n",
    "        outputs = []\n",
    "\n",
    "        if iterations > self.start_iter:\n",
    "            df = log_to_df(env.log.log, ['samples', self.sample_name])\n",
    "            df.drop_duplicates(subset='samples', inplace=True)\n",
    "            bs = self.buffer_size\n",
    "            if bs > 0:\n",
    "                \n",
    "                subset = df[df[self.sample_name]>np.percentile(df[self.sample_name].values, \n",
    "                                                               self.percentile)]\n",
    "                outputs = list(subset.sample(n=min(bs, subset.shape[0])).samples.values)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "class TokenSwapSampler(LogSampler):\n",
    "    def __init__(self, sample_name, start_iter, percentile, buffer_size, \n",
    "                 vocab, swap_percent):\n",
    "        super().__init__(sample_name, start_iter, percentile, buffer_size)\n",
    "        self.vocab = vocab\n",
    "        self.swap_percent = swap_percent\n",
    "        \n",
    "    def _build_buffer(self):\n",
    "        samples = super()._build_buffer()\n",
    "        \n",
    "        new_samples = []\n",
    "        \n",
    "        for sample in samples:\n",
    "            tokens = self.vocab.tokenize(sample)\n",
    "            num_swaps = int(self.swap_percent*len(tokens))\n",
    "            swap_idxs = np.random.choice(np.arange(len(tokens)), num_swaps, replace=False)\n",
    "            new_tokens = np.random.choice(self.vocab.itos, num_swaps, replace=True)\n",
    "            for idx, new_token in zip(swap_idxs, new_tokens):\n",
    "                tokens[idx] = new_token\n",
    "            \n",
    "            sample = self.vocab.join_tokens(tokens)\n",
    "            sample = self.vocab.postprocess(sample)\n",
    "            new_samples.append(sample)\n",
    "            \n",
    "        return new_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class LogEnumerator(LogSampler):\n",
    "    def __init__(self, sample_name, start_iter, percentile, \n",
    "                 buffer_size, atom_types=None):\n",
    "        super().__init__(sample_name+'_enum', start_iter, percentile, buffer_size)\n",
    "\n",
    "        if atom_types is None:\n",
    "            atom_types = ['C', 'N', 'O', 'F', 'S', 'Br', 'Cl', -1]\n",
    "            \n",
    "        self.atom_types = atom_types\n",
    "        \n",
    "    def _build_buffer(self):\n",
    "        \n",
    "        samples = super()._build_buffer()\n",
    "        \n",
    "        new_samples = []\n",
    "        \n",
    "        for sample in samples:\n",
    "            \n",
    "            new_smiles = add_atom_combi(s, self.atom_types) + add_bond_combi(s)\n",
    "            new_smiles = [i for i in new_smiles if i is not None]\n",
    "            new_smiles = [i for i in new_smiles if not '.' in i]\n",
    "            new_samples += new_smiles\n",
    "\n",
    "        return new_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mrl)",
   "language": "python",
   "name": "mrl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
