{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp sampler\n",
    "\n",
    "# all_rdkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samplers\n",
    "\n",
    "> Sampling callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "from mrl.imports import *\n",
    "from mrl.torch_imports import *\n",
    "from mrl.torch_core import *\n",
    "from mrl.callbacks import *\n",
    "from mrl.chem import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Sampler(Callback):\n",
    "    def __init__(self, name, buffer_size=0, p_batch=0., track=True):\n",
    "        super().__init__(name=name)\n",
    "        self.name = name\n",
    "        self.buffer_size = buffer_size\n",
    "        self.p_batch = p_batch\n",
    "        self.track = track\n",
    "            \n",
    "    def _build_buffer(self):\n",
    "        return []\n",
    "        \n",
    "    def _sample_batch(self):\n",
    "        return []\n",
    "        \n",
    "    def build_buffer(self):\n",
    "        outputs = self._build_buffer()\n",
    "        if outputs:\n",
    "            self.environment.buffer.add(outputs, self.name)\n",
    "    \n",
    "    def sample_batch(self):\n",
    "        outputs = self._sample_batch()\n",
    "        if outputs:\n",
    "            self.environment.batch_state.samples += outputs\n",
    "            self.environment.batch_state.sources += [self.name]*len(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class DatasetSampler(Sampler):\n",
    "    def __init__(self, data, buffer_size, name):\n",
    "        super().__init__(name, buffer_size, 0.)\n",
    "        self.data = data\n",
    "        \n",
    "    def _build_buffer(self):\n",
    "        idxs = np.random.randint(0, len(self.data), self.buffer_size)\n",
    "        samples = [self.data[i] for i in idxs]\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export          \n",
    "                  \n",
    "class ModelSampler(Sampler):\n",
    "    def __init__(self, vocab, model, name, buffer_size, p_batch, \n",
    "                 genbatch, track=True, temperature=1.):\n",
    "        super().__init__(name, buffer_size, p_batch, track)\n",
    "        \n",
    "        self.vocab = vocab\n",
    "        self.model = model\n",
    "        self.genbatch = genbatch\n",
    "        self.temperature = temperature\n",
    "        \n",
    "    def setup(self):\n",
    "        if self.p_batch>0. and self.track:\n",
    "            log = self.environment.log\n",
    "            log.add_metric(f'{self.name}_diversity')\n",
    "            log.add_metric(f'{self.name}_valid')\n",
    "            log.add_metric(f'{self.name}_rewards')\n",
    "            log.add_metric(f'{self.name}_new')\n",
    "            \n",
    "    def build_buffer(self):\n",
    "        env = self.environment\n",
    "        sl = env.sl\n",
    "        outputs = self._build_buffer(sl)\n",
    "        if outputs:\n",
    "            self.environment.buffer.add(outputs, self.name)\n",
    "        \n",
    "    def _build_buffer(self, sl): \n",
    "        buffer_size = self.buffer_size\n",
    "        outputs = []\n",
    "        to_generate = buffer_size\n",
    "        \n",
    "        if buffer_size > 0:\n",
    "            for batch in range(int(np.ceil(buffer_size/self.genbatch))):\n",
    "                current_bs = min(self.genbatch, to_generate)\n",
    "                \n",
    "                preds, _ = self.model.sample_no_grad(current_bs, sl, multinomial=True,\n",
    "                                                     temperature=self.temperature)\n",
    "                sequences = [self.vocab.reconstruct(i) for i in preds]\n",
    "                sequences = list(set(sequences))\n",
    "                outputs += sequences\n",
    "                outputs = list(set(outputs))\n",
    "                to_generate = buffer_size - len(outputs)\n",
    "                \n",
    "        return outputs\n",
    "    \n",
    "    \n",
    "    def sample_batch(self):\n",
    "        env = self.environment\n",
    "        bs = env.bs\n",
    "        sl = env.sl\n",
    "        outputs = self._sample_batch(bs, sl)\n",
    "        env.batch_state[f'{self.name}_raw'] = outputs\n",
    "        if outputs:\n",
    "            env.batch_state.samples += outputs\n",
    "            env.batch_state.sources += [self.name]*len(outputs)\n",
    "            \n",
    "            \n",
    "    def _sample_batch(self, bs, sl):\n",
    "        bs = int(bs * self.p_batch)\n",
    "        sequences = []\n",
    "        \n",
    "        if bs > 0:\n",
    "            \n",
    "            preds, _ = self.model.sample_no_grad(bs, sl, z=None, multinomial=True,\n",
    "                                                temperature=self.temperature)\n",
    "            \n",
    "            sequences = [self.vocab.reconstruct(i) for i in preds]\n",
    "                \n",
    "        return sequences\n",
    "        \n",
    "    def after_compute_reward(self):\n",
    "        if self.p_batch>0. and self.track:\n",
    "            batch_state = self.environment.batch_state\n",
    "            log = self.environment.log\n",
    "            rewards = batch_state.rewards.detach().cpu().numpy()\n",
    "            sources = np.array(batch_state.sources)\n",
    "            \n",
    "            if self.name in sources:\n",
    "                log.update_metric(f'{self.name}_rewards', rewards[sources==self.name].mean())\n",
    "            else:\n",
    "                log.update_metric(f'{self.name}_rewards', 0.)\n",
    "        \n",
    "    def after_sample(self):\n",
    "        if self.p_batch > 0. and self.track:\n",
    "            log = self.environment.log\n",
    "            batch_state = self.environment.batch_state\n",
    "            samples = batch_state.samples\n",
    "            sources = np.array(batch_state.sources)==self.name\n",
    "\n",
    "            samples = [samples[i] for i in range(len(samples)) if sources[i]]\n",
    "            \n",
    "            raw_samples = batch_state[f'{self.name}_raw']\n",
    "            \n",
    "            if len(samples)>0:\n",
    "                diversity = len(set(raw_samples))/len(raw_samples)\n",
    "                used = log.unique_samples\n",
    "                novel = [i for i in samples if not i in used]\n",
    "                percent_novel = len(novel)/len(samples)\n",
    "            else:\n",
    "                diversity = 0\n",
    "                percent_novel = 0.\n",
    "                \n",
    "            valid = len(samples)/len(set(batch_state[f'{self.name}_raw']))\n",
    "\n",
    "            log.update_metric(f'{self.name}_new', percent_novel)\n",
    "            log.update_metric(f\"{self.name}_diversity\", diversity)\n",
    "            log.update_metric(f\"{self.name}_valid\", valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class PriorSampler(ModelSampler):\n",
    "    def __init__(self, vocab, model, prior, name, buffer_size, \n",
    "                 p_batch, genbatch, track=True, track_losses=True, train=True,\n",
    "                 train_all=False, prior_loss=None,\n",
    "                 temperature=1., opt_kwargs={}):\n",
    "        super().__init__(vocab, \n",
    "                         model, \n",
    "                         name, \n",
    "                         buffer_size, \n",
    "                         p_batch, \n",
    "                         genbatch, \n",
    "                         track, \n",
    "                         temperature)\n",
    "        \n",
    "        self.train = train\n",
    "        self.track_losses = track_losses\n",
    "        self.train_all = train_all\n",
    "        self.set_prior(prior, opt_kwargs)\n",
    "        self.prior_loss = prior_loss\n",
    "        \n",
    "    def setup(self):\n",
    "        super().setup()\n",
    "        if self.train and self.prior_loss is not None:\n",
    "            self.environment.log.add_log(self.name+'_loss')\n",
    "            if self.track_losses:\n",
    "                self.environment.log.add_metric(self.name+'_loss')\n",
    "        \n",
    "        \n",
    "    def set_prior(self, prior, opt_kwargs):\n",
    "        self.prior = to_device(prior)\n",
    "        if self.train:\n",
    "            self.opt = optim.Adam(self.prior.parameters(), **opt_kwargs)\n",
    "            \n",
    "    def zero_grad(self):\n",
    "        if self.train:\n",
    "            self.opt.zero_grad()\n",
    "        \n",
    "    def step(self):\n",
    "        if self.train:\n",
    "            self.opt.step()\n",
    "            \n",
    "    def _build_buffer(self, sl): \n",
    "        buffer_size = self.buffer_size\n",
    "        outputs = []\n",
    "        to_generate = buffer_size\n",
    "        \n",
    "        if buffer_size > 0:\n",
    "            for batch in range(int(np.ceil(buffer_size/self.genbatch))):\n",
    "                current_bs = min(self.genbatch, to_generate)\n",
    "                \n",
    "                z = self.prior.sample(current_bs)\n",
    "                preds, _ = self.model.sample_no_grad(current_bs, sl, z=z, multinomial=True,\n",
    "                                                     temperature=self.temperature)\n",
    "                sequences = [self.vocab.reconstruct(i) for i in preds]\n",
    "                sequences = list(set(sequences))\n",
    "                outputs += sequences\n",
    "                outputs = list(set(outputs))\n",
    "                to_generate = buffer_size - len(outputs)\n",
    "                \n",
    "        return outputs\n",
    "    \n",
    "    def sample_batch(self):\n",
    "        env = self.environment\n",
    "        bs = env.bs\n",
    "        sl = env.sl\n",
    "        sequences, sample_latents = self._sample_batch(bs, sl)\n",
    "        \n",
    "        env.batch_state[f'{self.name}_raw'] = sequences\n",
    "        env.batch_state.latent_data[self.name] = sample_latents\n",
    "        \n",
    "        if sequences:\n",
    "            env.batch_state.samples += sequences\n",
    "            env.batch_state.sources += [self.name]*len(sequences)\n",
    "    \n",
    "    def _sample_batch(self, bs, sl):\n",
    "        bs = int(bs * self.p_batch)\n",
    "        sequences = []\n",
    "        sample_latents = []\n",
    "        \n",
    "        if bs > 0:\n",
    "            \n",
    "            z = self.prior.rsample(bs)\n",
    "\n",
    "            preds, _ = self.model.sample_no_grad(bs, sl, z=z, multinomial=True,\n",
    "                                                temperature=self.temperature)\n",
    "            sequences = [self.vocab.reconstruct(i) for i in preds]\n",
    "                            \n",
    "        return sequences, z\n",
    "    \n",
    "    def compute_loss(self):\n",
    "        env = self.environment\n",
    "        batch_state = env.batch_state\n",
    "        \n",
    "        if self.train and self.prior_loss is not None:\n",
    "            if self.train_all:\n",
    "                subset_name = None\n",
    "            else:\n",
    "                subset_name = self.name\n",
    "                \n",
    "            loss = self.prior_loss.from_batch_state(batch_state, subset_name)\n",
    "\n",
    "            if self.track_losses:\n",
    "                \n",
    "                loss_d = loss.detach().cpu()\n",
    "                \n",
    "                if self.train_all:\n",
    "                    mean_loss = loss_d.mean()\n",
    "                else:\n",
    "                    mean_loss = loss_d[loss_d.nonzero()[0]].mean()\n",
    "                    \n",
    "                self.environment.log.update_metric(self.name+'_loss', mean_loss.numpy())\n",
    "\n",
    "            self.environment.batch_state.loss += loss.mean()\n",
    "            self.environment.batch_state[self.name+'_loss'] = loss.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export          \n",
    "                  \n",
    "class LatentSampler(ModelSampler):\n",
    "    def __init__(self, vocab, model, latents, name, buffer_size, \n",
    "                 p_batch, genbatch, track=True, train=True,\n",
    "                 temperature=1., opt_kwargs={}):\n",
    "        super().__init__(vocab, \n",
    "                         model, \n",
    "                         name, \n",
    "                         buffer_size, \n",
    "                         p_batch, \n",
    "                         genbatch, \n",
    "                         track, \n",
    "                         temperature)\n",
    "        \n",
    "        self.train = train\n",
    "        self.set_latents(latents, opt_kwargs)\n",
    "        \n",
    "    def set_latents(self, latents, opt_kwargs):\n",
    "        self.latents = to_device(latents)\n",
    "        if self.train:\n",
    "            self.latents = nn.Parameter(self.latents)\n",
    "            self.opt = optim.Adam([self.latents], **opt_kwargs)\n",
    "        else:\n",
    "            self.latents._requires_grad(False)\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        if self.train:\n",
    "            self.opt.zero_grad()\n",
    "        \n",
    "    def step(self):\n",
    "        if self.train:\n",
    "            self.opt.step()\n",
    "        \n",
    "    def _build_buffer(self, sl): \n",
    "        return []\n",
    "    \n",
    "    def sample_batch(self):\n",
    "        env = self.environment\n",
    "        bs = env.bs\n",
    "        sl = env.sl\n",
    "        sequences, sample_latents = self._sample_batch(bs, sl)\n",
    "        \n",
    "        env.batch_state[f'{self.name}_raw'] = sequences\n",
    "        env.batch_state.latent_data[self.name] = sample_latents\n",
    "        \n",
    "        if sequences:\n",
    "            env.batch_state.samples += sequences\n",
    "            env.batch_state.sources += [self.name]*len(sequences)\n",
    "    \n",
    "    def _sample_batch(self, bs, sl):\n",
    "        bs = int(bs * self.p_batch)\n",
    "        sequences = []\n",
    "        sample_latents = []\n",
    "        \n",
    "        if bs > 0:\n",
    "            \n",
    "            latent_idxs = torch.randint(0, self.latents.shape[0]-1, (bs,))\n",
    "            sample_latents = self.latents[latent_idxs]\n",
    "\n",
    "            preds, _ = self.model.sample_no_grad(bs, sl, z=sample_latents, multinomial=True,\n",
    "                                                temperature=self.temperature)\n",
    "            sequences = [self.vocab.reconstruct(i) for i in preds]\n",
    "                            \n",
    "        return sequences, sample_latents\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class ContrastiveSampler(Sampler):\n",
    "    def __init__(self, base_sampler, vocab, dataset, output_model, bs, repeats=1):\n",
    "        super().__init__(base_sampler.name, base_sampler.buffer_size,\n",
    "                         base_sampler.p_batch, base_sampler.track)\n",
    "        \n",
    "        self.base_sampler = base_sampler\n",
    "        self.vocab = vocab\n",
    "        self.dataset = dataset\n",
    "        self.output_model = output_model\n",
    "        self.bs = bs\n",
    "        self.repeats = repeats\n",
    "        \n",
    "    def __call__(self, event_name):\n",
    "        \n",
    "        event = getattr(self, event_name, None)\n",
    "        \n",
    "        if event is not None:\n",
    "            output = event()\n",
    "        else:\n",
    "            output = None\n",
    "            \n",
    "        if not (event_name in ['build_buffer', 'sample_batch']):\n",
    "            _ = self.base_sampler(event_name)\n",
    "            \n",
    "        return output\n",
    "    \n",
    "    def setup(self):\n",
    "        self.base_sampler.environment = self.environment\n",
    "        \n",
    "    def sample_outputs(self, sequences, sl):   \n",
    "        sequences = list(sequences)\n",
    "        if self.repeats>1:\n",
    "            sequences = sequences*self.repeats\n",
    "        pairs = [(i,'') for i in sequences]\n",
    "        batch_ds = self.dataset.new(pairs)\n",
    "        \n",
    "        if len(batch_ds)<self.bs:\n",
    "        \n",
    "            batch = batch_ds.collate_function([batch_ds[i] for i in range(len(batch_ds))])\n",
    "            batch = to_device(batch)\n",
    "            x,_ = batch\n",
    "            z = self.output_model.x_to_latent(x)\n",
    "            preds, _ = self.output_model.sample_no_grad(z.shape[0], sl, z=z)\n",
    "            new_sequences = [self.vocab.reconstruct(i) for i in preds]\n",
    "            \n",
    "        else:\n",
    "            batch_dl = batch_ds.dataloader(self.bs, shuffle=False)\n",
    "\n",
    "            new_sequences = []\n",
    "\n",
    "            for i, batch in enumerate(batch_dl):\n",
    "                batch = to_device(batch)\n",
    "                x,_ = batch\n",
    "                z = self.output_model.x_to_latent(x)\n",
    "                preds, _ = self.output_model.sample_no_grad(z.shape[0], sl, z=z)\n",
    "                new_sequences += [self.vocab.reconstruct(i) for i in preds]\n",
    "        \n",
    "        outputs = [(sequences[i], new_sequences[i]) for i in range(len(sequences))]\n",
    "              \n",
    "        return outputs\n",
    "        \n",
    "    def _build_buffer(self):\n",
    "        outputs = self.base_sampler._build_buffer()\n",
    "        env = self.environment\n",
    "        sl = env.sl\n",
    "        if outputs:\n",
    "            outputs = self.sample_outputs(outputs, sl)\n",
    "        return outputs\n",
    "    \n",
    "    def _sample_batch(self):\n",
    "        outputs = self.base_sampler._sample_batch()\n",
    "        env = self.environment\n",
    "        sl = env.sl\n",
    "        if outputs:\n",
    "            outputs = self.sample_outputs(outputs, sl)\n",
    "            env.batch_state[f'{self.name}_raw_contrastive'] = outputs\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class LogSampler(Sampler):\n",
    "    def __init__(self, sample_name, lookup_name, start_iter, percentile, buffer_size):\n",
    "        super().__init__(sample_name+'_sample', buffer_size, p_batch=0.)\n",
    "        self.start_iter = start_iter\n",
    "        self.percentile = percentile\n",
    "        self.sample_name = sample_name\n",
    "        self.lookup_name = lookup_name\n",
    "        \n",
    "    def build_buffer(self):\n",
    "        env = self.environment\n",
    "        iterations = self.environment.log.iterations\n",
    "        df = env.log.df\n",
    "        \n",
    "        outputs = self._build_buffer(iterations, df)\n",
    "        if outputs:\n",
    "            self.environment.buffer.add(outputs, self.name)\n",
    "                    \n",
    "    def _build_buffer(self, iterations, df):\n",
    "        outputs = []\n",
    "\n",
    "        if iterations > self.start_iter:\n",
    "            bs = self.buffer_size\n",
    "            if bs > 0:\n",
    "                \n",
    "                subset = df[df[self.lookup_name]>np.percentile(df[self.lookup_name].values, \n",
    "                                                               self.percentile)]\n",
    "                outputs = list(subset.sample(n=min(bs, subset.shape[0]))[self.sample_name].values)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "class TokenSwapSampler(LogSampler):\n",
    "    def __init__(self, sample_name, lookup_name, start_iter, percentile, buffer_size, \n",
    "                 vocab, swap_percent):\n",
    "        super().__init__(sample_name, lookup_name, start_iter, percentile, buffer_size)\n",
    "        self.name = sample_name+'_tokswap'\n",
    "        self.vocab = vocab\n",
    "        self.swap_percent = swap_percent\n",
    "        \n",
    "    def _build_buffer(self, iterations, log):\n",
    "        samples = super()._build_buffer(iterations, log)\n",
    "        \n",
    "        new_samples = []\n",
    "        \n",
    "        for sample in samples:\n",
    "            tokens = self.vocab.tokenize(sample)\n",
    "            num_swaps = int(self.swap_percent*len(tokens))\n",
    "            swap_idxs = np.random.choice(np.arange(len(tokens)), num_swaps, replace=False)\n",
    "            new_tokens = np.random.choice(self.vocab.itos, num_swaps, replace=True)\n",
    "            for idx, new_token in zip(swap_idxs, new_tokens):\n",
    "                tokens[idx] = new_token\n",
    "            \n",
    "            sample = self.vocab.join_tokens(tokens)\n",
    "            sample = self.vocab.postprocess(sample)\n",
    "            new_samples.append(sample)\n",
    "            \n",
    "        return new_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class LogEnumerator(LogSampler):\n",
    "    def __init__(self, sample_name, lookup_name, start_iter, percentile, \n",
    "                 buffer_size, atom_types=None):\n",
    "        super().__init__(sample_name, lookup_name, start_iter, percentile, buffer_size)\n",
    "\n",
    "        self.name = sample_name+'_enum'\n",
    "        if atom_types is None:\n",
    "            atom_types = ['C', 'N', 'O', 'F', 'S', 'Br', 'Cl', -1]\n",
    "            \n",
    "        self.atom_types = atom_types\n",
    "        \n",
    "    def _build_buffer(self, iterations, df):\n",
    "        samples = super()._build_buffer(iterations, df)\n",
    "        \n",
    "        new_samples = []\n",
    "        \n",
    "        for sample in samples:\n",
    "            \n",
    "            new_smiles = add_atom_combi(sample, self.atom_types) + add_bond_combi(sample)\n",
    "            new_smiles = [i for i in new_smiles if i is not None]\n",
    "            new_smiles = [i for i in new_smiles if not '.' in i]\n",
    "            new_samples += new_smiles\n",
    "\n",
    "        return new_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mrl)",
   "language": "python",
   "name": "mrl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
