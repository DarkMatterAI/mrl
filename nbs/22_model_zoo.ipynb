{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp model_zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Zoo\n",
    "\n",
    "> Standard Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmai/miniconda3/envs/mrl/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: to-Python converter for boost::shared_ptr<RDKit::FilterCatalogEntry const> already registered; second conversion method ignored.\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "from mrl.imports import *\n",
    "from mrl.core import *\n",
    "from mrl.chem import *\n",
    "from mrl.torch_imports import *\n",
    "from mrl.torch_core import *\n",
    "from mrl.layers import *\n",
    "from mrl.dataloaders import *\n",
    "from mrl.vocab import *\n",
    "from mrl.g_models import *\n",
    "from mrl.agent import *\n",
    "\n",
    "from torch.utils.model_zoo import load_url\n",
    "from torch.hub import download_url_to_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "\n",
    "S3_PREFIX = 'https://dmai-mrl.s3.amazonaws.com/mrl_public'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def lstm_lm_small(vocab, drop=True):\n",
    "    \n",
    "    d_vocab = len(vocab.itos)\n",
    "    bos_idx = vocab.stoi['bos']\n",
    "    d_embedding = 256\n",
    "    d_hidden = 1024\n",
    "    n_layers = 3\n",
    "    bidir = False\n",
    "    tie_weights = True\n",
    "    \n",
    "    if drop:\n",
    "        input_dropout = 0.3\n",
    "        lstm_dropout = 0.3\n",
    "    else:\n",
    "        input_dropout = 0.\n",
    "        lstm_dropout = 0.\n",
    "    \n",
    "    model = LSTM_LM(d_vocab, \n",
    "                    d_embedding,\n",
    "                    d_hidden, \n",
    "                    n_layers,\n",
    "                    input_dropout,\n",
    "                    lstm_dropout,\n",
    "                    bos_idx, \n",
    "                    bidir, \n",
    "                    tie_weights)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def lstm_lm_large(vocab, drop=True):\n",
    "    \n",
    "    d_vocab = len(vocab.itos)\n",
    "    bos_idx = vocab.stoi['bos']\n",
    "    d_embedding = 400\n",
    "    d_hidden = 1552\n",
    "    n_layers = 5\n",
    "    bidir = False\n",
    "    tie_weights = True\n",
    "    \n",
    "    \n",
    "    if drop:\n",
    "        input_dropout = 0.3\n",
    "        lstm_dropout = 0.3\n",
    "    else:\n",
    "        input_dropout = 0.\n",
    "        lstm_dropout = 0.\n",
    "    \n",
    "    model = LSTM_LM(d_vocab, \n",
    "                    d_embedding,\n",
    "                    d_hidden, \n",
    "                    n_layers,\n",
    "                    input_dropout,\n",
    "                    lstm_dropout,\n",
    "                    bos_idx, \n",
    "                    bidir, \n",
    "                    tie_weights)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = CharacterVocab(SMILES_CHAR_VOCAB)\n",
    "model = lstm_lm_small(vocab)\n",
    "assert isinstance(model, nn.Module)\n",
    "model = lstm_lm_large(vocab)\n",
    "assert isinstance(model, nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class LSTM_LM_Small_ZINC(GenerativeAgent):\n",
    "    def __init__(self, \n",
    "                 base_update=0.97, \n",
    "                 base_update_iter=5,\n",
    "                 base_model=True,\n",
    "                 opt_kwargs={},\n",
    "                 clip=1.,\n",
    "                 name = 'lstmlm_small_zinc'\n",
    "                ):\n",
    "        \n",
    "        vocab = CharacterVocab(SMILES_CHAR_VOCAB)\n",
    "        model = lstm_lm_small(vocab)\n",
    "        location = f'{S3_PREFIX}/lstmlm_small_zinc.pt'\n",
    "        model.load_state_dict(load_url(location, map_location='cpu'))\n",
    "        loss_function = CrossEntropy()\n",
    "        \n",
    "        dataset = Text_Dataset(['C'], vocab)\n",
    "        \n",
    "        \n",
    "        super().__init__(model,\n",
    "                         vocab, \n",
    "                         loss_function,\n",
    "                         dataset,\n",
    "                         base_update=base_update,\n",
    "                         base_update_iter=base_update_iter,\n",
    "                         base_model=base_model,\n",
    "                         opt_kwargs=opt_kwargs,\n",
    "                         clip=clip,\n",
    "                         name=name\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "\n",
    "agent = LSTM_LM_Small_ZINC()\n",
    "\n",
    "preds, _ = agent.model.sample_no_grad(100, 100)\n",
    "smiles = agent.reconstruct(preds)\n",
    "mols = to_mols(smiles)\n",
    "mols = [i for i in mols if i is not None]\n",
    "assert len(mols)>80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class LSTM_LM_Small_Chembl(GenerativeAgent):\n",
    "    def __init__(self, \n",
    "                 base_update=0.97, \n",
    "                 base_update_iter=5,\n",
    "                 base_model=True,\n",
    "                 opt_kwargs={},\n",
    "                 clip=1.,\n",
    "                 name = 'lstmlm_small_chembl'\n",
    "                ):\n",
    "        \n",
    "        vocab = CharacterVocab(SMILES_CHAR_VOCAB)\n",
    "        model = lstm_lm_small(vocab)\n",
    "        location = f'{S3_PREFIX}/lstmlm_small_chembl.pt'\n",
    "        model.load_state_dict(load_url(location, map_location='cpu'))\n",
    "        loss_function = CrossEntropy()\n",
    "        \n",
    "        dataset = Text_Dataset(['C'], vocab)\n",
    "        \n",
    "        \n",
    "        super().__init__(model,\n",
    "                         vocab, \n",
    "                         loss_function,\n",
    "                         dataset,\n",
    "                         base_update=base_update,\n",
    "                         base_update_iter=base_update_iter,\n",
    "                         base_model=base_model,\n",
    "                         opt_kwargs=opt_kwargs,\n",
    "                         clip=clip,\n",
    "                         name=name\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "\n",
    "agent = LSTM_LM_Small_Chembl()\n",
    "\n",
    "preds, _ = agent.model.sample_no_grad(100, 100)\n",
    "smiles = agent.reconstruct(preds)\n",
    "mols = to_mols(smiles)\n",
    "mols = [i for i in mols if i is not None]\n",
    "assert len(mols)>80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class LSTM_LM_Small_ZINC_NC(GenerativeAgent):\n",
    "    def __init__(self, \n",
    "                 base_update=0.97, \n",
    "                 base_update_iter=5,\n",
    "                 base_model=True,\n",
    "                 opt_kwargs={},\n",
    "                 clip=1.,\n",
    "                 name = 'lstmlm_small_zinc_nc'\n",
    "                ):\n",
    "        \n",
    "        vocab = CharacterVocab(SMILES_CHAR_VOCAB, prefunc=remove_stereo, postfunc=remove_stereo)\n",
    "        model = lstm_lm_small(vocab)\n",
    "        location = f'{S3_PREFIX}/lstmlm_small_zinc_nc.pt'\n",
    "        model.load_state_dict(load_url(location, map_location='cpu'))\n",
    "        loss_function = CrossEntropy()\n",
    "        \n",
    "        dataset = Text_Dataset(['C'], vocab)\n",
    "        \n",
    "        \n",
    "        super().__init__(model,\n",
    "                         vocab, \n",
    "                         loss_function,\n",
    "                         dataset,\n",
    "                         base_update=base_update,\n",
    "                         base_update_iter=base_update_iter,\n",
    "                         base_model=base_model,\n",
    "                         opt_kwargs=opt_kwargs,\n",
    "                         clip=clip,\n",
    "                         name=name\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "\n",
    "agent = LSTM_LM_Small_ZINC_NC()\n",
    "\n",
    "preds, _ = agent.model.sample_no_grad(100, 100)\n",
    "smiles = agent.reconstruct(preds)\n",
    "mols = to_mols(smiles)\n",
    "mols = [i for i in mols if i is not None]\n",
    "assert len(mols)>80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class LSTM_LM_Small_Chembl_NC(GenerativeAgent):\n",
    "    def __init__(self, \n",
    "                 base_update=0.97, \n",
    "                 base_update_iter=5,\n",
    "                 base_model=True,\n",
    "                 opt_kwargs={},\n",
    "                 clip=1.,\n",
    "                 name = 'lstmlm_small_chembl_nc'\n",
    "                ):\n",
    "        \n",
    "        vocab = CharacterVocab(SMILES_CHAR_VOCAB, prefunc=remove_stereo, postfunc=remove_stereo)\n",
    "        model = lstm_lm_small(vocab)\n",
    "        location = f'{S3_PREFIX}/lstmlm_small_chembl_nc.pt'\n",
    "        model.load_state_dict(load_url(location, map_location='cpu'))\n",
    "        loss_function = CrossEntropy()\n",
    "        \n",
    "        dataset = Text_Dataset(['C'], vocab)\n",
    "        \n",
    "        \n",
    "        super().__init__(model,\n",
    "                         vocab, \n",
    "                         loss_function,\n",
    "                         dataset,\n",
    "                         base_update=base_update,\n",
    "                         base_update_iter=base_update_iter,\n",
    "                         base_model=base_model,\n",
    "                         opt_kwargs=opt_kwargs,\n",
    "                         clip=clip,\n",
    "                         name=name\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "\n",
    "agent = LSTM_LM_Small_Chembl_NC()\n",
    "\n",
    "preds, _ = agent.model.sample_no_grad(100, 100)\n",
    "smiles = agent.reconstruct(preds)\n",
    "mols = to_mols(smiles)\n",
    "mols = [i for i in mols if i is not None]\n",
    "assert len(mols)>80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "        \n",
    "class LSTM_LM_Small_ZINC_Selfies(GenerativeAgent):\n",
    "    def __init__(self, \n",
    "                 base_update=0.97, \n",
    "                 base_update_iter=5,\n",
    "                 base_model=True,\n",
    "                 opt_kwargs={},\n",
    "                 clip=1.,\n",
    "                 name = 'lstmlm_small_zinc_selfies'\n",
    "                ):\n",
    "        \n",
    "        vocab = FuncVocab(SELFIES_VOCAB, split_selfie, \n",
    "                  prefunc=smile_to_selfie, postfunc=selfie_to_smile)\n",
    "        model = lstm_lm_small(vocab)\n",
    "        location = f'{S3_PREFIX}/lstmlm_small_zinc_selfies.pt'\n",
    "        model.load_state_dict(load_url(location, map_location='cpu'))\n",
    "        loss_function = CrossEntropy()\n",
    "        \n",
    "        dataset = Text_Dataset(['C'], vocab)\n",
    "        \n",
    "        \n",
    "        super().__init__(model,\n",
    "                         vocab, \n",
    "                         loss_function,\n",
    "                         dataset,\n",
    "                         base_update=base_update,\n",
    "                         base_update_iter=base_update_iter,\n",
    "                         base_model=base_model,\n",
    "                         opt_kwargs=opt_kwargs,\n",
    "                         clip=clip,\n",
    "                         name=name\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "\n",
    "agent = LSTM_LM_Small_ZINC_Selfies()\n",
    "\n",
    "preds, _ = agent.model.sample_no_grad(100, 100)\n",
    "smiles = agent.reconstruct(preds)\n",
    "mols = to_mols(smiles)\n",
    "mols = [i for i in mols if i is not None]\n",
    "assert len(mols)>80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "        \n",
    "class LSTM_LM_Small_Chembl_Selfies(GenerativeAgent):\n",
    "    def __init__(self, \n",
    "                 base_update=0.97, \n",
    "                 base_update_iter=5,\n",
    "                 base_model=True,\n",
    "                 opt_kwargs={},\n",
    "                 clip=1.,\n",
    "                 name = 'lstmlm_small_chembl_selfies'\n",
    "                ):\n",
    "        \n",
    "        vocab = FuncVocab(SELFIES_VOCAB, split_selfie, \n",
    "                  prefunc=smile_to_selfie, postfunc=selfie_to_smile)\n",
    "        model = lstm_lm_small(vocab)\n",
    "        location = f'{S3_PREFIX}/lstmlm_small_chembl_selfies.pt'\n",
    "        model.load_state_dict(load_url(location, map_location='cpu'))\n",
    "        loss_function = CrossEntropy()\n",
    "        \n",
    "        dataset = Text_Dataset(['C'], vocab)\n",
    "        \n",
    "        \n",
    "        super().__init__(model,\n",
    "                         vocab, \n",
    "                         loss_function,\n",
    "                         dataset,\n",
    "                         base_update=base_update,\n",
    "                         base_update_iter=base_update_iter,\n",
    "                         base_model=base_model,\n",
    "                         opt_kwargs=opt_kwargs,\n",
    "                         clip=clip,\n",
    "                         name=name\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow\n",
    "\n",
    "agent = LSTM_LM_Small_Chembl_Selfies()\n",
    "\n",
    "preds, _ = agent.model.sample_no_grad(100, 100)\n",
    "smiles = agent.reconstruct(preds)\n",
    "mols = to_mols(smiles)\n",
    "mols = [i for i in mols if i is not None]\n",
    "assert len(mols)>80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional LSTM LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def cond_lstm_small(vocab, encoder, drop=True):\n",
    "    \n",
    "    d_vocab = len(vocab.itos)\n",
    "    bos_idx = vocab.stoi['bos']\n",
    "    \n",
    "    d_latent = 512\n",
    "    d_embedding = 256\n",
    "    d_hidden = 1024\n",
    "    n_layers = 3\n",
    "    bidir = False\n",
    "    tie_weights = True\n",
    "    condition_hidden = True\n",
    "    condition_output = False\n",
    "    norm_latent = True\n",
    "    \n",
    "    if drop:\n",
    "        input_dropout = 0.3\n",
    "        lstm_dropout = 0.3\n",
    "    else:\n",
    "        input_dropout = 0.\n",
    "        lstm_dropout = 0.\n",
    "    \n",
    "    model = Conditional_LSTM_LM(encoder, \n",
    "                                d_vocab, \n",
    "                                d_embedding, \n",
    "                                d_hidden, \n",
    "                                d_latent, \n",
    "                                n_layers,\n",
    "                                input_dropout, \n",
    "                                lstm_dropout, \n",
    "                                norm_latent, \n",
    "                                condition_hidden, \n",
    "                                condition_output, \n",
    "                                bos_idx)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def cond_lstm_large(vocab, encoder, drop=True):\n",
    "\n",
    "    d_vocab = len(vocab.itos)\n",
    "    bos_idx = vocab.stoi['bos']\n",
    "    \n",
    "    d_latent = 512\n",
    "    d_embedding = 400\n",
    "    d_hidden = 1552\n",
    "    n_layers = 5\n",
    "    bidir = False\n",
    "    tie_weights = True\n",
    "    condition_hidden = True\n",
    "    condition_output = False\n",
    "    norm_latent = True\n",
    "    \n",
    "    \n",
    "    if drop:\n",
    "        input_dropout = 0.3\n",
    "        lstm_dropout = 0.3\n",
    "    else:\n",
    "        input_dropout = 0.\n",
    "        lstm_dropout = 0.\n",
    "    \n",
    "    model = Conditional_LSTM_LM(encoder, \n",
    "                                d_vocab, \n",
    "                                d_embedding, \n",
    "                                d_hidden, \n",
    "                                d_latent, \n",
    "                                n_layers,\n",
    "                                input_dropout, \n",
    "                                lstm_dropout, \n",
    "                                norm_latent, \n",
    "                                condition_hidden, \n",
    "                                condition_output, \n",
    "                                bos_idx)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def mlp_cond_lstm_small(vocab, drop=True):\n",
    "    if drop:\n",
    "        enc_drops = [0.1, 0.1]\n",
    "    else:\n",
    "        enc_drops = [0., 0.]\n",
    "        \n",
    "    encoder = MLP_Encoder(2048, [1024, 512], 512, enc_drops)\n",
    "    return cond_lstm_small(vocab, encoder, drop=drop)\n",
    "\n",
    "def mlp_cond_lstm_large(vocab, drop=True):\n",
    "    if drop:\n",
    "        enc_drops = [0.2, 0.2, 0.2, 0.2]\n",
    "    else:\n",
    "        enc_drops = [0., 0., 0., 0.]\n",
    "    \n",
    "    encoder = MLP_Encoder(2048, [1024, 512, 512, 512], 512, [0.2, 0.2, 0.2, 0.2])\n",
    "    return cond_lstm_small(vocab, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = CharacterVocab(SMILES_CHAR_VOCAB)\n",
    "model = mlp_cond_lstm_small(vocab)\n",
    "assert isinstance(model, nn.Module)\n",
    "model = mlp_cond_lstm_large(vocab)\n",
    "assert isinstance(model, nn.Module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def mlp_vae(vocab, drop=True):\n",
    "    \n",
    "    d_vocab = len(vocab.itos)\n",
    "    bos_idx = vocab.stoi['bos']\n",
    "    \n",
    "    d_embedding = 256\n",
    "    encoder_d_in = 2048\n",
    "    encoder_dims = [1024, 512]\n",
    "    d_hidden = 1024\n",
    "    n_layers = 3\n",
    "    d_latent =512\n",
    "    condition_hidden=True\n",
    "    condition_output=True\n",
    "    \n",
    "    if drop:\n",
    "        encoder_drops = [0.2, 0.2]\n",
    "        input_dropout=0.3\n",
    "        lstm_dropout=0.3\n",
    "    else:\n",
    "        encoder_drops = [0., 0.]\n",
    "        input_dropout=0.\n",
    "        lstm_dropout=0.\n",
    "\n",
    "    model = MLP_VAE(\n",
    "                d_vocab,\n",
    "                d_embedding,\n",
    "                encoder_d_in,\n",
    "                encoder_dims,\n",
    "                encoder_drops,\n",
    "                d_hidden,\n",
    "                n_layers,\n",
    "                d_latent,\n",
    "                input_dropout=input_dropout,\n",
    "                lstm_dropout=lstm_dropout,\n",
    "                condition_hidden=condition_hidden,\n",
    "                condition_output=condition_output,\n",
    "                bos_idx=bos_idx,\n",
    "            )\n",
    "    \n",
    "    return model\n",
    "    \n",
    "def conv_vae(vocab, drop=True):\n",
    "    \n",
    "    d_vocab = len(vocab.itos)\n",
    "    bos_idx = vocab.stoi['bos']\n",
    "    \n",
    "    d_embedding = 256\n",
    "    conv_filters = [256, 512, 512]\n",
    "    kernel_sizes = [7, 7, 7]\n",
    "    strides = [2, 2, 2]\n",
    "    d_hidden = 1024\n",
    "    n_layers = 3\n",
    "    d_latent = 512\n",
    "    condition_hidden=True\n",
    "    condition_output=True\n",
    "    \n",
    "    if drop:\n",
    "        conv_drops = [0.2, 0.2, 0.2]\n",
    "        input_dropout=0.3\n",
    "        lstm_dropout=0.3\n",
    "    else:\n",
    "        conv_drops = [0., 0., 0.]\n",
    "        input_dropout=0.\n",
    "        lstm_dropout=0.\n",
    "    \n",
    "    model = Conv_VAE(\n",
    "                    d_vocab,\n",
    "                    d_embedding,\n",
    "                    conv_filters,\n",
    "                    kernel_sizes,\n",
    "                    strides,\n",
    "                    conv_drops,\n",
    "                    d_hidden,\n",
    "                    n_layers,\n",
    "                    d_latent,\n",
    "                    input_dropout=input_dropout,\n",
    "                    lstm_dropout=lstm_dropout,\n",
    "                    condition_hidden=condition_hidden,\n",
    "                    condition_output=condition_output,\n",
    "                    bos_idx=bos_idx)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "def lstm_vae(vocab, drop=True):\n",
    "    \n",
    "    d_vocab = len(vocab.itos)\n",
    "    bos_idx = vocab.stoi['bos']\n",
    "    \n",
    "    d_embedding = 256\n",
    "    d_hidden = 1024\n",
    "    n_layers = 3\n",
    "    d_latent = 512\n",
    "    condition_hidden=True\n",
    "    condition_output=True\n",
    "    \n",
    "    if drop:\n",
    "        input_dropout=0.3\n",
    "        lstm_dropout=0.3\n",
    "    else:\n",
    "        input_dropout=0.\n",
    "        lstm_dropout=0.\n",
    "\n",
    "    \n",
    "    model = LSTM_VAE(\n",
    "                    d_vocab,\n",
    "                    d_embedding,\n",
    "                    d_hidden,\n",
    "                    n_layers,\n",
    "                    d_latent,\n",
    "                    input_dropout=input_dropout,\n",
    "                    lstm_dropout=lstm_dropout,\n",
    "                    condition_hidden=condition_hidden,\n",
    "                    condition_output=condition_output,\n",
    "                    bos_idx=bos_idx,\n",
    "                )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = CharacterVocab(SMILES_CHAR_VOCAB)\n",
    "model = mlp_vae(vocab)\n",
    "assert isinstance(model, nn.Module)\n",
    "model = conv_vae(vocab)\n",
    "assert isinstance(model, nn.Module)\n",
    "model = lstm_vae(vocab)\n",
    "assert isinstance(model, nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mrl)",
   "language": "python",
   "name": "mrl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
