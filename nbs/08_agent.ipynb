{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3172110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cfcec1",
   "metadata": {},
   "source": [
    "# Agent\n",
    "\n",
    "> Base Agent class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5285fa8e",
   "metadata": {},
   "source": [
    "Agent holds a model, a reference model, vocab and dataset. agent handles getting log probs, reconstructing model outputs, and supervised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dbe6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db47f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from mrl.imports import *\n",
    "from mrl.core import *\n",
    "from mrl.torch_imports import *\n",
    "from mrl.torch_core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b14b0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self, model, loss_function, dataset, opt_kwargs={}):\n",
    "        self.model = model\n",
    "            \n",
    "        to_device(self.model)\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.opt = self.get_opt(self.model, **opt_kwargs)\n",
    "        self.loss_function = loss_function\n",
    "        \n",
    "    def get_opt(self, model, **optim_kwargs):\n",
    "        return optim.Adam(model.parameters(), **optim_kwargs)\n",
    "    \n",
    "    def one_batch(self, batch):\n",
    "        x,y = batch\n",
    "        if not type(x)==list:\n",
    "            x = [x]\n",
    "        output = self.model(*x)\n",
    "        loss = self.loss_function(output, y)\n",
    "        return loss\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        self.opt.zero_grad()\n",
    "        \n",
    "    def step(self):\n",
    "        self.opt.step()\n",
    "    \n",
    "    def train_supervised(self, bs, epochs, lr, percent_valid=0.05):\n",
    "        \n",
    "        train_ds, valid_ds = self.dataset.split(percent_valid)\n",
    "        \n",
    "        train_dl = train_ds.dataloader(bs, shuffle=True)\n",
    "        valid_dl = valid_ds.dataloader(bs)\n",
    "        \n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(self.opt, max_lr=lr,\n",
    "                                                 steps_per_epoch=len(train_dl), epochs=10)\n",
    "\n",
    "        mb = master_bar(range(epochs))\n",
    "        mb.write(['Epoch', 'Train Loss', 'Valid  Loss', 'Time'], table=True)\n",
    "        for epoch in mb:\n",
    "            start = time.time()\n",
    "            train_losses = []\n",
    "            \n",
    "            for batch in progress_bar(train_dl, parent=mb):\n",
    "                \n",
    "                loss = self.one_batch(batch)\n",
    "\n",
    "                self.zero_grad()\n",
    "                loss.backward()\n",
    "                self.step()\n",
    "                scheduler.step()\n",
    "                train_losses.append(loss.detach().cpu())\n",
    "                mb.child.comment = f\"{train_losses[-1]:.5f}\"\n",
    "                \n",
    "            with torch.no_grad():\n",
    "                valid_losses = []\n",
    "                for batch in progress_bar(valid_dl, parent=mb):\n",
    "\n",
    "                    loss = self.one_batch(batch)\n",
    "                    valid_losses.append(loss.detach().cpu())\n",
    "                    mb.child.comment = f\"{valid_losses[-1]:.5f}\"\n",
    "                    \n",
    "            train_loss = smooth_batches(train_losses)\n",
    "            valid_loss = smooth_batches(valid_losses)\n",
    "            end = time.time() - start\n",
    "            mb.write([epoch, f'{train_losses[-1]:.5f}', \n",
    "                      f'{valid_losses[-1]:.5f}', f'{format_time(end)}'], table=True)\n",
    "    \n",
    "    def update_dataset(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    def update_dataset_from_inputs(self, *dataset_inputs):\n",
    "        dataset = self.dataset.new(*dataset_inputs)\n",
    "        self.update_dataset(dataset)\n",
    "    \n",
    "    def load_weights(self, filename):\n",
    "        state_dict = torch.load(filename, map_location=get_model_device(self.model))\n",
    "        \n",
    "        self.model.load_state_dict(state_dict)\n",
    "\n",
    "    def save_weights(self, filename):\n",
    "        \n",
    "        state_dict = self.base_model.state_dict()\n",
    "        torch.save(state_dict, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d29d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "        \n",
    "class PredictiveAgent(Agent):\n",
    "    \n",
    "    def predict_tensor(self, x):\n",
    "        if not type(x)==list:\n",
    "            x = [x]\n",
    "        output = self.model(*x)\n",
    "        \n",
    "    def predict_data(self, data):\n",
    "        ds = self.dataset.new(data, [0 for i in data])\n",
    "        batch = ds.collate_function([ds[i] for i in range(len(ds))])\n",
    "        x,y = batch\n",
    "        return self.predict_tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da13d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class GenerativeAgent(Agent):\n",
    "    def __init__(self, model, vocab, loss_function, dataset, \n",
    "                 base_model=True, value_head=None, latents=None,\n",
    "                 opt_kwargs={}, vopt_kwargs={}, lopt_kwargs={}):\n",
    "        super().__init__(model, loss_function, dataset, opt_kwargs)\n",
    "                \n",
    "        if base_model==True:\n",
    "            self.base_model = copy.deepcopy(model)\n",
    "        else:\n",
    "            self.base_model = base_model\n",
    "            \n",
    "        to_device(self.model)\n",
    "        to_device(self.base_model)\n",
    "        \n",
    "        self.vocab = vocab\n",
    "        self.value_head = value_head\n",
    "        self.latents = latents\n",
    "        \n",
    "        self.opts = [self.opt]\n",
    "        if self.value_head is not None:\n",
    "            to_device(self.value_head)\n",
    "            self.value_opt = self.get_opt(self.value_head, **vopt_kwargs)\n",
    "            self.opts.append(self.value_opt)\n",
    "            \n",
    "        if self.latents is not None:\n",
    "            to_device(self.latents)\n",
    "            self.latent_opt = self.get_opt(self.latents, **lopt_kwargs)\n",
    "            self.opts.append(self.latent_opt)\n",
    "            \n",
    "    def zero_grad(self):\n",
    "        for opt in self.opts:\n",
    "            opt.zero_grad()\n",
    "            \n",
    "    def step(self):\n",
    "        for opt in self.opts:\n",
    "            opt.step()\n",
    "    \n",
    "    def reconstruct(self, preds):\n",
    "        return maybe_parallel(self.vocab.reconstruct, [i for i in preds.detach().cpu()])\n",
    "    \n",
    "    def load_weights(self, filename, base=False):\n",
    "        state_dict = torch.load(filename, map_location=get_model_device(self.model))\n",
    "        \n",
    "        if 'value_head' in state_dict.keys():\n",
    "            value_state = state_dict['value_head']\n",
    "            state_dict = state_dict['model']\n",
    "            if not base:\n",
    "                self.value_head.load_state_dict(value_state)\n",
    "        \n",
    "        if not base:\n",
    "            self.model.load_state_dict(state_dict)\n",
    "        else:\n",
    "            if not isinstance(self.base_model, nn.Module):\n",
    "                self.base_model = copy.deepcopy(model)\n",
    "            \n",
    "            self.base_model.load_state_dict(state_dict)\n",
    "\n",
    "    def save_weights(self, filename, base=False):\n",
    "        \n",
    "        if base:\n",
    "            state_dict = self.base_model.state_dict()\n",
    "        else:\n",
    "            state_dict = self.model.state_dict()\n",
    "            \n",
    "        if self.value_head is not None:\n",
    "            value_state = self.value_head.state_dict()\n",
    "        else:\n",
    "            value_state = None\n",
    "            \n",
    "        state_dict = {'model':state_dict, 'value_head':value_state}    \n",
    "            \n",
    "        torch.save(state_dict, filename)\n",
    "        \n",
    "    def get_batch_params(self, model_output):\n",
    "        x = model_output['x']\n",
    "        y = model_output['y']\n",
    "        mask = ~(y==self.vocab.stoi['pad'])\n",
    "        lengths = mask.sum(-1)\n",
    "        sl = y.shape[-1]\n",
    "        smiles = self.reconstruct(y)\n",
    "        \n",
    "        model_output['mask'] = mask\n",
    "        model_output['lengths'] = lengths\n",
    "        model_output['sl'] = sl\n",
    "        model_output['sequences'] = smiles\n",
    "        \n",
    "        return model_output\n",
    "        \n",
    "    \n",
    "    def get_model_outputs(self, model_output):\n",
    "        x = model_output['x']\n",
    "        y = model_output['y']\n",
    "        latent = model_output['latent']\n",
    "        mo, mlp, mglp, me = self.model.get_rl_tensors(x,y,latent=latent)\n",
    "        mprob = mlp.exp()\n",
    "    \n",
    "        model_output['model_output'] = mo\n",
    "        model_output['model_logprobs'] = mlp\n",
    "        model_output['model_gathered_logprobs'] = mglp\n",
    "        model_output['model_encoded'] = me\n",
    "        model_output['y_gumbel'] = F.one_hot(y, len(self.vocab.itos)) + mprob - mprob.detach()\n",
    "        \n",
    "        if self.value_head is not None:\n",
    "            value_predictions = self.value_head(me)\n",
    "        else:\n",
    "            value_predictions = None\n",
    "            \n",
    "        model_output['state_values'] = value_predictions\n",
    "        \n",
    "        if self.base_model is not None:\n",
    "            with torch.no_grad():\n",
    "                bo, blp, bglp, be = self.base_model.get_rl_tensors(x,y)\n",
    "        else:\n",
    "            bo, blp, bglp, be = None, None, None, None\n",
    "\n",
    "        model_output['reference_output'] = bo\n",
    "        model_output['reference_logprobs'] = blp\n",
    "        model_output['reference_gathered_logprobs'] = bglp\n",
    "        model_output['reference_encoded'] = be\n",
    "    \n",
    "        return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb9f6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class ModelOutput(dict):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.__setitem__('sequences', [])                      # buffer/batch\n",
    "        self.__setitem__('mols', [])                           # buffer/batch\n",
    "        self.__setitem__('source', [])                         # buffer/batch\n",
    "        self.__setitem__('x', None)                            # buffer/batch\n",
    "        self.__setitem__('y', None)                            # buffer/batch\n",
    "        self.__setitem__('mask', None)                         # buffer/batch\n",
    "        self.__setitem__('lengths', None)                      # buffer/batch\n",
    "        self.__setitem__('sl', None)                           # buffer/batch\n",
    "        self.__setitem__('model_output', None)                 # model\n",
    "        self.__setitem__('model_encoded', None)                # model\n",
    "        self.__setitem__('model_logprobs', None)               # model\n",
    "        self.__setitem__('model_gathered_logprobs', None)      # model\n",
    "        self.__setitem__('y_gumbel', None)                     # agent\n",
    "        self.__setitem__('latent', None)                       # agent\n",
    "        self.__setitem__('state_values', None)                 # agent value_head\n",
    "        self.__setitem__('reference_output', None)             # reference model\n",
    "        self.__setitem__('reference_encoded', None)            # reference model\n",
    "        self.__setitem__('reference_logprobs', None)           # reference model\n",
    "        self.__setitem__('reference_gathered_logprobs', None)  # reference model\n",
    "        self.__setitem__('rewards', None)                      # reward function\n",
    "        self.__setitem__('rewards_dict', {})                   # reward function\n",
    "        self.__setitem__('rewards_scaled', None)               # reward function\n",
    "        self.__setitem__('trajectory_rewards', None)           # trajectory reward function\n",
    "        self.__setitem__('losses',     {'pg_loss' : None,\n",
    "                                       'diff_loss' : None})\n",
    "        self.__setitem__('loss_dicts', {'pg_dict' : {},\n",
    "                                        'diff_dict' : {}})\n",
    "\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a224b848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eff190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3472b366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
