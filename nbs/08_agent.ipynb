{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cbe154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b693ce36",
   "metadata": {},
   "source": [
    "# Agent\n",
    "\n",
    "> Base Agent class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3eecd0",
   "metadata": {},
   "source": [
    "Agent holds a model, a reference model, vocab and dataset. agent handles getting log probs, reconstructing model outputs, and supervised training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0071c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcced49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from mrl.imports import *\n",
    "from mrl.core import *\n",
    "from mrl.torch_imports import *\n",
    "from mrl.torch_core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db03d485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "# export\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self, model, vocab, loss_function, dataset, base_model=True):\n",
    "        self.model = model\n",
    "        \n",
    "        if base_model==True:\n",
    "            self.base_model = copy.deepcopy(model)\n",
    "        else:\n",
    "            self.base_model = base_model\n",
    "            \n",
    "        to_device(self.model)\n",
    "        to_device(self.base_model)\n",
    "        \n",
    "        self.vocab = vocab\n",
    "        self.dataset = dataset\n",
    "        self.opt = self.get_opt()\n",
    "        self.loss_function = loss_function\n",
    "        \n",
    "    def get_opt(self, **optim_kwargs):\n",
    "        return optim.Adam(self.model.parameters(), **optim_kwargs)\n",
    "    \n",
    "    def one_batch(self, batch):\n",
    "        x,y = batch\n",
    "        if not type(x)==list:\n",
    "            x = [x]\n",
    "        output = self.model(*x)\n",
    "        loss = self.loss_function(output, y)\n",
    "        return loss\n",
    "    \n",
    "    def train_supervised(self, bs, epochs, lr, percent_valid=0.05):\n",
    "        \n",
    "        train_ds, valid_ds = self.dataset.split(percent_valid)\n",
    "        \n",
    "        train_dl = train_ds.dataloader(bs)\n",
    "        valid_dl = valid_ds.dataloader(bs)\n",
    "        \n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(self.opt, max_lr=lr,\n",
    "                                                 steps_per_epoch=len(train_dl), epochs=10)\n",
    "\n",
    "        mb = master_bar(range(epochs))\n",
    "        mb.write(['Epoch', 'Train Loss', 'Valid  Loss', 'Time'], table=True)\n",
    "        for epoch in mb:\n",
    "            start = time.time()\n",
    "            train_losses = []\n",
    "            \n",
    "            for batch in progress_bar(train_dl, parent=mb):\n",
    "                \n",
    "                loss = self.one_batch(batch)\n",
    "\n",
    "                self.opt.zero_grad()\n",
    "                loss.backward()\n",
    "                self.opt.step()\n",
    "                scheduler.step()\n",
    "                train_losses.append(loss.detach().cpu())\n",
    "                mb.child.comment = f\"{train_losses[-1]:.5f}\"\n",
    "                \n",
    "            with torch.no_grad():\n",
    "                valid_losses = []\n",
    "                for batch in progress_bar(valid_dl, parent=mb):\n",
    "\n",
    "                    loss = self.one_batch(batch)\n",
    "                    valid_losses.append(loss.detach().cpu())\n",
    "                    mb.child.comment = f\"{valid_losses[-1]:.5f}\"\n",
    "                    \n",
    "            train_loss = smooth_batches(train_losses)\n",
    "            valid_loss = smooth_batches(valid_losses)\n",
    "            end = time.time() - start\n",
    "            mb.write([epoch, f'{train_losses[-1]:.5f}', \n",
    "                      f'{valid_losses[-1]:.5f}', f'{format_time(end)}'], table=True)\n",
    "    \n",
    "    def update_dataset(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    def update_dataset_from_inputs(self, *dataset_inputs):\n",
    "        dataset = self.dataset.new(*dataset_inputs)\n",
    "        self.update_dataset(dataset)\n",
    "    \n",
    "    def reconstruct(self, preds):\n",
    "        return maybe_parallel(self.vocab.reconstruct, preds)\n",
    "    \n",
    "    def load_weights(self, filename, base=False):\n",
    "        state_dict = torch.load(filename, map_location=self.model.device)\n",
    "        \n",
    "        if not base:\n",
    "            self.model.load_state_dict(state_dict)\n",
    "        else:\n",
    "            if not isinstance(self.base_model, nn.Module):\n",
    "                self.base_model = copy.deepcopy(model)\n",
    "            \n",
    "            self.base_model.load_state_dict(state_dict)\n",
    "\n",
    "    def save_weights(self, filename, base=False):\n",
    "        \n",
    "        if base:\n",
    "            state_dict = self.base_model.state_dict()\n",
    "        else:\n",
    "            state_dict = self.model.state_dict()\n",
    "            \n",
    "        torch.save(state_dict, filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65615423",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
