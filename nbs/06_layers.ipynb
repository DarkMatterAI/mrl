{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers\n",
    "\n",
    "> Pytorch model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from mrl.imports import *\n",
    "from mrl.torch_imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, d_in, d_out, act=True, bn=False, dropout=0.):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = [nn.Linear(d_in, d_out)]\n",
    "        \n",
    "        if bn:\n",
    "            layers.append(nn.BatchNorm1d(d_out))\n",
    "            \n",
    "        if act:\n",
    "            layers.append(nn.ReLU())\n",
    "            \n",
    "        if dropout>0.:\n",
    "            layers.append(nn.Dropout(p=dropout))\n",
    "            \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class LSTMBase(nn.Module):\n",
    "    def __init__(self, d_vocab, d_embedding, d_hidden, n_layers, pad_idx, \n",
    "                 lstm_drop=0.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_vocab = d_vocab\n",
    "        self.d_embedding = d_embedding\n",
    "        self.d_hidden = d_hidden\n",
    "        self.n_layers = n_layers\n",
    "        self.pad_idx = pad_idx\n",
    "        \n",
    "        self.embedding = nn.Embedding(d_vocab, d_embedding, padding_idx=pad_idx)\n",
    "        \n",
    "        self.lstms = []\n",
    "        \n",
    "        for i in range(n_layers):\n",
    "            input_size = d_embedding if i==0 else d_hidden\n",
    "            output_size = d_embedding if i==n_layers-1 else d_hidden\n",
    "                \n",
    "            lstm = nn.LSTM(input_size, output_size, 1, batch_first=True, dropout=lstm_drop)\n",
    "            self.lstms.append(lstm)\n",
    "            \n",
    "        self.lstms = nn.ModuleList(self.lstms)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        hiddens = []\n",
    "        for i, lstm in enumerate(self.lstms):\n",
    "            x, (h,c) = lstm(x)\n",
    "            hiddens.append((h.detach(), c.detach()))\n",
    "        \n",
    "        self.last_hiddens = hiddens\n",
    "\n",
    "        return x\n",
    "    \n",
    "# class LMHead(nn.Module):\n",
    "#     def __init__(self, d_in, d_out):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.layer = nn.Linear(d_in, d_out)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrl.dataloaders import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('files/smiles.csv')\n",
    "df = next(pd.read_csv('../../ZINC_shards_shuffled/shard_0.csv', chunksize=10000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.smiles.map(lambda x: len(x))<100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>zinc_id</th>\n",
       "      <th>inchikey</th>\n",
       "      <th>mwt</th>\n",
       "      <th>logp</th>\n",
       "      <th>reactive</th>\n",
       "      <th>purchasable</th>\n",
       "      <th>tranche_name</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O=C(NCc1ccc(Br)cc1F)C(=O)NCC1(Cc2ccccc2)CC1</td>\n",
       "      <td>ZINC000807669219</td>\n",
       "      <td>RPRBOANYNLBELV-UHFFFAOYSA-N</td>\n",
       "      <td>419.294</td>\n",
       "      <td>3.344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>HGAD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C[C@@H](NC(=O)[C@@H]1CCc2nccn2C1)C1CN(Cc2cncn2...</td>\n",
       "      <td>ZINC000969991574</td>\n",
       "      <td>GDQMPQCGXNSNHF-ZIAGYGMSSA-N</td>\n",
       "      <td>342.447</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>ECAD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C[C@@H](c1ccccc1F)N(C)c1nnc(CC(C)(C)C)n1CCNS(=...</td>\n",
       "      <td>ZINC001541788850</td>\n",
       "      <td>ALRPTKPQPMHISQ-INIZCTEOSA-N</td>\n",
       "      <td>478.594</td>\n",
       "      <td>3.311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>JGAD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O=C(Cc1ccccc1Cl)N1CC(NC(=O)[C@@H]2C[C@@H]3CCCC...</td>\n",
       "      <td>ZINC000997656351</td>\n",
       "      <td>BFXLNUTXWTYLSO-RRQGHBQHSA-N</td>\n",
       "      <td>360.885</td>\n",
       "      <td>3.036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>FGAD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cn1[nH]c(CN2C[C@H]3CC[C@H]2CN3C(=O)[C@H]2CCNC(...</td>\n",
       "      <td>ZINC000971263820</td>\n",
       "      <td>JZUXMQSAMSOURF-SDDRHHMPSA-N</td>\n",
       "      <td>348.407</td>\n",
       "      <td>-1.190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>EAAD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles           zinc_id  \\\n",
       "0        O=C(NCc1ccc(Br)cc1F)C(=O)NCC1(Cc2ccccc2)CC1  ZINC000807669219   \n",
       "1  C[C@@H](NC(=O)[C@@H]1CCc2nccn2C1)C1CN(Cc2cncn2...  ZINC000969991574   \n",
       "2  C[C@@H](c1ccccc1F)N(C)c1nnc(CC(C)(C)C)n1CCNS(=...  ZINC001541788850   \n",
       "3  O=C(Cc1ccccc1Cl)N1CC(NC(=O)[C@@H]2C[C@@H]3CCCC...  ZINC000997656351   \n",
       "4  Cn1[nH]c(CN2C[C@H]3CC[C@H]2CN3C(=O)[C@H]2CCNC(...  ZINC000971263820   \n",
       "\n",
       "                      inchikey      mwt   logp  reactive  purchasable  \\\n",
       "0  RPRBOANYNLBELV-UHFFFAOYSA-N  419.294  3.344       0.0         20.0   \n",
       "1  GDQMPQCGXNSNHF-ZIAGYGMSSA-N  342.447  0.816       0.0         20.0   \n",
       "2  ALRPTKPQPMHISQ-INIZCTEOSA-N  478.594  3.311       0.0         20.0   \n",
       "3  BFXLNUTXWTYLSO-RRQGHBQHSA-N  360.885  3.036       0.0         20.0   \n",
       "4  JZUXMQSAMSOURF-SDDRHHMPSA-N  348.407 -1.190       0.0         20.0   \n",
       "\n",
       "  tranche_name features  \n",
       "0         HGAD      NaN  \n",
       "1         ECAD      NaN  \n",
       "2         JGAD      NaN  \n",
       "3         FGAD      NaN  \n",
       "4         EAAD      NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = CharacterVocab(SMILES_CHAR_VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df.sample(frac=0.98)\n",
    "valid_data = df[~(df.index.isin(train_data.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TextDataset(train_data.smiles.values, vocab)\n",
    "valid_ds = TextDataset(valid_data.smiles.values, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = train_ds.dataloader(96, num_workers=0)\n",
    "valid_dl = valid_ds.dataloader(96, num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102077"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMLM(nn.Module):\n",
    "    def __init__(self, d_vocab, d_embedding, d_hidden, n_layers, pad_idx, lstm_drop=0.):\n",
    "        super().__init__()\n",
    "        self.base = LSTMBase(d_vocab, d_embedding, d_hidden, n_layers, pad_idx, lstm_drop)\n",
    "        self.head = Linear(d_embedding, d_vocab, act=False, bn=False, dropout=0.)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMLM(len(vocab.itos), 256, 1024, 3, vocab.stoi['pad'])\n",
    "# encoder = AWD_LSTM(len(vocab.itos), 256, 1024, 3, vocab.stoi['pad'])\n",
    "# decoder = LinearDecoder(len(vocab.itos), 256, 0., tie_encoder=False, bias=True)\n",
    "# model = SequentialRNN(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoaders(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = Learner(dl, model, loss_func=CrossEntropyLossFlat(), cbs=[ModelResetter(), RNNCallback()])\n",
    "learn = Learner(dl, model, loss_func=CrossEntropyLossFlat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.005754399299621582, lr_steep=0.0012022644514217973)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.317389</td>\n",
       "      <td>0.317360</td>\n",
       "      <td>4:06:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.300273</td>\n",
       "      <td>0.300688</td>\n",
       "      <td>4:08:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(2, 3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('models/lstm1.pth')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.save('lstm1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.356515</td>\n",
       "      <td>0.356407</td>\n",
       "      <td>12:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.331074</td>\n",
       "      <td>0.332720</td>\n",
       "      <td>12:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.312755</td>\n",
       "      <td>0.316965</td>\n",
       "      <td>12:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.301957</td>\n",
       "      <td>0.311658</td>\n",
       "      <td>12:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(4, 3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.5)\n",
    "sched = torch.optim.lr_scheduler.OneCycleLR(opt, 3e-3, total_steps=len(train_dl)*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(1.7611)\n",
      "tensor(1.4714)\n",
      "tensor(1.0725)\n",
      "tensor(0.8579)\n",
      "tensor(0.7714)\n",
      "tensor(0.6974)\n",
      "tensor(0.6446)\n",
      "tensor(0.6038)\n",
      "tensor(0.5761)\n",
      "tensor(0.5557)\n",
      "tensor(0.5363)\n",
      "tensor(0.5197)\n",
      "tensor(0.4988)\n",
      "tensor(0.4862)\n",
      "tensor(0.4780)\n",
      "tensor(0.4592)\n",
      "tensor(0.4567)\n",
      "tensor(0.4506)\n",
      "tensor(0.4499)\n",
      "tensor(0.4467)\n",
      "tensor(0.4278)\n",
      "tensor(0.4210)\n",
      "tensor(0.4169)\n",
      "tensor(0.4187)\n",
      "tensor(0.4169)\n",
      "tensor(0.4191)\n",
      "tensor(0.4122)\n",
      "tensor(0.4050)\n",
      "tensor(0.4041)\n",
      "tensor(0.4046)\n",
      "tensor(0.3974)\n",
      "tensor(0.4041)\n",
      "tensor(0.3977)\n",
      "tensor(0.3945)\n",
      "tensor(0.3891)\n",
      "tensor(0.3880)\n",
      "tensor(0.3958)\n",
      "tensor(0.3902)\n",
      "tensor(0.3875)\n",
      "tensor(0.3820)\n",
      "tensor(0.3847)\n",
      "tensor(0.3835)\n",
      "tensor(0.3829)\n",
      "tensor(0.3711)\n",
      "tensor(0.3737)\n",
      "tensor(0.3786)\n",
      "tensor(0.3775)\n",
      "tensor(0.3751)\n",
      "tensor(0.3789)\n",
      "tensor(0.3665)\n",
      "tensor(0.3752)\n",
      "tensor(0.3796)\n",
      "tensor(0.3762)\n",
      "tensor(0.3712)\n",
      "tensor(0.3763)\n",
      "tensor(0.3688)\n",
      "tensor(0.3646)\n",
      "tensor(0.3705)\n",
      "tensor(0.3683)\n",
      "tensor(0.3676)\n",
      "tensor(0.3674)\n",
      "tensor(0.3699)\n",
      "tensor(0.3675)\n",
      "tensor(0.3698)\n",
      "tensor(0.3696)\n",
      "tensor(0.3668)\n",
      "tensor(0.3680)\n",
      "tensor(0.3694)\n",
      "tensor(0.3702)\n",
      "tensor(0.3738)\n",
      "tensor(0.3702)\n",
      "tensor(0.3646)\n",
      "tensor(0.3636)\n",
      "tensor(0.3686)\n",
      "Valid loss: 0.3691312074661255\n",
      "1\n",
      "tensor(0.3681)\n",
      "tensor(0.3731)\n",
      "tensor(0.3711)\n",
      "tensor(0.3642)\n",
      "tensor(0.3728)\n",
      "tensor(0.3696)\n",
      "tensor(0.3688)\n",
      "tensor(0.3697)\n",
      "tensor(0.3713)\n",
      "tensor(0.3729)\n",
      "tensor(0.3703)\n",
      "tensor(0.3714)\n",
      "tensor(0.3672)\n",
      "tensor(0.3678)\n",
      "tensor(0.3693)\n",
      "tensor(0.3620)\n",
      "tensor(0.3648)\n",
      "tensor(0.3681)\n",
      "tensor(0.3714)\n",
      "tensor(0.3753)\n",
      "tensor(0.3645)\n",
      "tensor(0.3644)\n",
      "tensor(0.3639)\n",
      "tensor(0.3665)\n",
      "tensor(0.3686)\n",
      "tensor(0.3725)\n",
      "tensor(0.3707)\n",
      "tensor(0.3671)\n",
      "tensor(0.3692)\n",
      "tensor(0.3707)\n",
      "tensor(0.3667)\n",
      "tensor(0.3744)\n",
      "tensor(0.3702)\n",
      "tensor(0.3690)\n",
      "tensor(0.3673)\n",
      "tensor(0.3681)\n",
      "tensor(0.3769)\n",
      "tensor(0.3773)\n",
      "tensor(0.3736)\n",
      "tensor(0.3695)\n",
      "tensor(0.3716)\n",
      "tensor(0.3703)\n",
      "tensor(0.3718)\n",
      "tensor(0.3609)\n",
      "tensor(0.3633)\n",
      "tensor(0.3683)\n",
      "tensor(0.3681)\n",
      "tensor(0.3678)\n",
      "tensor(0.3752)\n",
      "tensor(0.3619)\n",
      "tensor(0.3703)\n",
      "tensor(0.3760)\n",
      "tensor(0.3737)\n",
      "tensor(0.3681)\n",
      "tensor(0.3725)\n",
      "tensor(0.3647)\n",
      "tensor(0.3610)\n",
      "tensor(0.3666)\n",
      "tensor(0.3650)\n",
      "tensor(0.3633)\n",
      "tensor(0.3654)\n",
      "tensor(0.3682)\n",
      "tensor(0.3653)\n",
      "tensor(0.3667)\n",
      "tensor(0.3683)\n",
      "tensor(0.3652)\n",
      "tensor(0.3661)\n",
      "tensor(0.3668)\n",
      "tensor(0.3681)\n",
      "tensor(0.3708)\n",
      "tensor(0.3660)\n",
      "tensor(0.3631)\n",
      "tensor(0.3613)\n",
      "tensor(0.3666)\n",
      "Valid loss: 0.36752864718437195\n",
      "2\n",
      "tensor(0.3656)\n",
      "tensor(0.3706)\n",
      "tensor(0.3681)\n",
      "tensor(0.3614)\n",
      "tensor(0.3688)\n",
      "tensor(0.3658)\n",
      "tensor(0.3660)\n",
      "tensor(0.3651)\n",
      "tensor(0.3669)\n",
      "tensor(0.3689)\n",
      "tensor(0.3659)\n",
      "tensor(0.3667)\n",
      "tensor(0.3616)\n",
      "tensor(0.3618)\n",
      "tensor(0.3634)\n",
      "tensor(0.3564)\n",
      "tensor(0.3585)\n",
      "tensor(0.3617)\n",
      "tensor(0.3638)\n",
      "tensor(0.3682)\n",
      "tensor(0.3582)\n",
      "tensor(0.3819)\n",
      "tensor(0.3769)\n",
      "tensor(0.3767)\n",
      "tensor(0.3750)\n",
      "tensor(0.3779)\n",
      "tensor(0.4069)\n",
      "tensor(0.3918)\n",
      "tensor(0.3896)\n",
      "tensor(0.3867)\n",
      "tensor(0.3816)\n",
      "tensor(0.3878)\n",
      "tensor(0.3809)\n",
      "tensor(0.3778)\n",
      "tensor(0.3740)\n",
      "tensor(0.3735)\n",
      "tensor(0.3806)\n",
      "tensor(0.3757)\n",
      "tensor(0.3730)\n",
      "tensor(0.3698)\n",
      "tensor(0.3710)\n",
      "tensor(0.3705)\n",
      "tensor(0.3712)\n",
      "tensor(0.3606)\n",
      "tensor(0.3626)\n",
      "tensor(0.3674)\n",
      "tensor(0.3662)\n",
      "tensor(0.3647)\n",
      "tensor(0.3682)\n",
      "tensor(0.3588)\n",
      "tensor(0.3662)\n",
      "tensor(0.3708)\n",
      "tensor(0.3668)\n",
      "tensor(0.3619)\n",
      "tensor(0.3671)\n",
      "tensor(0.3588)\n",
      "tensor(0.3553)\n",
      "tensor(0.3599)\n",
      "tensor(0.3588)\n",
      "tensor(0.3570)\n",
      "tensor(0.3578)\n",
      "tensor(0.3593)\n",
      "tensor(0.3564)\n",
      "tensor(0.3585)\n",
      "tensor(0.3579)\n",
      "tensor(0.3556)\n",
      "tensor(0.3565)\n",
      "tensor(0.3572)\n",
      "tensor(0.3574)\n",
      "tensor(0.3605)\n",
      "tensor(0.3556)\n",
      "tensor(0.3510)\n",
      "tensor(0.3501)\n",
      "tensor(0.3546)\n",
      "Valid loss: 0.35580065846443176\n",
      "3\n",
      "tensor(0.3543)\n",
      "tensor(0.3591)\n",
      "tensor(0.3564)\n",
      "tensor(0.3494)\n",
      "tensor(0.3555)\n",
      "tensor(0.3538)\n",
      "tensor(0.3527)\n",
      "tensor(0.3532)\n",
      "tensor(0.3543)\n",
      "tensor(0.3560)\n",
      "tensor(0.3545)\n",
      "tensor(0.3560)\n",
      "tensor(0.3505)\n",
      "tensor(0.3506)\n",
      "tensor(0.3513)\n",
      "tensor(0.3457)\n",
      "tensor(0.3469)\n",
      "tensor(0.3495)\n",
      "tensor(0.3521)\n",
      "tensor(0.3562)\n",
      "tensor(0.3427)\n",
      "tensor(0.3436)\n",
      "tensor(0.3425)\n",
      "tensor(0.3468)\n",
      "tensor(0.3482)\n",
      "tensor(0.3512)\n",
      "tensor(0.3494)\n",
      "tensor(0.3460)\n",
      "tensor(0.3474)\n",
      "tensor(0.3490)\n",
      "tensor(0.3444)\n",
      "tensor(0.3517)\n",
      "tensor(0.3477)\n",
      "tensor(0.3464)\n",
      "tensor(0.3437)\n",
      "tensor(0.3437)\n",
      "tensor(0.3510)\n",
      "tensor(0.3473)\n",
      "tensor(0.3453)\n",
      "tensor(0.3434)\n",
      "tensor(0.3450)\n",
      "tensor(0.3447)\n",
      "tensor(0.3468)\n",
      "tensor(0.3364)\n",
      "tensor(0.3392)\n",
      "tensor(0.3438)\n",
      "tensor(0.3438)\n",
      "tensor(0.3425)\n",
      "tensor(0.3462)\n",
      "tensor(0.3357)\n",
      "tensor(0.3436)\n",
      "tensor(0.3482)\n",
      "tensor(0.3451)\n",
      "tensor(0.3411)\n",
      "tensor(0.3456)\n",
      "tensor(0.3390)\n",
      "tensor(0.3359)\n",
      "tensor(0.3408)\n",
      "tensor(0.3396)\n",
      "tensor(0.3381)\n",
      "tensor(0.3390)\n",
      "tensor(0.3408)\n",
      "tensor(0.3388)\n",
      "tensor(0.3410)\n",
      "tensor(0.3413)\n",
      "tensor(0.3387)\n",
      "tensor(0.3406)\n",
      "tensor(0.3415)\n",
      "tensor(0.3417)\n",
      "tensor(0.3451)\n",
      "tensor(0.3406)\n",
      "tensor(0.3363)\n",
      "tensor(0.3360)\n",
      "tensor(0.3400)\n",
      "Valid loss: 0.344256192445755\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "losses = []\n",
    "lrs = []\n",
    "epochs = 4\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(epoch)\n",
    "    for i, batch in enumerate(train_dl):\n",
    "        if i%400==0 and i>0:\n",
    "            print(torch.tensor(losses[-50:]).mean())\n",
    "        x,y = batch\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "        out = model(x)\n",
    "        opt.zero_grad()\n",
    "        loss = loss_fn(out.reshape(-1,out.shape[-1]), y.reshape(-1))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        sched.step()\n",
    "        losses.append(loss.detach().cpu())\n",
    "        lrs.append(opt.defaults['lr'])\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        valid_losses = []\n",
    "        for i, batch in enumerate(valid_dl):\n",
    "            x,y = batch\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            out = model(x)\n",
    "            loss = loss_fn(out.reshape(-1,out.shape[-1]), y.reshape(-1))\n",
    "            valid_losses.append(loss.detach().cpu())\n",
    "            \n",
    "            \n",
    "        valid_loss = torch.tensor(valid_losses).mean()\n",
    "        print(f'Valid loss: {valid_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 12\n",
    "\n",
    "preds = idxs = torch.tensor([vocab.stoi['bos']]*bs).long().cuda().unsqueeze(-1)\n",
    "\n",
    "hiddens = []\n",
    "for l in range(model.base.n_layers):\n",
    "    if l==model.base.n_layers-1:\n",
    "        d_hidden = model.base.d_embedding\n",
    "    else:\n",
    "        d_hidden = model.base.d_hidden\n",
    "        \n",
    "    h = torch.zeros((1,bs, d_hidden)).cuda()\n",
    "    c = torch.zeros((1,bs, d_hidden)).cuda()\n",
    "    hiddens.append((h,c))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(80):\n",
    "        x = model.base.embedding(idxs)\n",
    "        new_hidden = []\n",
    "        for i, lstm in enumerate(model.base.lstms):\n",
    "            x, (h,c) = lstm(x, hiddens[i])\n",
    "            new_hidden.append((h.detach(), c.detach()))\n",
    "            \n",
    "        hiddens = new_hidden\n",
    "            \n",
    "        x = model.head(x)\n",
    "        log_probs = F.log_softmax(x, -1).squeeze(1)\n",
    "        idxs = torch.multinomial(log_probs.exp(), 1)\n",
    "#         idxs = x.argmax(-1)\n",
    "        preds = torch.cat([preds, idxs], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 22, 22, 22, 26, 22,  5, 19, 27,  6, 22, 22, 36, 11, 33,  5, 22, 27,\n",
       "        33, 12, 33, 33, 33,  5, 22,  6, 33,  5, 22,  6, 33, 12,  6, 36, 36, 33,\n",
       "        11, 26, 11, 22, 22, 30, 22, 20, 24, 32,  5, 30, 22, 20, 20, 24, 32, 12,\n",
       "        22, 22, 27, 22, 12,  6, 22, 11,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "         2,  2,  2,  2,  2,  2,  2,  2,  2], device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CCCNC(=O)CCn1c(COc2ccc(C)c(C)c2)nnc1N1CC[C@H]([C@@H]2CCOC2)C1'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.reconstruct(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(valid_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 75])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    p = learn.model(x.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 75, 42])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = F.softmax(p, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22, 22,  5,  5, 22, 22,  6, 26, 19, 27,  6, 26, 22, 22,  5, 19, 27,  6,\n",
       "        33, 11, 33, 36, 24, 32, 33, 12, 22, 33, 12, 33, 33, 33, 33, 33, 22, 22,\n",
       "         6, 33, 12,  6, 36, 33, 11, 22,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "         2,  2,  2], device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.argmax(-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22, 22, 26,  5, 22, 22, 22,  5, 19, 27,  6, 27,  6, 22,  5, 19, 27,  6,\n",
       "        33, 11, 30, 36, 24, 32, 33,  5,  8, 33, 12, 33, 33, 33, 33,  5, 27, 22,\n",
       "         6, 33, 12,  6, 36, 33, 11, 22,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "         2,  2,  2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True, False,  True,  True,  True, False, False,  True,  True,\n",
       "         True, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True, False, False,  True,  True,  True,\n",
       "         True,  True,  True, False, False,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True], device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.argmax(-1)[0]==y[0].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_chem.ipynb.\n",
      "Converted 02_template.filters.ipynb.\n",
      "Converted 03_template.template.ipynb.\n",
      "Converted 04_template.blocks.ipynb.\n",
      "Converted 05_torch_core.ipynb.\n",
      "Converted 06_layers.ipynb.\n",
      "Converted 07_dataloaders.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted template.overview.ipynb.\n",
      "Converted tutorials.ipynb.\n",
      "Converted tutorials.structure_enumeration.ipynb.\n",
      "Converted tutorials.template.advanced.ipynb.\n",
      "Converted tutorials.template.beginner.ipynb.\n",
      "Converted tutorials.template.intermediate.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
