{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloaders\n",
    "\n",
    "> Pytorch datasets, dataloaders, collate functions and vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from mrl.imports import *\n",
    "from mrl.torch_imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "SMILES_CHAR_VOCAB = ['#', '(', ')', '+', '-', '/', '0',\n",
    "                 '1', '2', '3', '4', '5', '6', '7',\n",
    "                 '8', '=', '@', 'B', 'C', 'F', 'H',\n",
    "                 'I', 'N', 'O', 'P', 'S', '[', '\\\\',\n",
    "                 ']', 'c', 'i', 'l', 'n', 'o', 'r', 's',\n",
    "                 '*', ':']\n",
    "\n",
    "\n",
    "SPECIAL_TOKENS = ['bos', 'eos', 'pad', 'unk']\n",
    "\n",
    "MAPPING_TOKENS = ['[1*:1]', '[2*:1]', '[1*:2]', '[2*:2]', '[1*:3]',\n",
    "                  '[2*:3]', '[1*:4]', '[2*:4]', '[1*:5]', '[2*:5]']\n",
    "\n",
    "HALOGEN_REPLACE = {'Br':'R',\n",
    "                   'Cl':'L'}\n",
    "\n",
    "MAPPING_REPLACE = {'[1*:1]':'A',\n",
    "                   '[2*:1]':'D',\n",
    "                   '[1*:2]':'E',\n",
    "                   '[2*:2]':'G',\n",
    "                   '[1*:3]':'J',\n",
    "                   '[2*:3]':'M',\n",
    "                   '[1*:4]':'Q',\n",
    "                   '[2*:4]':'T',\n",
    "                   '[1*:5]':'U', \n",
    "                   '[2*:5]':'V'}\n",
    "\n",
    "SMILE_REGEX = \"\"\"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|H|\\(|\\)|\\.|=|\n",
    "                 #|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9])\"\"\"\n",
    "\n",
    "MAPPING_REGEX = \"\"\"(\\[.\\*:.]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|H|\\[|\\]|\\(|\\)|\\.|=|\n",
    "                    #|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9])\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def tokenize_by_character(smile):\n",
    "    return [i for i in smile]\n",
    "\n",
    "def tokenize_with_replacements(smile, replacement_dict):\n",
    "    for k,v in replacement_dict.items():\n",
    "        smile = smile.replace(k,v)\n",
    "    return [i for i in smile]\n",
    "\n",
    "def regex_tokenize(smile, regex):\n",
    "    tokens = [token for token in regex.findall(smile)]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Vocab():\n",
    "    def __init__(self, itos):\n",
    "        self.special_tokens = ['bos', 'eos', 'pad', 'unk']\n",
    "        \n",
    "        self.itos = self.special_tokens + [i for i in itos if not i in self.special_tokens]\n",
    "        self.stoi = {self.itos[i]:i for i in range(len(self.itos))}\n",
    "        self.unks = []\n",
    "        \n",
    "    def tokenize(self, input):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def numericalize(self, input):\n",
    "        output = []\n",
    "        for tok in input:\n",
    "            if tok in self.stoi.keys():\n",
    "                output.append(self.stoi[tok])\n",
    "            else:\n",
    "                output.append(self.stoi['unk'])\n",
    "                self.unks.append(tok)\n",
    "        return output\n",
    "    \n",
    "    def reconstruct(self, input):\n",
    "        \n",
    "        output = []\n",
    "        for item in input:\n",
    "            item = self.itos[item]\n",
    "            if item=='eos':\n",
    "                break\n",
    "                \n",
    "            if not item=='bos':\n",
    "                output.append(item)\n",
    "        \n",
    "        return ''.join(output)\n",
    "                \n",
    "    def update_vocab(self):\n",
    "        unks = list(set(self.unks))\n",
    "        self.itos += unks\n",
    "        self.stoi = {self.itos[i]:i for i in range(len(self.itos))}\n",
    "        self.unks = []\n",
    "        \n",
    "    def update_vocab_from_data(self, inputs):\n",
    "        _ = [self.numericalize(self.tokenize(i)) for i in inputs]\n",
    "        self.update_vocab()\n",
    "        \n",
    "        \n",
    "class CharacterVocab(Vocab):\n",
    "    def tokenize(self, smile):\n",
    "        toks = tokenize_by_character(smile)\n",
    "        toks = ['bos'] + toks + ['eos']\n",
    "        return toks\n",
    "    \n",
    "    \n",
    "class CharacterReplaceVocab(Vocab):\n",
    "    def __init__(self, itos, replace_dict):\n",
    "        self.replace_dict = replace_dict\n",
    "        self.reverse_dict = {v:k for k,v in replace_dict.items()}\n",
    "        for rep in self.reverse_dict.keys():\n",
    "            if not rep in itos:\n",
    "                itos.append(rep)\n",
    "        super().__init__(itos)\n",
    "        \n",
    "    def tokenize(self, smile):\n",
    "        toks = tokenize_with_replacements(smile, self.replace_dict)\n",
    "        toks = ['bos'] + toks + ['eos']\n",
    "        return toks\n",
    "    \n",
    "    def reconstruct(self, input):\n",
    "        output = []\n",
    "        for item in input:\n",
    "            item = self.itos[item]\n",
    "            if item=='eos':\n",
    "                break\n",
    "            \n",
    "            if not item=='bos':\n",
    "                if item in self.reverse_dict.keys():\n",
    "                    item = self.reverse_dict[item]\n",
    "\n",
    "                output.append(item)\n",
    "        \n",
    "        return ''.join(output)\n",
    "    \n",
    "    \n",
    "class RegexVocab(Vocab):\n",
    "    def __init__(self, itos, pattern):\n",
    "        super().__init__(itos)\n",
    "        \n",
    "        self.pattern = pattern\n",
    "        self.regex = re.compile(self.pattern)\n",
    "        \n",
    "    def tokenize(self, smile):\n",
    "        toks = regex_tokenize(smile, self.regex)\n",
    "        toks = ['bos'] + toks + ['eos']\n",
    "        return toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def test_reconstruction(vocab, inputs):\n",
    "    fails = []\n",
    "    for item in inputs:\n",
    "        recon = vocab.reconstruct(vocab.numericalize(vocab.tokenize(item)))\n",
    "        if not item==recon:\n",
    "            fails.append((item, recon))\n",
    "            \n",
    "    return fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def batch_sequences(sequences, pad_idx):\n",
    "    \n",
    "    max_len = max([len(i) for i in sequences])+1\n",
    "    bs = len(sequences)\n",
    "    \n",
    "    batch_tensor = torch.zeros((bs, max_len)).long() + pad_idx\n",
    "    \n",
    "    for i,item in enumerate(sequences):\n",
    "        batch_tensor[i,:item.shape[0]] = item\n",
    "        \n",
    "    return batch_tensor\n",
    "    \n",
    "    \n",
    "def lm_collate(batch, pad_idx, batch_first=True):\n",
    "    \n",
    "    batch_tensor = batch_sequences(batch, pad_idx)\n",
    "        \n",
    "    if batch_first:\n",
    "        output = (batch_tensor[:,:-1], batch_tensor[:,1:])\n",
    "    else:\n",
    "        batch_tensor = batch_tensor.T\n",
    "        output = (batch_tensor[:-1,:], batch_tensor[1:,:])\n",
    "        \n",
    "    return output\n",
    "\n",
    "def sequence_prediction_collate(batch, pad_idx, batch_first=True):\n",
    "    \n",
    "    batch_tensor = batch_sequences([i[0] for i in batch], pad_idx)\n",
    "    y_vals = torch.stack([i[1] for i in batch])\n",
    "    y_vals = y_vals.squeeze(-1)\n",
    "\n",
    "    if not batch_first:\n",
    "        batch_tensor = batch_tensor.T\n",
    "        \n",
    "    return (batch_tensor, y_vals)\n",
    "\n",
    "def fp_collate(batch):\n",
    "    fps = torch.stack([i[0] for i in batch])\n",
    "    y_vals = torch.stack([i[1] for i in batch])\n",
    "    y_vals = y_vals.squeeze(-1)\n",
    "    return (fps, y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, collate_function):\n",
    "        self.collate_function = collate_function\n",
    "        \n",
    "    def dataloader(self, bs, num_workers=-1, **dl_kwargs):\n",
    "        if num_workers==-1:\n",
    "            num_workers=os.cpu_count()\n",
    "        return DataLoader(self, batch_size=bs, num_workers=num_workers, \n",
    "                          collate_fn=self.collate_function, **dl_kwargs)\n",
    "\n",
    "class TextDataset(BaseDataset):\n",
    "    def __init__(self, smiles, vocab, collate_function=None):\n",
    "        self.smiles = smiles\n",
    "        self.vocab = vocab\n",
    "        if collate_function is None:\n",
    "            collate_function = partial(lm_collate, pad_idx=self.vocab.stoi['pad'])\n",
    "        \n",
    "        super().__init__(collate_function)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.smiles)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        smile = self.smiles[idx]\n",
    "        tokens = self.vocab.tokenize(smile)\n",
    "        ints = self.vocab.numericalize(tokens)\n",
    "        ints = torch.LongTensor(ints)\n",
    "        return ints\n",
    "    \n",
    "        \n",
    "class TextPredictionDataset(TextDataset):\n",
    "    def __init__(self, smiles, y_vals, vocab, collate_function=None):\n",
    "        \n",
    "        if collate_function is None:\n",
    "            collate_function = partial(sequence_prediction_collate, pad_idx=vocab.stoi['pad'])\n",
    "        \n",
    "        super().__init__(smiles, vocab, collate_function)\n",
    "        \n",
    "        self.y_vals = y_vals\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        ints = super().__getitem__(idx)\n",
    "        y_val = torch.Tensor([self.y_vals[idx]]).float()\n",
    "        return (ints, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class FPDataset(BaseDataset):\n",
    "    def __init__(self, smiles, y_vals, fp_function, collate_function=None):\n",
    "        if collate_function is None:\n",
    "            collate_function = fp_collate\n",
    "        super().__init__(collate_function)\n",
    "        \n",
    "        self.smiles = smiles\n",
    "        self.y_vals = y_vals\n",
    "        self.fp_function = fp_function\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.smiles)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        smile = self.smiles[idx]\n",
    "        fp = self.fp_function(smile)\n",
    "        fp = torch.FloatTensor(fp)\n",
    "        y_val = torch.FloatTensor([self.y_vals[idx]])\n",
    "        return (fp, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('files/smiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = CharacterVocab(SMILES_CHAR_VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = TextDataset(df.smiles.values, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = ds.dataloader(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 66])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 66])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = TextPredictionDataset(df.smiles.values, np.random.randn(df.smiles.values.shape[0]),\n",
    "                          vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = ds.dataloader(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 67])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/insight/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: to-Python converter for boost::shared_ptr<RDKit::FilterCatalogEntry const> already registered; second conversion method ignored.\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from mrl.chem import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = FPDataset(df.smiles.values, np.random.randn(df.smiles.values.shape[0]), ECFP6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = ds.dataloader(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2048])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(73.)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = CharacterVocab(SMILES_CHAR_VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = TextDataset(df.smiles.values, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = ds.dataloader(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 66])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(len(vocab.itos), 400, padding_idx=vocab.stoi['pad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = embedding(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 66, 400])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(400, 1280, 3, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = lstm(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 66, 1280])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([3, 32, 1280]), torch.Size([3, 32, 1280])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.shape for i in out2[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers.py - common layers\n",
    "    \n",
    "models\n",
    "    agent.py - base agent\n",
    "    lstm - lstm model + agent\n",
    "    vae - vae model + agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
