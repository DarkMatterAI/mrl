{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reward\n",
    "\n",
    "> Rewards - non-differentiable scores for samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "from mrl.imports import *\n",
    "from mrl.core import *\n",
    "from mrl.callbacks import *\n",
    "from mrl.torch_imports import *\n",
    "from mrl.torch_core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class Reward(Callback):\n",
    "    def __init__(self, name, sample_name='samples', \n",
    "                 weight=1., bs=None,\n",
    "                 order=10, track=True, log=True):\n",
    "        super().__init__(name=name, order=order)\n",
    "        \n",
    "        self.sample_name = sample_name\n",
    "        self.weight = weight\n",
    "        self.bs = bs\n",
    "        self.track = track\n",
    "        self.log = log\n",
    "        self.score_log = {}\n",
    "        \n",
    "    def load_data(self, samples, values):\n",
    "        for i in range(len(samples)):\n",
    "            self.score_log[samples[i]] = values[i]\n",
    "        \n",
    "    def setup(self):\n",
    "        log = self.environment.log\n",
    "        log.add_log(self.name)\n",
    "        if self.track:\n",
    "            log.add_metric(self.name)\n",
    "            \n",
    "    def _compute_reward(self, samples):\n",
    "        return [0. for i in samples]\n",
    "    \n",
    "    def compute_batched_reward(self, samples):\n",
    "        if self.bs is not None:\n",
    "            sample_chunks = chunk_list(samples, self.bs)\n",
    "            rewards = []\n",
    "            for chunk in sample_chunks:\n",
    "                rewards_iter = self._compute_reward(chunk)\n",
    "                rewards += list(rewards_iter)\n",
    "            \n",
    "        else:\n",
    "            rewards = self._compute_reward(samples)\n",
    "            \n",
    "        return rewards\n",
    "            \n",
    "    def compute_reward(self):\n",
    "        env = self.environment\n",
    "        batch_state = env.batch_state\n",
    "        samples = batch_state[self.sample_name]\n",
    "        \n",
    "        if self.log:\n",
    "            to_score = [i for i in samples if not i in self.score_log.keys()]\n",
    "            rewards = self.compute_batched_reward(to_score)\n",
    "        \n",
    "            for i in range(len(to_score)):\n",
    "                self.score_log[to_score[i]] = rewards[i]\n",
    "                \n",
    "            rewards = [self.score_log[i] for i in samples]\n",
    "            \n",
    "        else:\n",
    "            rewards = self.compute_batched_reward(samples)\n",
    "            \n",
    "        rewards = to_device(torch.tensor(rewards).float())\n",
    "        rewards = rewards * self.weight\n",
    "        \n",
    "        batch_state.rewards += rewards\n",
    "        batch_state[self.name] = rewards\n",
    "        \n",
    "        if self.track:\n",
    "            env.log.update_metric(self.name, rewards.mean().detach().cpu().numpy())\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class FunctionReward(Reward):\n",
    "    def __init__(self, reward_function, name, sample_name='samples', \n",
    "                 weight=1., bs=None,\n",
    "                 order=10, track=True, log=True):\n",
    "        super().__init__(name=name, \n",
    "                         sample_name=sample_name, \n",
    "                         weight=weight,\n",
    "                         bs=bs,\n",
    "                         order=order, \n",
    "                         track=track, \n",
    "                         log=log)\n",
    "        \n",
    "        self.reward_function = reward_function\n",
    "        \n",
    "        \n",
    "    def _compute_reward(self, samples):\n",
    "        rewards = []\n",
    "        if samples:\n",
    "            rewards = self.reward_function(samples)\n",
    "        return rewards\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class NoveltyReward(Reward):\n",
    "    def __init__(self, weight=1., track=True):\n",
    "        super().__init__(name='novel', \n",
    "                         sample_name='samples',\n",
    "                         weight=weight, \n",
    "                         order=10, \n",
    "                         track=track,\n",
    "                         log=False)\n",
    "        \n",
    "    def _compute_reward(self, samples):\n",
    "        log = self.environment.log\n",
    "        old = log.unique_samples\n",
    "        new = [not i in old for i in samples]\n",
    "        new = [float(i) for i in new]\n",
    "        return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mrl)",
   "language": "python",
   "name": "mrl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
