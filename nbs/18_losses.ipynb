{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses\n",
    "\n",
    "> Loss callback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "from mrl.imports import *\n",
    "from mrl.torch_imports import *\n",
    "from mrl.torch_core import *\n",
    "from mrl.callbacks import *\n",
    "from mrl.policy_gradient import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class LossCallback(Callback):\n",
    "    def __init__(self, loss_function, name, weight=1., track=True, order=20):\n",
    "        super().__init__(name=name, order=order)\n",
    "        self.loss_function = loss_function\n",
    "        self.weight = weight\n",
    "        self.track = track\n",
    "        \n",
    "    def setup(self):\n",
    "        if self.track:\n",
    "            log = self.environment.log\n",
    "            log.add_metric(self.name)\n",
    "            log.add_log(self.name)\n",
    "        \n",
    "    def compute_loss(self):\n",
    "        loss, loss_dict = self.loss_function.from_batch_state(self.batch_state)\n",
    "        \n",
    "        if self.track:\n",
    "            self.environment.log.update_metric(self.name, loss.mean().detach().cpu().numpy())\n",
    "            \n",
    "        loss = loss * self.weight\n",
    "        self.environment.batch_state.loss += loss.mean()\n",
    "        self.environment.batch_state[self.name] = loss.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyLoss(LossCallback):\n",
    "    def __init__(self, policy_function, name, value_head=None, \n",
    "                 v_update=0.95, v_update_iter=10,\n",
    "                 vopt_kwargs={}, weight=1, track=True):\n",
    "        assert isinstance(policy_function, BasePolicy)\n",
    "        super().__init__(policy_function, name, weight, track)\n",
    "        \n",
    "        self.set_model(value_head, vopt_kwargs)\n",
    "        self.v_update = v_update\n",
    "        self.v_update_iter = v_update_iter\n",
    "        self.fields = [\n",
    "            'model_gathered_logprobs',\n",
    "            'base_gathered_logprobs',\n",
    "            'mask',\n",
    "            'trajectory_rewards',\n",
    "            'model_logprobs',\n",
    "            'base_logprobs',\n",
    "            'value_input'\n",
    "        ]\n",
    "        \n",
    "    def set_model(self, value_head, vopt_kwargs):\n",
    "        self.value_head = value_head\n",
    "        if self.value_head is not None:\n",
    "            self.base_value_head = copy.deepcopy(self.value_head)\n",
    "            to_device(self.value_head)\n",
    "            to_device(self.base_value_head)\n",
    "            self.opt = optim.Adam(self.value_head.parameters(), **vopt_kwargs)\n",
    "            \n",
    "    def before_batch(self):\n",
    "        env = self.environment\n",
    "        batch_state = env.batch_state\n",
    "        for field in self.fields:\n",
    "            if not hasattr(batch_state, field):\n",
    "                batch_state[field] = None\n",
    "                \n",
    "    def get_model_outputs(self):\n",
    "            \n",
    "        env = self.environment\n",
    "        batch_state = env.batch_state\n",
    "        value_input = batch_state.value_input\n",
    "        \n",
    "        if (self.value_head is not None) and (value_input is not None):\n",
    "            value_predictions = self.agent.value_head(value_input)\n",
    "            with torch.no_grad():\n",
    "                base_value_predictions = self.base_value_head(value_input)\n",
    "                \n",
    "        else:\n",
    "            value_predictions = None\n",
    "            base_value_predictions = None\n",
    "            \n",
    "        batch_state.state_values = value_predictions\n",
    "        batch_state.ref_state_values = base_value_predictions\n",
    "            \n",
    "    def zero_grad(self):\n",
    "        self.opt.zero_grad()\n",
    "        \n",
    "    def step(self):\n",
    "        self.opt.step()\n",
    "        \n",
    "    def after_batch(self):\n",
    "        log = self.environment.log\n",
    "        iterations = log.iterations\n",
    "        if iterations%self.v_update_iter == 0 and iterations>0:\n",
    "            self.update_base_model()\n",
    "            \n",
    "    def update_base_model(self):\n",
    "        if self.value_head is not None:\n",
    "            if self.v_update < 1:\n",
    "                merge_models(self.base_value_head, self.value_head, alpha=self.v_update)\n",
    "                \n",
    "    def save_weights(self, filename):\n",
    "        state_dict = {}\n",
    "            \n",
    "        if isinstance(self.value_head, nn.Module):\n",
    "            state_dict['value_head'] = self.value_head.state_dict()\n",
    "            state_dict['base_value_head'] = self.base_value_head.state_dict()\n",
    "        else:\n",
    "            state_dict['value_head'] = None\n",
    "            state_dict['base_value_head'] = None\n",
    "            \n",
    "        torch.save(state_dict, filename)\n",
    "        \n",
    "    def load_weights(self, filename):\n",
    "        state_dict = torch.load(filename, map_location=get_model_device(self.model))\n",
    "            \n",
    "        if isinstance(self.value_head, nn.Module):\n",
    "            self.value_head.load_state_dict(state_dict['value_head'])\n",
    "            self.base_value_head.load_state_dict(state_dict['base_value_head'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mrl)",
   "language": "python",
   "name": "mrl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
