{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses\n",
    "\n",
    "> Loss callback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "from mrl.imports import *\n",
    "from mrl.torch_imports import *\n",
    "from mrl.torch_core import *\n",
    "from mrl.callbacks import *\n",
    "from mrl.policy_gradient import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class LossCallback(Callback):\n",
    "    def __init__(self, loss_function, name, weight=1., track=True, order=20):\n",
    "        super().__init__(name=name, order=order)\n",
    "        self.loss_function = loss_function\n",
    "        self.weight = weight\n",
    "        self.track = track\n",
    "        \n",
    "    def setup(self):\n",
    "        if self.track:\n",
    "            log = self.environment.log\n",
    "            log.add_metric(self.name)\n",
    "            log.add_log(self.name)\n",
    "        \n",
    "    def compute_loss(self):\n",
    "        loss = self.loss_function.from_batch_state(self.environment.batch_state)\n",
    "        loss = loss * self.weight\n",
    "        \n",
    "        if self.track:\n",
    "            self.environment.log.update_metric(self.name, loss.mean().detach().cpu().numpy())\n",
    "            \n",
    "        self.environment.batch_state.loss += loss.mean()\n",
    "        self.environment.batch_state[self.name] = loss.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class PolicyLoss(LossCallback):\n",
    "    def __init__(self, policy_function, name, value_head=None, \n",
    "                 v_update=0.95, v_update_iter=10,\n",
    "                 vopt_kwargs={}, weight=1, track=True):\n",
    "        assert isinstance(policy_function, BasePolicy)\n",
    "        super().__init__(policy_function, name, weight, track)\n",
    "        \n",
    "        self.set_model(value_head, vopt_kwargs)\n",
    "        self.v_update = v_update\n",
    "        self.v_update_iter = v_update_iter\n",
    "        self.fields = [\n",
    "            'model_gathered_logprobs',\n",
    "            'base_gathered_logprobs',\n",
    "            'mask',\n",
    "            'trajectory_rewards',\n",
    "            'model_logprobs',\n",
    "            'base_logprobs',\n",
    "            'value_input'\n",
    "        ]\n",
    "        \n",
    "    def set_model(self, value_head, vopt_kwargs):\n",
    "        self.value_head = value_head\n",
    "        if self.value_head is not None:\n",
    "            self.base_value_head = copy.deepcopy(self.value_head)\n",
    "            to_device(self.value_head)\n",
    "            to_device(self.base_value_head)\n",
    "            self.opt = optim.Adam(self.value_head.parameters(), **vopt_kwargs)\n",
    "        else:\n",
    "            self.opt = None\n",
    "            \n",
    "    def before_batch(self):\n",
    "        env = self.environment\n",
    "        batch_state = env.batch_state\n",
    "        for field in self.fields:\n",
    "            if not hasattr(batch_state, field):\n",
    "                batch_state[field] = None\n",
    "                \n",
    "    def get_model_outputs(self):\n",
    "            \n",
    "        env = self.environment\n",
    "        batch_state = env.batch_state\n",
    "        value_input = batch_state.value_input\n",
    "        \n",
    "        if (self.value_head is not None) and (value_input is not None):\n",
    "            value_predictions = self.value_head(value_input)\n",
    "            with torch.no_grad():\n",
    "                base_value_predictions = self.base_value_head(value_input)\n",
    "                \n",
    "        else:\n",
    "            value_predictions = None\n",
    "            base_value_predictions = None\n",
    "            \n",
    "        batch_state.state_values = value_predictions\n",
    "        batch_state.ref_state_values = base_value_predictions\n",
    "            \n",
    "    def zero_grad(self):\n",
    "        if self.opt is not None:\n",
    "            self.opt.zero_grad()\n",
    "        \n",
    "    def step(self):\n",
    "        if self.opt is not None:\n",
    "            self.opt.step()\n",
    "        \n",
    "    def after_batch(self):\n",
    "        log = self.environment.log\n",
    "        iterations = log.iterations\n",
    "        if iterations%self.v_update_iter == 0 and iterations>0:\n",
    "            self.update_base_model()\n",
    "            \n",
    "    def update_base_model(self):\n",
    "        if self.value_head is not None:\n",
    "            if self.v_update < 1:\n",
    "                merge_models(self.base_value_head, self.value_head, alpha=self.v_update)\n",
    "                \n",
    "    def save_weights(self, filename):\n",
    "        state_dict = {}\n",
    "            \n",
    "        if isinstance(self.value_head, nn.Module):\n",
    "            state_dict['value_head'] = self.value_head.state_dict()\n",
    "            state_dict['base_value_head'] = self.base_value_head.state_dict()\n",
    "        else:\n",
    "            state_dict['value_head'] = None\n",
    "            state_dict['base_value_head'] = None\n",
    "            \n",
    "        torch.save(state_dict, filename)\n",
    "        \n",
    "    def load_weights(self, filename):\n",
    "        state_dict = torch.load(filename, map_location=get_model_device(self.model))\n",
    "            \n",
    "        if isinstance(self.value_head, nn.Module):\n",
    "            self.value_head.load_state_dict(state_dict['value_head'])\n",
    "            self.base_value_head.load_state_dict(state_dict['base_value_head'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class PriorLoss():\n",
    "    def __init__(self, prior, model, base_prior=None, clip=1.):\n",
    "        \n",
    "        self.prior = prior\n",
    "        self.model = model\n",
    "        self.base_prior = base_prior\n",
    "        self.clip = clip\n",
    "        \n",
    "    def loss(self, x, rewards):\n",
    "        z = self.model.x_to_latent(x)\n",
    "        rewards = rewards-rewards.mean()\n",
    "        \n",
    "        prior_lps = self.prior.log_prob(z)\n",
    "        \n",
    "        if self.base_prior is not None:\n",
    "            with torch.no_grad():\n",
    "                base_lps = self.base_prior.log_prob(z)\n",
    "            \n",
    "            ratios = prior_lps - base_lps.detach()\n",
    "            \n",
    "            prior_loss = (-ratios.sum(-1)*rewards)\n",
    "        else:\n",
    "            prior_loss = (-prior_lps.sum(-1)*rewards)\n",
    "            \n",
    "        prior_loss = torch.clip(prior_loss, -self.clip, self.clip)\n",
    "        \n",
    "        return prior_loss\n",
    "    \n",
    "    def from_batch_state(self, batch_state):\n",
    "        x = batch_state.x\n",
    "        rewards = batch_state.rewards\n",
    "        return self.loss(x, rewards)\n",
    "        \n",
    "\n",
    "class HistoricPriorLoss(Callback):\n",
    "    def __init__(self, prior_loss, dataset, percentile, \n",
    "                 n, start_iter, frequency,\n",
    "                 log_term='rewards', weight=1., track=True):\n",
    "        super().__init__(name='hist_prior', order=20)\n",
    "        \n",
    "        self.prior_loss = prior_loss\n",
    "        self.dataset = dataset\n",
    "        self.percentile = percentile\n",
    "        self.n = n\n",
    "        self.start_iter = start_iter\n",
    "        self.frequency = frequency\n",
    "        self.log_term = log_term\n",
    "        self.weight = weight\n",
    "        self.track = track\n",
    "        \n",
    "    def setup(self):\n",
    "        if self.track:\n",
    "            log = self.environment.log\n",
    "            log.add_metric(self.name)\n",
    "\n",
    "    def compute_loss(self):\n",
    "        loss = self.historic_loss()\n",
    "        loss = loss * self.weight\n",
    "        \n",
    "        if self.track:\n",
    "            self.environment.log.update_metric(self.name, loss.mean().detach().cpu().numpy())\n",
    "        \n",
    "        self.environment.batch_state.loss += loss.mean()\n",
    "        self.environment.batch_state[self.name] = loss.detach().cpu().numpy()\n",
    "        \n",
    "    def historic_loss(self):\n",
    "        env = self.environment\n",
    "        \n",
    "        iterations = self.environment.log.iterations\n",
    "\n",
    "        if (iterations > self.start_iter) and (iterations%self.frequency==0):\n",
    "            df = env.log.df\n",
    "            \n",
    "            df1 = df[df[self.log_term]>np.percentile(df[self.log_term].values, self.percentile)]\n",
    "            n_samp = min(self.n, df1.shape[0])\n",
    "            samples1 = df1.sample(n=n_samp)\n",
    "            \n",
    "            df2 = df[df[self.log_term]<np.percentile(df[self.log_term].values, self.percentile)]\n",
    "            n_samp = min(self.n, df2.shape[0])\n",
    "            samples2 = df2.sample(n=n_samp)\n",
    "            \n",
    "            df = pd.concat([samples1, samples2])\n",
    "            \n",
    "            rewards = to_device(torch.tensor(df.rewards.values).float())\n",
    "            \n",
    "            \n",
    "            batch_ds = self.dataset.new(df.samples.values)\n",
    "            batch = batch_ds.collate_function([batch_ds[i] for i in range(len(batch_ds))])\n",
    "            batch = to_device(batch)\n",
    "            x,y = batch\n",
    "            \n",
    "            prior_loss = self.prior_loss.loss(x, rewards)\n",
    "\n",
    "        else:\n",
    "            prior_loss = torch.tensor(0.)\n",
    "        \n",
    "        return prior_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mrl)",
   "language": "python",
   "name": "mrl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
