{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "\n",
    "> Core functions for MRL, mostly low level plumbing and parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from mrl.imports import *\n",
    "from multiprocessing import get_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous Functions\n",
    "\n",
    "Low level helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def is_container(x):\n",
    "    \"check if `x` is a container (used for parallel processing)\"\n",
    "    if isinstance(x, (list, tuple, np.ndarray)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def flatten_recursive(list_of_lists):\n",
    "    \"Recursively flattel list of lists\"\n",
    "    flat_list = []\n",
    "    for item in list_of_lists:\n",
    "        if type(item) == list:\n",
    "            flat_list += flatten_recursive(item)\n",
    "        else:\n",
    "            flat_list.append(item)\n",
    "            \n",
    "    return flat_list\n",
    "\n",
    "def flatten_list_of_lists(list_of_lists):\n",
    "    \"Flattens list of lists (not recursive)\"\n",
    "    return [item for sublist in list_of_lists for item in sublist]\n",
    "\n",
    "def deduplicate_list(l):\n",
    "    \"Deduplicates list l\"\n",
    "    return list(set(l))\n",
    "\n",
    "def chunk_list(input_list, chunksize):\n",
    "    'Breaks `input_list` into chunks of size `chunksize`, ragged on last list'\n",
    "    return [input_list[i:i+chunksize] for i in range(0, len(input_list), chunksize)]\n",
    "\n",
    "def filter_passing(inputs, bools):\n",
    "    'Subsets `inputs` (list) by `bools` (list of bools)'\n",
    "    assert len(inputs)==len(bools), '`inputs` and `bools` must have the same length'\n",
    "    return [inputs[i] for i in range(len(inputs)) if bools[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert flatten_list_of_lists([[1],[2],[3]]) == [1,2,3]\n",
    "assert flatten_recursive([[1],[2],[3, [4,5, [6,7,8]]]]) == [1,2,3,4,5,6,7,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Processing\n",
    "\n",
    "MRL tries to build in parallel processing at every level. This can make a huge difference when you're processing millions of molecules\n",
    "\n",
    "`new_pool_parallel` and `maybe_parallel` are convenient wrappers for parallel processing. The given `func` is wrapped with `**kwargs` and used to process the `iterable`. If `iterable` is a `list` or `np.ndarray`, the elements in `iterable` are run in parallel by `func`.\n",
    "\n",
    "### Parallel processing tradeoffs\n",
    "\n",
    "Parallel processing can significantly speed up a process. There are however some tradeoffs.\n",
    "\n",
    "In Python, parallel processing is creating using a `Pool`. A pool maps instances of a function over an interable.\n",
    "\n",
    "```\n",
    "# uses 5 processes to map `my_iterable` to `my_func`\n",
    "with Pool(processes=5) as p:\n",
    "    outputs = p.map(my_func, my_iterable)\n",
    "```\n",
    "\n",
    "Using the above code creates a new `Pool` with 5 processes, and uses those 5 processes to process the function arguments. The code incurs some i/o overhead creating the `Pool`. This means that if the time required to process the function calls is less than the Pool overhead, using parallel processing will actually be slower than serial processing. There are two ways around this:\n",
    "\n",
    "1. Use process pools for bulk processing (ie function time much greater than i/o time)\n",
    "2. Maintain an open process pool to avoid repeated pool creation overhead\n",
    "\n",
    "MRL uses different functions to control the method of parallel processing used.\n",
    "\n",
    "The `new_pool_parallel` function implements parallel processing using a new pool for every function call, similar to the above code. This function is best used to process large numbers of inputs infrequently. Parallel processing is controlled by the `cpus` argument. If `cpus=None`, the `ncpus` environment variable is used (ie `os.environ['ncpus'] = '8'`)\n",
    "\n",
    "The `maybe_parallel` function allows for repeated use of a stateful process Pool, defined by the `GLOBAL_POOL` variable. By default, `GLOBAL_POOL=None`. To create a global pool, use the `set_global_pool` function.\n",
    "\n",
    "```\n",
    "set_global_pool(cpus=8)\n",
    "```\n",
    "\n",
    "If the `cpus=None`, `maybe_parallel` will run processes using `GLOBAL_POOL` if it exists, or serial processing if it does not. If `cpus` is not None, `maybe_parallel` defaults back to using `new_pool_parallel`\n",
    "\n",
    "If you need to frequently use parallel processing on small batches of inputs (ie batches from a model), set a global pool and use `maybe_parallel`\n",
    "\n",
    "### Global Pool Gotchas\n",
    "\n",
    "Using a global pool allows us to take advantage of parallel processing on small batches without having the overhead of creating process pools over and over again. However, process pools left open accumulate memory. If memory usage builds up, use `refresh_global_pool` to release the memory and create a new global pool, or use `close_global_pool` to delete the global pool and reset it to `None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "GLOBAL_POOL = None\n",
    "\n",
    "def set_global_pool(cpus=None):\n",
    "    global GLOBAL_POOL\n",
    "    if GLOBAL_POOL is not None:\n",
    "        close_global_pool()\n",
    "    \n",
    "    if cpus is None:\n",
    "        GLOBAL_POOL = None\n",
    "    else:   \n",
    "        GLOBAL_POOL = Pool(processes=cpus)\n",
    "        \n",
    "def close_global_pool():\n",
    "    global GLOBAL_POOL\n",
    "    if GLOBAL_POOL is not None:\n",
    "        GLOBAL_POOL.close()\n",
    "        del GLOBAL_POOL\n",
    "        GLOBAL_POOL = None\n",
    "        gc.collect()\n",
    "    \n",
    "def refresh_global_pool():\n",
    "    global GLOBAL_POOL\n",
    "    if GLOBAL_POOL is not None:\n",
    "        cpus = GLOBAL_POOL._processes\n",
    "        close_global_pool()\n",
    "        set_global_pool(cpus=cpus)\n",
    "        \n",
    "def new_pool_parallel(func, iterable, cpus=None, **kwargs):\n",
    "    p_func = partial(func, **kwargs)\n",
    "    if is_container(iterable):\n",
    "    \n",
    "        if cpus is None:\n",
    "            if 'ncpus' in os.environ.keys():\n",
    "                cpus = int(os.environ['ncpus'])\n",
    "            else:\n",
    "                cpus = 0\n",
    "\n",
    "        processes = min(cpus, len(iterable))\n",
    "\n",
    "        if processes == 1:\n",
    "            # spinning up a single pool has more overhead\n",
    "            processes = 0\n",
    "\n",
    "        if processes == 0:\n",
    "            output = [p_func(i) for i in iterable]\n",
    "\n",
    "        else:\n",
    "            with Pool(processes=cpus) as p:\n",
    "                output = p.map(p_func, iterable)\n",
    "            \n",
    "    else:\n",
    "        output = p_func(iterable)\n",
    "        \n",
    "    return output\n",
    "\n",
    "def maybe_parallel(func, iterable, cpus=None, **kwargs):\n",
    "    global GLOBAL_POOL\n",
    "    \n",
    "    p_func = partial(func, **kwargs)\n",
    "    \n",
    "    if is_container(iterable):\n",
    "        if cpus is not None:\n",
    "            \n",
    "            output = new_pool_parallel(func, iterable, cpus, **kwargs)\n",
    "                    \n",
    "        elif GLOBAL_POOL is not None:\n",
    "            output = GLOBAL_POOL.map(func, iterable)\n",
    "            \n",
    "        else:\n",
    "            output = [func(i) for i in iterable]\n",
    "            \n",
    "    else:\n",
    "        output = func(iterable)\n",
    "        \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_func(x):\n",
    "    time.sleep(0.5)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Serial time: 5.01\n",
      "\n",
      "new_pool_parallel, 0 cpus time: 5.01\n",
      "\n",
      "new_pool_parallel, 4 cpus (arg defined) time: 1.53\n",
      "\n",
      "new_pool_parallel, 4 cpus (environ defined) time: 1.53\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "_ = [test_func(i) for i in range(10)]\n",
    "t1 = time.time()\n",
    "_ = new_pool_parallel(test_func, list(range(10))) # serial processing\n",
    "t2 = time.time()\n",
    "_ = new_pool_parallel(test_func, list(range(10)), cpus=4) # 4 cpus manually defined\n",
    "t3 = time.time()\n",
    "os.environ['ncpus'] = '4'\n",
    "_ = new_pool_parallel(test_func, list(range(10))) # 4 cpus defined by environ variable\n",
    "t4 = time.time()\n",
    "\n",
    "print_str = f'''\n",
    "Serial time: {t1-start:.2f}\\n\n",
    "new_pool_parallel, 0 cpus time: {t2-t1:.2f}\\n\n",
    "new_pool_parallel, 4 cpus (arg defined) time: {t3-t2:.2f}\\n\n",
    "new_pool_parallel, 4 cpus (environ defined) time: {t4-t3:.2f}\\n\n",
    "'''\n",
    "\n",
    "print(print_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'NoneType'>\n",
      "<class 'multiprocessing.pool.Pool'>\n",
      "\n",
      "maybe_parallel Global Pool (5 cpus) time: 1.00\n",
      "\n",
      "maybe_parallel arg override 2 cpus time: 3.03\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(type(GLOBAL_POOL))\n",
    "set_global_pool(5)\n",
    "print(type(GLOBAL_POOL))\n",
    "\n",
    "start = time.time()\n",
    "_ = maybe_parallel(test_func, list(range(10)))\n",
    "t1 = time.time()\n",
    "_ = maybe_parallel(test_func, list(range(10)), cpus=2)\n",
    "t2 = time.time()\n",
    "\n",
    "print_str = f'''\n",
    "maybe_parallel Global Pool (5 cpus) time: {t1-start:.2f}\\n\n",
    "maybe_parallel arg override 2 cpus time: {t2-t1:.2f}\\n\n",
    "'''\n",
    "\n",
    "print(print_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Parallel Processing\n",
    "\n",
    "Errors in parallel processing can be difficult to debug because the true error and stack trace are obscured by the parallel processing stack trace. If you have errors in parallel processing, first try setting `os.environ['ncpus'] = '0'` and running `close_global_pool` to disable python multiprocessing. This should reveal the true error.\n",
    "\n",
    "If everything works fine when multiprocessing is disabled, it is likely one of your functions is failing to pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_chem.ipynb.\n",
      "Converted 02_template.filters.ipynb.\n",
      "Converted 03_template.template.ipynb.\n",
      "Converted 04_template.blocks.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mrl)",
   "language": "python",
   "name": "mrl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
