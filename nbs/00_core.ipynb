{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "\n",
    "> Core functions for MRL, mostly low level plumbing and parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from mrl.imports import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous Functions\n",
    "\n",
    "Low level helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def is_container(x):\n",
    "    \"check if `x` is a container (used for parallel processing)\"\n",
    "    if (type(x) == list) or (type(x) == np.ndarray):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def flatten_recursive(list_of_lists):\n",
    "    \"Recursively flattel list of lists\"\n",
    "    flat_list = []\n",
    "    for item in list_of_lists:\n",
    "        if type(item) == list:\n",
    "            flat_list += flatten_recursive(item)\n",
    "        else:\n",
    "            flat_list.append(item)\n",
    "            \n",
    "    return flat_list\n",
    "\n",
    "def flatten_list_of_lists(list_of_lists):\n",
    "    \"Flattens list of lists (not recursive)\"\n",
    "    return [item for sublist in list_of_lists for item in sublist]\n",
    "\n",
    "def deduplicate_list(l):\n",
    "    \"Deduplicates list l\"\n",
    "    return list(set(l))\n",
    "\n",
    "def chunk_list(input_list, chunksize):\n",
    "    'Breaks `input_list` into chunks of size `chunksize`, ragged on last list'\n",
    "    return [input_list[i:i+chunksize] for i in range(0, len(input_list), chunksize)]\n",
    "\n",
    "def filter_passing(inputs, bools):\n",
    "    'Subsets `inputs` (list) by `bools` (list of bools)'\n",
    "    assert len(inputs)==len(bools), '`inputs` and `bools` must have the same length'\n",
    "    return [inputs[i] for i in range(len(inputs)) if bools[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert flatten_list_of_lists([[1],[2],[3]]) == [1,2,3]\n",
    "assert flatten_recursive([[1],[2],[3, [4,5, [6,7,8]]]]) == [1,2,3,4,5,6,7,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Processing\n",
    "\n",
    "MRL tries to build in automatic parallel processing at every level. This can make a huge difference when you're processing millions of molecules\n",
    "\n",
    "`maybe_parallel` is a convenient wrapper for parallel processing. The given `func` is wrapped with `**kwargs` and used to process the `iterable`. If `iterable` is a `list` or `np.ndarray`, the elements in `iterable` are run in parallel by `func`.\n",
    "\n",
    "`maybe_parallel` defaults to using all availlable CPUs for processing. To control CPU usage, either pass in a specific number for the `cpus` argument, or set `ncpus` as an environment variable:\n",
    "\n",
    "`os.environ['ncpus'] = '8'`\n",
    "\n",
    "Passing `cpus=0` or setting `os.environ['ncpus'] = '0'` causes `maybe_parallel` to default to serial processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def maybe_parallel(func, iterable, cpus=None, **kwargs):\n",
    "    \n",
    "    func = partial(func, **kwargs)\n",
    "    \n",
    "    if is_container(iterable):\n",
    "    \n",
    "        if cpus is None:\n",
    "            if 'ncpus' in os.environ.keys():\n",
    "                cpus = int(os.environ['ncpus'])\n",
    "            else:\n",
    "                cpus = os.cpu_count()\n",
    "\n",
    "        processes = min(cpus, len(iterable))\n",
    "\n",
    "        if processes == 0:\n",
    "            output = [func(i) for i in iterable]\n",
    "\n",
    "        else:\n",
    "            with Pool(processes=cpus) as p:\n",
    "                output = p.map(func, iterable)\n",
    "            \n",
    "    else:\n",
    "        output = func(iterable)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial time: 10.03, Parallel time: 1.09.\n",
      "Results will depend on the number of CPUs available\n"
     ]
    }
   ],
   "source": [
    "def test_func(x):\n",
    "    time.sleep(1)\n",
    "    return x\n",
    "\n",
    "start = time.time()\n",
    "_ = [test_func(i) for i in range(10)]\n",
    "t1 = time.time()\n",
    "_ = maybe_parallel(test_func, list(range(10)))\n",
    "t2 = time.time()\n",
    "\n",
    "print(f'Serial time: {t1-start:.2f}, Parallel time: {t2-t1:.2f}.\\nResults will depend on the number of CPUs available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging Parallel Processing\n",
    "\n",
    "Errors in parallel processing can be difficult to debug because the true error and stack trace are obscured by the parallel processing stack trace. If you have errors in parallel processing, first try setting `os.environ['ncpus'] = '0'` to disable python multiprocessing. This should reveal the true error.\n",
    "\n",
    "If everything works fine when multiprocessing is disabled, it is likely one of your functions is failing to pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_chem.ipynb.\n",
      "Converted 02_template.filters.ipynb.\n",
      "Converted 03_template.template.ipynb.\n",
      "Converted 04_template.blocks.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
