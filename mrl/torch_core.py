# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/05_torch_core.ipynb (unless otherwise specified).

__all__ = ['get_device', 'to_device', 'set_device', 'get_model_device', 'USE_CUDA', 'x_to_preds', 'average_batches',
           'smooth_batches']

# Cell
from .imports import *
from .torch_imports import *

# Cell

USE_CUDA = torch.cuda.is_available()

if USE_CUDA:
    torch.backends.cudnn.benchmark = True

def get_device():
    if torch.cuda.is_available():
        device = int(os.environ.get('DEFAULT_GPU') or 0)
    else:
        device='cpu'

    device = torch.device(device)
    return device

def to_device(tensor, device=None):
    if device is None:
        device = get_device()
    else:
        device = torch.device(device)

    if hasattr(tensor, 'to'):
        output = tensor.to(device)
    else:
        output = [to_device(i, device) for i in tensor]

    return output

def set_device(device):
    os.environ['DEFAULT_GPU'] = device

def get_model_device(model):
    return next(model.parameters()).device

# Cell

def x_to_preds(x, multinomial=True):
    log_probs = F.log_softmax(x, -1).squeeze(1)
    probs = log_probs.detach().exp()

    if multinomial:
        idxs = torch.multinomial(probs, 1)
    else:
        idxs = x.argmax(-1)

    lps = torch.gather(log_probs, 1, idxs)
    return idxs, lps

# Cell

def average_batches(batches):
    val = torch.tensor(0.)
    c = 0
    for batch in batches:
        bs = batch.shape[0]
        val += batch.mean()*bs
        c += bs

    return val/c

def smooth_batches(batches, beta=0.98):

    val = torch.tensor(0.)
    count = 0

    for batch in batches:
        val = torch.lerp(batch.mean(), val, beta)
        count += 1

    return val/(1-beta**count)