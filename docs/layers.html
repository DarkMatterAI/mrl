---

title: Layers

keywords: fastai
sidebar: home_sidebar

summary: "Pytorch model layers"
description: "Pytorch model layers"
nb_path: "nbs/06_layers.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/06_layers.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LinearBlock" class="doc_header"><code>class</code> <code>LinearBlock</code><a href="https://github.com/DarkMatterAI/mrl/tree/main/mrl/layers.py#L14" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LinearBlock</code>(<strong><code>d_in</code></strong>, <strong><code>d_out</code></strong>, <strong><code>act</code></strong>=<em><code>True</code></em>, <strong><code>bn</code></strong>=<em><code>False</code></em>, <strong><code>dropout</code></strong>=<em><code>0.0</code></em>, <strong>**<code>lin_kwargs</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>LinearBlock - Combined linear, batchnorm, ReLU and dropout.
Layers are executed in the order linear, batchnorm, ReLU, dropout.
Batchnorm, activation and dropout layers are optional</p>
<p>Inputs:</p>

<pre><code>d_in int: number of input dimensions

d_out int: number of output dimensions

act bool: if True, applies a ReLU activation

bn bool: if True, applies 1d batchnorm

dropout float: dropout percentage

**lin_kwargs dict: keyword args passed to nn.Linear</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">layer</span> <span class="o">=</span> <span class="n">LinearBlock</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">bn</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">128</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ValueHead" class="doc_header"><code>class</code> <code>ValueHead</code><a href="https://github.com/DarkMatterAI/mrl/tree/main/mrl/layers.py#L56" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ValueHead</code>(<strong><code>d_in</code></strong>, <strong><code>dropout</code></strong>=<em><code>0.0</code></em>) :: <code>Module</code></p>
</blockquote>
<p>ValueHead - used in RL algorithms to predict state values</p>
<p>Inputs:</p>

<pre><code>d_in int: number of input dimensions</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Conv" class="doc_header"><code>class</code> <code>Conv</code><a href="https://github.com/DarkMatterAI/mrl/tree/main/mrl/layers.py#L76" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Conv</code>(<strong><code>d_in</code></strong>, <strong><code>d_out</code></strong>, <strong><code>ks</code></strong>=<em><code>3</code></em>, <strong><code>stride</code></strong>=<em><code>1</code></em>, <strong><code>padding</code></strong>=<em><code>None</code></em>, <strong><code>ndim</code></strong>=<em><code>2</code></em>, <strong><code>act</code></strong>=<em><code>True</code></em>, <strong><code>bn</code></strong>=<em><code>False</code></em>, <strong><code>dropout</code></strong>=<em><code>0.0</code></em>, <strong>**<code>conv_kwargs</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Conv - base module for convolutions</p>
<p>Inputs:</p>

<pre><code>d_in int: number of input dimensions

d_out int: number of output dimensions

ks int: kernel size

stride int: stride

padding int, None: padding. If None, derived from kernel size

ndim int: conv dimension (1D conv, 2D conv, 3D conv)

act bool: if True, applies a ReLU activation

bn bool: if True, applies batchnorm consistent with `ndim`

dropout float: dropout percentage

**conv_kwargs dict: keyword args passed to nn.Conv</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Conv1d" class="doc_header"><code>class</code> <code>Conv1d</code><a href="https://github.com/DarkMatterAI/mrl/tree/main/mrl/layers.py#L135" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Conv1d</code>(<strong><code>d_in</code></strong>, <strong><code>d_out</code></strong>, <strong><code>ks</code></strong>=<em><code>3</code></em>, <strong><code>stride</code></strong>=<em><code>1</code></em>, <strong><code>padding</code></strong>=<em><code>None</code></em>, <strong><code>act</code></strong>=<em><code>True</code></em>, <strong><code>bn</code></strong>=<em><code>False</code></em>, <strong><code>dropout</code></strong>=<em><code>0.0</code></em>, <strong>**<code>conv_kwargs</code></strong>) :: <a href="/mrl/layers#Conv"><code>Conv</code></a></p>
</blockquote>
<p>Conv1d - 1D convolution</p>
<p>Inputs:</p>

<pre><code>d_in int: number of input dimensions

d_out int: number of output dimensions

ks int: kernel size

stride int: stride

padding int, None: padding. If None, derived from kernel size

act bool: if True, applies a ReLU activation

bn bool: if True, applies batchnorm consistent with `ndim`

dropout float: dropout percentage

**conv_kwargs dict: keyword args passed to nn.Conv</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Conv2d" class="doc_header"><code>class</code> <code>Conv2d</code><a href="https://github.com/DarkMatterAI/mrl/tree/main/mrl/layers.py#L164" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Conv2d</code>(<strong><code>d_in</code></strong>, <strong><code>d_out</code></strong>, <strong><code>ks</code></strong>=<em><code>3</code></em>, <strong><code>stride</code></strong>=<em><code>1</code></em>, <strong><code>padding</code></strong>=<em><code>None</code></em>, <strong><code>act</code></strong>=<em><code>True</code></em>, <strong><code>bn</code></strong>=<em><code>False</code></em>, <strong><code>dropout</code></strong>=<em><code>0.0</code></em>, <strong>**<code>conv_kwargs</code></strong>) :: <a href="/mrl/layers#Conv"><code>Conv</code></a></p>
</blockquote>
<p>Conv2d - 2D convolution</p>
<p>Inputs:</p>

<pre><code>d_in int: number of input dimensions

d_out int: number of output dimensions

ks int: kernel size

stride int: stride

padding int, None: padding. If None, derived from kernel size

act bool: if True, applies a ReLU activation

bn bool: if True, applies batchnorm consistent with `ndim`

dropout float: dropout percentage

**conv_kwargs dict: keyword args passed to nn.Conv</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Conv3d" class="doc_header"><code>class</code> <code>Conv3d</code><a href="https://github.com/DarkMatterAI/mrl/tree/main/mrl/layers.py#L193" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Conv3d</code>(<strong><code>d_in</code></strong>, <strong><code>d_out</code></strong>, <strong><code>ks</code></strong>=<em><code>3</code></em>, <strong><code>stride</code></strong>=<em><code>1</code></em>, <strong><code>padding</code></strong>=<em><code>None</code></em>, <strong><code>act</code></strong>=<em><code>True</code></em>, <strong><code>bn</code></strong>=<em><code>False</code></em>, <strong><code>dropout</code></strong>=<em><code>0.0</code></em>, <strong>**<code>conv_kwargs</code></strong>) :: <a href="/mrl/layers#Conv"><code>Conv</code></a></p>
</blockquote>
<p>Conv3d - 3D convolution</p>
<p>Inputs:</p>

<pre><code>d_in int: number of input dimensions

d_out int: number of output dimensions

ks int: kernel size

stride int: stride

padding int, None: padding. If None, derived from kernel size

act bool: if True, applies a ReLU activation

bn bool: if True, applies batchnorm consistent with `ndim`

dropout float: dropout percentage

**conv_kwargs dict: keyword args passed to nn.Conv</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SphericalDistribution" class="doc_header"><code>class</code> <code>SphericalDistribution</code><a href="https://github.com/DarkMatterAI/mrl/tree/main/mrl/layers.py#L224" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SphericalDistribution</code>(<strong><code>loc</code></strong>, <strong><code>scale</code></strong>, <strong><code>validate_args</code></strong>=<em><code>False</code></em>) :: <code>Distribution</code></p>
</blockquote>
<p>SphericalDistribution - samples from points on the surface of a sphere</p>
<p>Inputs:</p>

<pre><code>loc torch.Tensor: vector of means

scale torch.Tensor: vector of variances</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Prior" class="doc_header"><code>class</code> <code>Prior</code><a href="https://github.com/DarkMatterAI/mrl/tree/main/mrl/layers.py#L256" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Prior</code>() :: <code>Module</code></p>
</blockquote>
<p>Prior - base class for trainable priors</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="NormalPrior" class="doc_header"><code>class</code> <code>NormalPrior</code><a href="https://github.com/DarkMatterAI/mrl/tree/main/mrl/layers.py#L281" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>NormalPrior</code>(<strong><code>loc</code></strong>, <strong><code>log_scale</code></strong>, <strong><code>trainable</code></strong>=<em><code>True</code></em>) :: <a href="/mrl/layers#Prior"><code>Prior</code></a></p>
</blockquote>
<p>NormalPrior - normal distribution prior</p>
<p>Inputs:</p>

<pre><code>loc torch.Tensor: vector of means

log_scale torch.Tensor: vector of log-variances

trainable bool: if True, `loc` and `scale` are trainable

</code></pre>
<p>Note that log-variances are used for stability. Optimizing
the variance directly can cause issues with gradient descent
sending variance values negative</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SphericalPrior" class="doc_header"><code>class</code> <code>SphericalPrior</code><a href="https://github.com/DarkMatterAI/mrl/tree/main/mrl/layers.py#L317" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SphericalPrior</code>(<strong><code>loc</code></strong>, <strong><code>log_scale</code></strong>, <strong><code>trainable</code></strong>=<em><code>True</code></em>) :: <a href="/mrl/layers#NormalPrior"><code>NormalPrior</code></a></p>
</blockquote>
<p>SphericalPrior - spherical distribution prior</p>
<p>Inputs:</p>

<pre><code>loc torch.Tensor: vector of means

log_scale torch.Tensor: vector of log-variances

trainable bool: if True, `loc` and `scale` are trainable

</code></pre>
<p>Note that log-variances are used for stability. Optimizing
the variance directly can cause issues with gradient descent
sending variance values negative</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">NormalPrior</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">64</span><span class="p">,)),</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">64</span><span class="p">,)),</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">p</span><span class="o">.</span><span class="n">rsample</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad</span>
<span class="k">assert</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">SphericalPrior</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,)),</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">2</span><span class="p">,)),</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">assert</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">rsample</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad</span>
<span class="k">assert</span> <span class="ow">not</span> <span class="n">p</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SequenceDropout" class="doc_header"><code>class</code> <code>SequenceDropout</code><a href="https://github.com/DarkMatterAI/mrl/tree/main/mrl/layers.py#L341" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SequenceDropout</code>(<strong><code>p</code></strong>, <strong><code>batch_first</code></strong>=<em><code>True</code></em>) :: <code>Module</code></p>
</blockquote>
<p>SequenceDropout - dropout along the sequence dimension</p>
<p>Inputs:</p>

<pre><code>p float: dropout probability

batch_first bool: if batch dimension is first in input tensors

</code></pre>
<p>Samples a dropout mask that is constant in the sequence dimension</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Conditional_LSTM" class="doc_header"><code>class</code> <code>Conditional_LSTM</code><a href="https://github.com/DarkMatterAI/mrl/tree/main/mrl/layers.py#L375" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Conditional_LSTM</code>(<strong><code>d_embedding</code></strong>, <strong><code>d_hidden</code></strong>, <strong><code>d_output</code></strong>, <strong><code>d_latent</code></strong>, <strong><code>n_layers</code></strong>, <strong><code>condition_hidden</code></strong>=<em><code>True</code></em>, <strong><code>condition_output</code></strong>=<em><code>True</code></em>, <strong><code>bidir</code></strong>=<em><code>False</code></em>, <strong><code>input_dropout</code></strong>=<em><code>0.0</code></em>, <strong><code>lstm_dropout</code></strong>=<em><code>0.0</code></em>, <strong><code>batch_first</code></strong>=<em><code>True</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Conditional_LSTM - Conditional LSTM module</p>
<p>Inputs:</p>

<pre><code>d_embedding int: embedding dimension

d_hidden int: hidden dimension

d_output int: output dimension

d_latent int: latent vector dimension

n_layers int: number of layers

condition_hidden bool: if True, latent vector is used to initialize the
hidden state

condition_output bool: if True, latent vector is concatenated to inputs

bidir bool: if the LSTM should be bidirectional

input_dropout float: dropout percentage on inputs

lstm_dropout float: dropout on LSTM layers

batch_first bool: if batch dimension is first on input tensors</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">d_embedding</span><span class="o">=</span><span class="mi">64</span>
<span class="n">d_hidden</span><span class="o">=</span><span class="mi">128</span>
<span class="n">d_latent</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">n_layers</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">l1</span> <span class="o">=</span> <span class="n">Conditional_LSTM</span><span class="p">(</span><span class="n">d_embedding</span><span class="p">,</span> <span class="n">d_hidden</span><span class="p">,</span> <span class="n">d_embedding</span><span class="p">,</span> <span class="n">d_latent</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span>
                     <span class="n">condition_hidden</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">condition_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                     <span class="n">bidir</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">l2</span> <span class="o">=</span> <span class="n">Conditional_LSTM</span><span class="p">(</span><span class="n">d_embedding</span><span class="p">,</span> <span class="n">d_hidden</span><span class="p">,</span> <span class="n">d_embedding</span><span class="p">,</span> <span class="n">d_latent</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span>
                     <span class="n">condition_hidden</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">condition_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                     <span class="n">bidir</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">l3</span> <span class="o">=</span> <span class="n">Conditional_LSTM</span><span class="p">(</span><span class="n">d_embedding</span><span class="p">,</span> <span class="n">d_hidden</span><span class="p">,</span> <span class="n">d_embedding</span><span class="p">,</span> <span class="n">d_latent</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span>
                     <span class="n">condition_hidden</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">condition_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                     <span class="n">bidir</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">l4</span> <span class="o">=</span> <span class="n">Conditional_LSTM</span><span class="p">(</span><span class="n">d_embedding</span><span class="p">,</span> <span class="n">d_hidden</span><span class="p">,</span> <span class="n">d_embedding</span><span class="p">,</span> <span class="n">d_latent</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span>
                     <span class="n">condition_hidden</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">condition_output</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                     <span class="n">bidir</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">l5</span> <span class="o">=</span> <span class="n">Conditional_LSTM</span><span class="p">(</span><span class="n">d_embedding</span><span class="p">,</span> <span class="n">d_hidden</span><span class="p">,</span> <span class="n">d_embedding</span><span class="p">,</span> <span class="n">d_latent</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span>
                     <span class="n">condition_hidden</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">condition_output</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                     <span class="n">bidir</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">input_dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">lstm_dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">bs</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="n">bs</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="n">d_embedding</span><span class="p">))</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="n">bs</span><span class="p">,</span> <span class="n">d_latent</span><span class="p">))</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">z</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">z</span><span class="p">,</span> <span class="n">l1</span><span class="o">.</span><span class="n">latent_to_hidden</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">l2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">z</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">l2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">z</span><span class="p">,</span> <span class="n">l2</span><span class="o">.</span><span class="n">latent_to_hidden</span><span class="p">(</span><span class="n">z</span><span class="p">))</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">l3</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">z</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">l3</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">z</span><span class="p">,</span> <span class="n">l3</span><span class="o">.</span><span class="n">get_new_hidden</span><span class="p">(</span><span class="n">bs</span><span class="p">))</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">l4</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">z</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">l4</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">z</span><span class="p">,</span> <span class="n">l4</span><span class="o">.</span><span class="n">get_new_hidden</span><span class="p">(</span><span class="n">bs</span><span class="p">))</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">l5</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">z</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">l5</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="kc">None</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">l5</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">z</span><span class="p">,</span> <span class="n">l5</span><span class="o">.</span><span class="n">get_new_hidden</span><span class="p">(</span><span class="n">bs</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">l5</span><span class="o">.</span><span class="n">get_new_hidden</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>2</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">[(</span><span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">i</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">l5</span><span class="o">.</span><span class="n">get_new_hidden</span><span class="p">(</span><span class="mi">5</span><span class="p">)]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[(torch.Size([2, 5, 64]), torch.Size([2, 5, 64])),
 (torch.Size([2, 5, 32]), torch.Size([2, 5, 32]))]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LSTM" class="doc_header"><code>class</code> <code>LSTM</code><a href="https://github.com/DarkMatterAI/mrl/tree/main/mrl/layers.py#L551" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LSTM</code>(<strong><code>d_embedding</code></strong>, <strong><code>d_hidden</code></strong>, <strong><code>d_output</code></strong>, <strong><code>n_layers</code></strong>, <strong><code>bidir</code></strong>=<em><code>False</code></em>, <strong><code>input_dropout</code></strong>=<em><code>0.0</code></em>, <strong><code>lstm_dropout</code></strong>=<em><code>0.0</code></em>, <strong><code>batch_first</code></strong>=<em><code>True</code></em>) :: <a href="/mrl/layers#Conditional_LSTM"><code>Conditional_LSTM</code></a></p>
</blockquote>
<p>LSTM - LSTM module</p>
<p>Inputs:</p>

<pre><code>d_embedding int: embedding dimension

d_hidden int: hidden dimension

d_output int: output dimension

n_layers int: number of layers

bidir bool: if the LSTM should be bidirectional

input_dropout float: dropout percentage on inputs

lstm_dropout float: dropout on LSTM layers

batch_first bool: if batch dimension is first on input tensors</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">l1</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="n">d_embedding</span><span class="p">,</span> <span class="n">d_hidden</span><span class="p">,</span> <span class="n">d_embedding</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">bidir</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">l2</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="n">d_embedding</span><span class="p">,</span> <span class="n">d_hidden</span><span class="p">,</span> <span class="n">d_embedding</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">bidir</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
         <span class="n">input_dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">lstm_dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">l1</span><span class="o">.</span><span class="n">get_new_hidden</span><span class="p">(</span><span class="n">bs</span><span class="p">))</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">l2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">l2</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">l2</span><span class="o">.</span><span class="n">get_new_hidden</span><span class="p">(</span><span class="n">bs</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Conditional_LSTM_Block" class="doc_header"><code>class</code> <code>Conditional_LSTM_Block</code><a href="https://github.com/DarkMatterAI/mrl/tree/main/mrl/layers.py#L599" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Conditional_LSTM_Block</code>(<strong><code>d_vocab</code></strong>, <strong><code>d_embedding</code></strong>, <strong><code>d_hidden</code></strong>, <strong><code>d_output</code></strong>, <strong><code>d_latent</code></strong>, <strong><code>n_layers</code></strong>, <strong><code>input_dropout</code></strong>=<em><code>0.0</code></em>, <strong><code>lstm_dropout</code></strong>=<em><code>0.0</code></em>, <strong><code>bidir</code></strong>=<em><code>False</code></em>, <strong><code>condition_hidden</code></strong>=<em><code>True</code></em>, <strong><code>condition_output</code></strong>=<em><code>False</code></em>, <strong><code>forward_rollout</code></strong>=<em><code>False</code></em>, <strong><code>p_force</code></strong>=<em><code>1.0</code></em>, <strong><code>p_force_decay</code></strong>=<em><code>1.0</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Conditional_LSTM_Block - combines Embedding, Conditional LSTM,
and output layer</p>
<p>Inputs:</p>

<pre><code>d_vocab int: vocab size

d_embedding int: embedding dimension

d_hidden int: hidden dimension

d_output int: output dimension

d_latent int: latent vector dimension

n_layers int: number of layers

input_dropout float: dropout percentage on inputs

lstm_dropout float: dropout on LSTM layers

bidir bool: if the LSTM should be bidirectional

condition_hidden bool: if True, latent vector is used to initialize the
hidden state

condition_output bool: if True, latent vector is concatenated to inputs

forward_rollout bool: if model should generate outputs through rollout
with teacher forcing

p_force float: teacher forcing frequency

p_force_decay float: teacher forcing decay rate</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LSTM_Block" class="doc_header"><code>class</code> <code>LSTM_Block</code><a href="https://github.com/DarkMatterAI/mrl/tree/main/mrl/layers.py#L714" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LSTM_Block</code>(<strong><code>d_vocab</code></strong>, <strong><code>d_embedding</code></strong>, <strong><code>d_hidden</code></strong>, <strong><code>d_output</code></strong>, <strong><code>n_layers</code></strong>, <strong><code>input_dropout</code></strong>=<em><code>0.0</code></em>, <strong><code>lstm_dropout</code></strong>=<em><code>0.0</code></em>, <strong><code>bidir</code></strong>=<em><code>False</code></em>) :: <code>Module</code></p>
</blockquote>
<p>LSTM_Block - combines Embedding, LSTM, and output layer</p>
<p>Inputs:</p>

<pre><code>d_vocab int: vocab size

d_embedding int: embedding dimension

d_hidden int: hidden dimension

d_output int: output dimension

n_layers int: number of layers

input_dropout float: dropout percentage on inputs

lstm_dropout float: dropout on LSTM layers

bidir bool: if the LSTM should be bidirectional</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Encoder" class="doc_header"><code>class</code> <code>Encoder</code><a href="https://github.com/DarkMatterAI/mrl/tree/main/mrl/layers.py#L763" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Encoder</code>(<strong><code>d_latent</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Base encoder module. All encoders have a
d_latent attribute which is referenced by other modules</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LSTM_Encoder" class="doc_header"><code>class</code> <code>LSTM_Encoder</code><a href="https://github.com/DarkMatterAI/mrl/tree/main/mrl/layers.py#L772" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LSTM_Encoder</code>(<strong><code>d_vocab</code></strong>, <strong><code>d_embedding</code></strong>, <strong><code>d_hidden</code></strong>, <strong><code>n_layers</code></strong>, <strong><code>d_latent</code></strong>, <strong><code>input_dropout</code></strong>=<em><code>0.0</code></em>, <strong><code>lstm_dropout</code></strong>=<em><code>0.0</code></em>) :: <a href="/mrl/layers#Encoder"><code>Encoder</code></a></p>
</blockquote>
<p>LSTM_Encoder - LSTM-based encoder</p>
<p>Inputs:</p>

<pre><code>d_vocab int: vocab size

d_embedding int: embedding dimension

d_hidden int: hidden dimension

n_layers int: number of layers

d_latent int: latent vector dimension

input_dropout float: dropout percentage on inputs

lstm_dropout float: dropout on LSTM layers

</code></pre>
<p>Generates latent vector from hidden states from the last LSTM layer</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">d_latent</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">l</span> <span class="o">=</span> <span class="n">LSTM_Encoder</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">input_dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">lstm_dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">l</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">31</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">15</span><span class="p">)))</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">d_latent</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="MLP_Encoder" class="doc_header"><code>class</code> <code>MLP_Encoder</code><a href="https://github.com/DarkMatterAI/mrl/tree/main/mrl/layers.py#L812" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>MLP_Encoder</code>(<strong><code>d_in</code></strong>, <strong><code>dims</code></strong>, <strong><code>d_latent</code></strong>, <strong><code>dropouts</code></strong>) :: <a href="/mrl/layers#Encoder"><code>Encoder</code></a></p>
</blockquote>
<p>MLP_Encoder - MLP-based encoder</p>
<p>Inputs:</p>

<pre><code>d_in int: number of input dimensions

dims list[int]: list of layer sizes ie `[1024, 512, 256]`

dropouts list[float]: list of dropout pobabilities ie `[0.2, 0.2, 0.3]`</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">m</span> <span class="o">=</span> <span class="n">MLP_Encoder</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">16</span><span class="p">],</span> <span class="n">d_latent</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">])</span>
<span class="k">assert</span> <span class="n">m</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">128</span><span class="p">))</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">d_latent</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Conv_Encoder" class="doc_header"><code>class</code> <code>Conv_Encoder</code><a href="https://github.com/DarkMatterAI/mrl/tree/main/mrl/layers.py#L843" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Conv_Encoder</code>(<strong><code>d_vocab</code></strong>, <strong><code>d_embedding</code></strong>, <strong><code>d_latent</code></strong>, <strong><code>filters</code></strong>, <strong><code>kernel_sizes</code></strong>, <strong><code>strides</code></strong>, <strong><code>dropouts</code></strong>) :: <a href="/mrl/layers#Encoder"><code>Encoder</code></a></p>
</blockquote>
<p>Conv_Encoder - 1D conv encoder</p>
<p>Inputs:</p>

<pre><code>d_vocab int: vocab size

d_embedding int: embedding dimension

d_latent int: latent vector dimension

filters list[int]: filter sizes for conv layers ie `[64, 128, 256]`

kernel_sizes list[int]: kernel sizes for conv layers ie `[5, 5, 5]`

strides list[int]: strides for conv layers ie `[2, 2, 2]`

dropouts list[float]: list of dropout pobabilities ie `[0.2, 0.2, 0.3]`</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">c</span> <span class="o">=</span> <span class="n">Conv_Encoder</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">d_latent</span><span class="p">,</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">16</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span><span class="mi">7</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">])</span>
<span class="k">assert</span> <span class="n">c</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">31</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">15</span><span class="p">)))</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">d_latent</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="MLP" class="doc_header"><code>class</code> <code>MLP</code><a href="https://github.com/DarkMatterAI/mrl/tree/main/mrl/layers.py#L888" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>MLP</code>(<strong><code>d_in</code></strong>, <strong><code>dims</code></strong>, <strong><code>d_out</code></strong>, <strong><code>drops</code></strong>, <strong><code>outrange</code></strong>=<em><code>None</code></em>) :: <code>Module</code></p>
</blockquote>
<p>MLP - multi-layer perceptron</p>
<p>Inputs:</p>

<pre><code>d_in int: number of input dimensions

dims list[int]: list of layer sizes ie `[1024, 512, 256]`

d_out int: number of output dimensions

drops list[float]: list of dropout pobabilities ie `[0.2, 0.2, 0.3]`

outrange list[float], None: squashes the output to be between `outrange[0]`
and `outrange[1]`</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

