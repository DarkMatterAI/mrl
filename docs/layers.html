---

title: Layers


keywords: fastai
sidebar: home_sidebar

summary: "Pytorch model layers"
description: "Pytorch model layers"
nb_path: "nbs/06_layers.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/06_layers.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Linear" class="doc_header"><code>class</code> <code>Linear</code><a href="https://github.com/DarkMatterAI/mrl/tree/main/mrl/layers.py#L11" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Linear</code>(<strong><code>d_in</code></strong>, <strong><code>d_out</code></strong>, <strong><code>act</code></strong>=<em><code>True</code></em>, <strong><code>bn</code></strong>=<em><code>False</code></em>, <strong><code>dropout</code></strong>=<em><code>0.0</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LSTMBase" class="doc_header"><code>class</code> <code>LSTMBase</code><a href="https://github.com/DarkMatterAI/mrl/tree/main/mrl/layers.py#L33" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LSTMBase</code>(<strong><code>d_vocab</code></strong>, <strong><code>d_embedding</code></strong>, <strong><code>d_hidden</code></strong>, <strong><code>n_layers</code></strong>, <strong><code>pad_idx</code></strong>, <strong><code>lstm_drop</code></strong>=<em><code>0.0</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">mrl.dataloaders</span> <span class="k">import</span> <span class="o">*</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;files/smiles.csv&#39;</span><span class="p">)</span>
<span class="c1"># df = next(pd.read_csv(&#39;../../ZINC_shards_shuffled/shard_0.csv&#39;, chunksize=10000000))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">smiles</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">&lt;</span><span class="mi">100</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>smiles</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>CNc1nc(SCC(=O)Nc2cc(Cl)ccc2OC)nc2ccccc12</td>
    </tr>
    <tr>
      <td>1</td>
      <td>COc1ccc(C(=O)Oc2ccc(/C=C3\C(=N)N4OC(C)=CC4=NC3...</td>
    </tr>
    <tr>
      <td>2</td>
      <td>Cc1sc(NC(=O)c2ccccc2)c(C(N)=O)c1C</td>
    </tr>
    <tr>
      <td>3</td>
      <td>COc1ccc(NCc2noc(-c3ccoc3)n2)cc1OC(F)F</td>
    </tr>
    <tr>
      <td>4</td>
      <td>O=C(COC(=O)c1cccc(Br)c1)c1ccc2c(c1)OCCCO2</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vocab</span> <span class="o">=</span> <span class="n">CharacterVocab</span><span class="p">(</span><span class="n">SMILES_CHAR_VOCAB</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">itos</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>42</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;CUDA_LAUNCH_BLOCKING&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;1&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_data</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mf">0.98</span><span class="p">)</span>
<span class="n">valid_data</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="o">~</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">train_data</span><span class="o">.</span><span class="n">index</span><span class="p">))]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_ds</span> <span class="o">=</span> <span class="n">TextDataset</span><span class="p">(</span><span class="n">train_data</span><span class="o">.</span><span class="n">smiles</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">vocab</span><span class="p">)</span>
<span class="n">valid_ds</span> <span class="o">=</span> <span class="n">TextDataset</span><span class="p">(</span><span class="n">valid_data</span><span class="o">.</span><span class="n">smiles</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">vocab</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_dl</span> <span class="o">=</span> <span class="n">train_ds</span><span class="o">.</span><span class="n">dataloader</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">valid_dl</span> <span class="o">=</span> <span class="n">valid_ds</span><span class="o">.</span><span class="n">dataloader</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">train_dl</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>21</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LSTMLM" class="doc_header"><code>class</code> <code>LSTMLM</code><a href="https://github.com/DarkMatterAI/mrl/tree/main/mrl/layers.py#L80" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LSTMLM</code>(<strong><code>d_vocab</code></strong>, <strong><code>d_embedding</code></strong>, <strong><code>d_hidden</code></strong>, <strong><code>n_layers</code></strong>, <strong><code>pad_idx</code></strong>, <strong><code>lstm_drop</code></strong>=<em><code>0.0</code></em>, <strong><code>bos_idx</code></strong>=<em><code>0</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastai.text.all</span> <span class="k">import</span> <span class="o">*</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">ModuleNotFoundError</span>                       Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-17-0b556a8fb243&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-fg">----&gt; 1</span><span class="ansi-red-fg"> </span><span class="ansi-green-fg">from</span> fastai<span class="ansi-blue-fg">.</span>text<span class="ansi-blue-fg">.</span>all <span class="ansi-green-fg">import</span> <span class="ansi-blue-fg">*</span>

<span class="ansi-red-fg">ModuleNotFoundError</span>: No module named &#39;fastai.text.all&#39;</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LSTMLM</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">itos</span><span class="p">),</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">vocab</span><span class="o">.</span><span class="n">stoi</span><span class="p">[</span><span class="s1">&#39;pad&#39;</span><span class="p">])</span>
<span class="c1"># encoder = AWD_LSTM(len(vocab.itos), 256, 1024, 3, vocab.stoi[&#39;pad&#39;])</span>
<span class="c1"># decoder = LinearDecoder(len(vocab.itos), 256, 0., tie_encoder=False, bias=True)</span>
<span class="c1"># model = SequentialRNN(encoder, decoder)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">fastai.vision.all</span> <span class="k">import</span> <span class="o">*</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dl</span> <span class="o">=</span> <span class="n">DataLoaders</span><span class="p">(</span><span class="n">train_dl</span><span class="p">,</span> <span class="n">valid_dl</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span><span class="n">dl</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">CrossEntropyLossFlat</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-18-1e0adfa5d9ee&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-red-fg"># learn = Learner(dl, model, loss_func=CrossEntropyLossFlat(), cbs=[ModelResetter(), RNNCallback()])</span>
<span class="ansi-green-fg">----&gt; 2</span><span class="ansi-red-fg"> </span>learn <span class="ansi-blue-fg">=</span> Learner<span class="ansi-blue-fg">(</span>dl<span class="ansi-blue-fg">,</span> model<span class="ansi-blue-fg">,</span> loss_func<span class="ansi-blue-fg">=</span>CrossEntropyLossFlat<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">NameError</span>: name &#39;Learner&#39; is not defined</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">

</div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SuggestedLRs(lr_min=0.005754399299621582, lr_steep=0.0012022644514217973)</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">3e-3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.317389</td>
      <td>0.317360</td>
      <td>4:06:27</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.300273</td>
      <td>0.300688</td>
      <td>4:08:10</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

IOPub message rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_msg_rate_limit`.

Current values:
NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)
NotebookApp.rate_limit_window=3.0 (secs)

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;lstm1&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Path(&#39;models/lstm1.pth&#39;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">enabled</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>True</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mf">3e-3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.356515</td>
      <td>0.356407</td>
      <td>12:51</td>
    </tr>
    <tr>
      <td>1</td>
      <td>0.331074</td>
      <td>0.332720</td>
      <td>12:55</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.312755</td>
      <td>0.316965</td>
      <td>12:56</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.301957</td>
      <td>0.311658</td>
      <td>12:30</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">();</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sched</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">OneCycleLR</span><span class="p">(</span><span class="n">opt</span><span class="p">,</span> <span class="mf">3e-3</span><span class="p">,</span> <span class="n">total_steps</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_dl</span><span class="p">)</span><span class="o">*</span><span class="mi">4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">lrs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">4</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_dl</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span><span class="o">%</span><span class="k">400</span>==0 and i&gt;0:
            <span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">losses</span><span class="p">[</span><span class="o">-</span><span class="mi">50</span><span class="p">:])</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
        <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

        <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">sched</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
        <span class="n">lrs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">opt</span><span class="o">.</span><span class="n">defaults</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">])</span>
        
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">valid_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">valid_dl</span><span class="p">):</span>
            <span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="n">batch</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">valid_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
            
            
        <span class="n">valid_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">valid_losses</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Valid loss: </span><span class="si">{valid_loss}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0
tensor(1.7611)
tensor(1.4714)
tensor(1.0725)
tensor(0.8579)
tensor(0.7714)
tensor(0.6974)
tensor(0.6446)
tensor(0.6038)
tensor(0.5761)
tensor(0.5557)
tensor(0.5363)
tensor(0.5197)
tensor(0.4988)
tensor(0.4862)
tensor(0.4780)
tensor(0.4592)
tensor(0.4567)
tensor(0.4506)
tensor(0.4499)
tensor(0.4467)
tensor(0.4278)
tensor(0.4210)
tensor(0.4169)
tensor(0.4187)
tensor(0.4169)
tensor(0.4191)
tensor(0.4122)
tensor(0.4050)
tensor(0.4041)
tensor(0.4046)
tensor(0.3974)
tensor(0.4041)
tensor(0.3977)
tensor(0.3945)
tensor(0.3891)
tensor(0.3880)
tensor(0.3958)
tensor(0.3902)
tensor(0.3875)
tensor(0.3820)
tensor(0.3847)
tensor(0.3835)
tensor(0.3829)
tensor(0.3711)
tensor(0.3737)
tensor(0.3786)
tensor(0.3775)
tensor(0.3751)
tensor(0.3789)
tensor(0.3665)
tensor(0.3752)
tensor(0.3796)
tensor(0.3762)
tensor(0.3712)
tensor(0.3763)
tensor(0.3688)
tensor(0.3646)
tensor(0.3705)
tensor(0.3683)
tensor(0.3676)
tensor(0.3674)
tensor(0.3699)
tensor(0.3675)
tensor(0.3698)
tensor(0.3696)
tensor(0.3668)
tensor(0.3680)
tensor(0.3694)
tensor(0.3702)
tensor(0.3738)
tensor(0.3702)
tensor(0.3646)
tensor(0.3636)
tensor(0.3686)
Valid loss: 0.3691312074661255
1
tensor(0.3681)
tensor(0.3731)
tensor(0.3711)
tensor(0.3642)
tensor(0.3728)
tensor(0.3696)
tensor(0.3688)
tensor(0.3697)
tensor(0.3713)
tensor(0.3729)
tensor(0.3703)
tensor(0.3714)
tensor(0.3672)
tensor(0.3678)
tensor(0.3693)
tensor(0.3620)
tensor(0.3648)
tensor(0.3681)
tensor(0.3714)
tensor(0.3753)
tensor(0.3645)
tensor(0.3644)
tensor(0.3639)
tensor(0.3665)
tensor(0.3686)
tensor(0.3725)
tensor(0.3707)
tensor(0.3671)
tensor(0.3692)
tensor(0.3707)
tensor(0.3667)
tensor(0.3744)
tensor(0.3702)
tensor(0.3690)
tensor(0.3673)
tensor(0.3681)
tensor(0.3769)
tensor(0.3773)
tensor(0.3736)
tensor(0.3695)
tensor(0.3716)
tensor(0.3703)
tensor(0.3718)
tensor(0.3609)
tensor(0.3633)
tensor(0.3683)
tensor(0.3681)
tensor(0.3678)
tensor(0.3752)
tensor(0.3619)
tensor(0.3703)
tensor(0.3760)
tensor(0.3737)
tensor(0.3681)
tensor(0.3725)
tensor(0.3647)
tensor(0.3610)
tensor(0.3666)
tensor(0.3650)
tensor(0.3633)
tensor(0.3654)
tensor(0.3682)
tensor(0.3653)
tensor(0.3667)
tensor(0.3683)
tensor(0.3652)
tensor(0.3661)
tensor(0.3668)
tensor(0.3681)
tensor(0.3708)
tensor(0.3660)
tensor(0.3631)
tensor(0.3613)
tensor(0.3666)
Valid loss: 0.36752864718437195
2
tensor(0.3656)
tensor(0.3706)
tensor(0.3681)
tensor(0.3614)
tensor(0.3688)
tensor(0.3658)
tensor(0.3660)
tensor(0.3651)
tensor(0.3669)
tensor(0.3689)
tensor(0.3659)
tensor(0.3667)
tensor(0.3616)
tensor(0.3618)
tensor(0.3634)
tensor(0.3564)
tensor(0.3585)
tensor(0.3617)
tensor(0.3638)
tensor(0.3682)
tensor(0.3582)
tensor(0.3819)
tensor(0.3769)
tensor(0.3767)
tensor(0.3750)
tensor(0.3779)
tensor(0.4069)
tensor(0.3918)
tensor(0.3896)
tensor(0.3867)
tensor(0.3816)
tensor(0.3878)
tensor(0.3809)
tensor(0.3778)
tensor(0.3740)
tensor(0.3735)
tensor(0.3806)
tensor(0.3757)
tensor(0.3730)
tensor(0.3698)
tensor(0.3710)
tensor(0.3705)
tensor(0.3712)
tensor(0.3606)
tensor(0.3626)
tensor(0.3674)
tensor(0.3662)
tensor(0.3647)
tensor(0.3682)
tensor(0.3588)
tensor(0.3662)
tensor(0.3708)
tensor(0.3668)
tensor(0.3619)
tensor(0.3671)
tensor(0.3588)
tensor(0.3553)
tensor(0.3599)
tensor(0.3588)
tensor(0.3570)
tensor(0.3578)
tensor(0.3593)
tensor(0.3564)
tensor(0.3585)
tensor(0.3579)
tensor(0.3556)
tensor(0.3565)
tensor(0.3572)
tensor(0.3574)
tensor(0.3605)
tensor(0.3556)
tensor(0.3510)
tensor(0.3501)
tensor(0.3546)
Valid loss: 0.35580065846443176
3
tensor(0.3543)
tensor(0.3591)
tensor(0.3564)
tensor(0.3494)
tensor(0.3555)
tensor(0.3538)
tensor(0.3527)
tensor(0.3532)
tensor(0.3543)
tensor(0.3560)
tensor(0.3545)
tensor(0.3560)
tensor(0.3505)
tensor(0.3506)
tensor(0.3513)
tensor(0.3457)
tensor(0.3469)
tensor(0.3495)
tensor(0.3521)
tensor(0.3562)
tensor(0.3427)
tensor(0.3436)
tensor(0.3425)
tensor(0.3468)
tensor(0.3482)
tensor(0.3512)
tensor(0.3494)
tensor(0.3460)
tensor(0.3474)
tensor(0.3490)
tensor(0.3444)
tensor(0.3517)
tensor(0.3477)
tensor(0.3464)
tensor(0.3437)
tensor(0.3437)
tensor(0.3510)
tensor(0.3473)
tensor(0.3453)
tensor(0.3434)
tensor(0.3450)
tensor(0.3447)
tensor(0.3468)
tensor(0.3364)
tensor(0.3392)
tensor(0.3438)
tensor(0.3438)
tensor(0.3425)
tensor(0.3462)
tensor(0.3357)
tensor(0.3436)
tensor(0.3482)
tensor(0.3451)
tensor(0.3411)
tensor(0.3456)
tensor(0.3390)
tensor(0.3359)
tensor(0.3408)
tensor(0.3396)
tensor(0.3381)
tensor(0.3390)
tensor(0.3408)
tensor(0.3388)
tensor(0.3410)
tensor(0.3413)
tensor(0.3387)
tensor(0.3406)
tensor(0.3415)
tensor(0.3417)
tensor(0.3451)
tensor(0.3406)
tensor(0.3363)
tensor(0.3360)
tensor(0.3400)
Valid loss: 0.344256192445755
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">bs</span> <span class="o">=</span> <span class="mi">12</span>

<span class="n">preds</span> <span class="o">=</span> <span class="n">idxs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">vocab</span><span class="o">.</span><span class="n">stoi</span><span class="p">[</span><span class="s1">&#39;bos&#39;</span><span class="p">]]</span><span class="o">*</span><span class="n">bs</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">hiddens</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">n_layers</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">l</span><span class="o">==</span><span class="n">model</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">n_layers</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">d_hidden</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">d_embedding</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">d_hidden</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">d_hidden</span>
        
    <span class="n">h</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">bs</span><span class="p">,</span> <span class="n">d_hidden</span><span class="p">))</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">bs</span><span class="p">,</span> <span class="n">d_hidden</span><span class="p">))</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
    <span class="n">hiddens</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">h</span><span class="p">,</span><span class="n">c</span><span class="p">))</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">80</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">idxs</span><span class="p">)</span>
        <span class="n">new_hidden</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">lstm</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">base</span><span class="o">.</span><span class="n">lstms</span><span class="p">):</span>
            <span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span><span class="n">c</span><span class="p">)</span> <span class="o">=</span> <span class="n">lstm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">hiddens</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">new_hidden</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">h</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">c</span><span class="o">.</span><span class="n">detach</span><span class="p">()))</span>
            
        <span class="n">hiddens</span> <span class="o">=</span> <span class="n">new_hidden</span>
            
        <span class="n">x</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">log_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">idxs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">log_probs</span><span class="o">.</span><span class="n">exp</span><span class="p">(),</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1">#         idxs = x.argmax(-1)</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">preds</span><span class="p">,</span> <span class="n">idxs</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">preds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([ 0, 22, 22, 22, 26, 22,  5, 19, 27,  6, 22, 22, 36, 11, 33,  5, 22, 27,
        33, 12, 33, 33, 33,  5, 22,  6, 33,  5, 22,  6, 33, 12,  6, 36, 36, 33,
        11, 26, 11, 22, 22, 30, 22, 20, 24, 32,  5, 30, 22, 20, 20, 24, 32, 12,
        22, 22, 27, 22, 12,  6, 22, 11,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,
         2,  2,  2,  2,  2,  2,  2,  2,  2], device=&#39;cuda:0&#39;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vocab</span><span class="o">.</span><span class="n">reconstruct</span><span class="p">(</span><span class="n">preds</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&#39;CCCNC(=O)CCn1c(COc2ccc(C)c(C)c2)nnc1N1CC[C@H]([C@@H]2CCOC2)C1&#39;</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="p">,</span><span class="n">y</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">valid_dl</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([96, 75])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">device</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>device(type=&#39;cpu&#39;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">cuda</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">p</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([96, 75, 42])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">probs</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([22, 22,  5,  5, 22, 22,  6, 26, 19, 27,  6, 26, 22, 22,  5, 19, 27,  6,
        33, 11, 33, 36, 24, 32, 33, 12, 22, 33, 12, 33, 33, 33, 33, 33, 22, 22,
         6, 33, 12,  6, 36, 33, 11, 22,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,
         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,
         2,  2,  2], device=&#39;cuda:0&#39;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([22, 22, 26,  5, 22, 22, 22,  5, 19, 27,  6, 27,  6, 22,  5, 19, 27,  6,
        33, 11, 30, 36, 24, 32, 33,  5,  8, 33, 12, 33, 33, 33, 33,  5, 27, 22,
         6, 33, 12,  6, 36, 33, 11, 22,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,
         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,
         2,  2,  2])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">probs</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">==</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([ True,  True, False,  True,  True,  True, False, False,  True,  True,
         True, False, False,  True,  True,  True,  True,  True,  True,  True,
        False,  True,  True,  True,  True, False, False,  True,  True,  True,
         True,  True,  True, False, False,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,
         True,  True,  True,  True,  True], device=&#39;cuda:0&#39;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

