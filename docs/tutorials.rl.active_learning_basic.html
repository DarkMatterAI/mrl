---

title: Basic Active Learning


keywords: fastai
sidebar: home_sidebar

summary: "Basics of using active learning"
description: "Basics of using active learning"
nb_path: "nbs/tutorials/tutorials.rl.active_learning_basic.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/tutorials/tutorials.rl.active_learning_basic.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Active-Learning">Active Learning<a class="anchor-link" href="#Active-Learning"> </a></h2><p>Generative models give us the ability to rapidly produce millions of novel chemical structures. While this is great for generating designs, it can lead to an imbalance between the computational effort required to generate structures versus evaluating structures.</p>
<p>It is not uncommon to encounter molecular score functions that require minutes  to hours of compute time per compound to generate a score. The lower end of the scale includes methods like docking, which can take low digit minutes per compound depending on the docking config, to large scale molecular simulations which might require an hour or more of GPU compute per compound.</p>
<p>This imbalance is particularly significant when generative models are involved. Say I want to evaluate my compounds with docking, and my docking config requires 2 minutes of CPU compute per compound. With a generative model, I can easily generate ~10 million compounds in ~15 minutes. Evaluating all these compounds would then require 20 million minutes of compute time. At time of writing, AWS is charging about 0.096 dollars/vCPU hour. This means 20 million minutes of compute time will cost about $32,000.</p>
<p>Given that most compounds are likely duds, this will be a huge waste of money. Cash burn is compounded when this is projected out to many model runs over the course of a year.</p>
<p>How can we deal with this? The solution is <strong>active learning</strong>. Active learning is a process where we use a simple, cheap model to approximate our desired score function. We use the cheap score function to generate predictions for a set of compounds we want to score. Then we sample a batch of compounds from the dataset based on the predicted score. We send these samples to the slow, high cost score function. Then we use the results of the slow score to update our simple score.</p>
<p>By iterating on this process, we can find most of the top scoring compounds on a large dataset by screening less than 5\% of the dataset with our slow score function. This notebook gives a minimal example for using active learning to mine a dataset</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Performance-Notes">Performance Notes<a class="anchor-link" href="#Performance-Notes"> </a></h2><p>The workflow in this notebook is more CPU-constrained than GPU-constrained due to the need to evaluate samples on CPU. If you have a multi-core machine, it is recommended that you uncomment and run the <a href="/mrl/core.html#set_global_pool"><code>set_global_pool</code></a> cells in the notebook. This will trigger the use of multiprocessing, which will result in 2-4x speedups.</p>
<p>This notebook may run slow on Collab due to CPU limitations.</p>
<p>If running on Collab, remember to change the runtime to GPU</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>

<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;../&#39;</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">mrl.imports</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">mrl.core</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">mrl.chem</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">mrl.templates.all</span> <span class="kn">import</span> <span class="o">*</span>

<span class="kn">from</span> <span class="nn">mrl.torch_imports</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">mrl.torch_core</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">mrl.layers</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">mrl.dataloaders</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">mrl.g_models.all</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">mrl.vocab</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">mrl.policy_gradient</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">mrl.train.all</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">mrl.model_zoo</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/dmai/miniconda3/envs/mrl/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: to-Python converter for boost::shared_ptr&lt;RDKit::FilterCatalogEntry const&gt; already registered; second conversion method ignored.
  return f(*args, **kwds)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Download-Data">Download Data<a class="anchor-link" href="#Download-Data"> </a></h2><p>We will use the ZINC 250k dataset as our test dataset. This includes 250k compounds from the ZINC library</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># ! wget https://raw.githubusercontent.com/aspuru-guzik-group/chemical_vae/master/models/zinc_properties/250k_rndm_zinc_drugs_clean_3.csv</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;250k_rndm_zinc_drugs_clean_3.csv&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Score-Function">Score Function<a class="anchor-link" href="#Score-Function"> </a></h2><p>Since this is a tutorial, we will use a cheap score function as our target score. In a more realistic setting, this would be something more computationally intensive like docking.</p>
<p>The score function we will use is a MLP model that uses molecular fingerprints to predict the binding affinity of a compound against EGFR. This is a simple and flawed score function, but we use it for the purpose of showing how to use the framework without requiring a significant compute budget to explore the library.</p>
<p>For this purpose of this exercise, we treat the score function as an oracle that gives ground truth predictions</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">oracle_model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="mi">2048</span><span class="p">,</span> <span class="p">[</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="n">outrange</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">15</span><span class="p">])</span>

<span class="n">r_ds</span> <span class="o">=</span> <span class="n">Vec_Prediction_Dataset</span><span class="p">([</span><span class="s1">&#39;C&#39;</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">partial</span><span class="p">(</span><span class="n">failsafe_fp</span><span class="p">,</span> <span class="n">fp_function</span><span class="o">=</span><span class="n">ECFP6</span><span class="p">))</span>

<span class="n">oracle_agent</span> <span class="o">=</span> <span class="n">PredictiveAgent</span><span class="p">(</span><span class="n">oracle_model</span><span class="p">,</span> <span class="n">MSELoss</span><span class="p">(),</span> <span class="n">r_ds</span><span class="p">,</span> <span class="n">opt_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;lr&#39;</span><span class="p">:</span><span class="mf">1e-3</span><span class="p">})</span>

<span class="n">oracle_agent</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">model_from_url</span><span class="p">(</span><span class="s1">&#39;egfr_affinity_mlp.pt&#39;</span><span class="p">))</span>

<span class="n">oracle_agent</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">();</span>

<span class="n">freeze</span><span class="p">(</span><span class="n">oracle_agent</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>

<span class="n">reward</span> <span class="o">=</span> <span class="n">Reward</span><span class="p">(</span><span class="n">oracle_agent</span><span class="o">.</span><span class="n">predict_data</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">4096</span><span class="p">)</span>

<span class="n">aff_reward</span> <span class="o">=</span> <span class="n">RewardCallback</span><span class="p">(</span><span class="n">reward</span><span class="p">,</span> <span class="s1">&#39;affinity&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Initial-Predictions">Initial Predictions<a class="anchor-link" href="#Initial-Predictions"> </a></h2><p>We generate predictions from the oracle for all compounds in the dataset. In a real setting with a computationally expensive score function, we wouldn't do this (in fact we want to use active learning to specifically avoid this). But since this is a tutorial using a cheap oracle, we can generate all our ground truth predictions and use them to evaluate how well the active learning process works at finding high scoring compounds.</p>
<p>We will evaluate the performance of the active learning process by what percentage of compounds above a given score are found relative to the number of compounds screened</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">oracle_agent</span><span class="o">.</span><span class="n">predict_data_batch</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">smiles</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span>
    
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;targs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">preds</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">targs</span><span class="p">,</span> <span class="mi">99</span><span class="p">),</span> <span class="n">df</span><span class="o">.</span><span class="n">targs</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(6.475615110397339, 8.208409)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Active-Learning-Module">Active Learning Module<a class="anchor-link" href="#Active-Learning-Module"> </a></h2><p>Active learning is implemented as a <a href="/mrl/buffer.html#Buffer"><code>Buffer</code></a> in the MRL framework. Normally a buffer holds a set of unscored compounds and samples from this compound set randomly.</p>
<p>With active learning, we use a model to generate predictions for every compound in the buffer, and weight our sampling by these predictions. Then we train the predictive model every batch based on the actual rewards earned.</p>
<p>Our predictive model will be a MLP model that uses molecular fingerprints to generate predictions</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">active_model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="mi">2048</span><span class="p">,</span> <span class="p">[</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span> <span class="n">outrange</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">15</span><span class="p">])</span>

<span class="n">r_ds</span> <span class="o">=</span> <span class="n">Vec_Prediction_Dataset</span><span class="p">([</span><span class="s1">&#39;C&#39;</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">partial</span><span class="p">(</span><span class="n">failsafe_fp</span><span class="p">,</span> <span class="n">fp_function</span><span class="o">=</span><span class="n">ECFP6</span><span class="p">))</span>

<span class="n">active_agent</span> <span class="o">=</span> <span class="n">PredictiveAgent</span><span class="p">(</span><span class="n">active_model</span><span class="p">,</span> <span class="n">MSELoss</span><span class="p">(),</span> <span class="n">r_ds</span><span class="p">,</span> <span class="n">opt_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;lr&#39;</span><span class="p">:</span><span class="mf">1e-3</span><span class="p">})</span>

<span class="n">p_total</span> <span class="o">=</span> <span class="mf">1.</span>
<span class="n">refresh_predictions</span> <span class="o">=</span> <span class="mi">5</span>     <span class="c1"># update predictions every 5 batches</span>
<span class="n">pred_bs</span> <span class="o">=</span> <span class="mi">2048</span>              <span class="c1"># prediction batch size</span>
<span class="n">supervised_frequency</span> <span class="o">=</span> <span class="mi">10</span>   <span class="c1"># how often to do offline supervised training </span>
<span class="n">supervised_epochs</span> <span class="o">=</span> <span class="mi">3</span>       <span class="c1"># number of epochs for offline training</span>
<span class="n">supervised_bs</span> <span class="o">=</span> <span class="mi">32</span>          <span class="c1"># supervised training bs</span>
<span class="n">supervised_lr</span> <span class="o">=</span> <span class="mf">1e-3</span>        <span class="c1"># supervised training learning rate</span>
<span class="n">pct_argmax</span><span class="o">=</span><span class="mf">0.6</span>              <span class="c1"># percent of batch to sample via argmax rather than weighted sampling</span>

<span class="n">buffer</span> <span class="o">=</span> <span class="n">PredictiveBuffer</span><span class="p">(</span><span class="n">p_total</span><span class="p">,</span>
                          <span class="n">refresh_predictions</span><span class="p">,</span> 
                          <span class="n">active_agent</span><span class="p">,</span>
                          <span class="n">pred_bs</span><span class="p">,</span>
                          <span class="n">supervised_frequency</span><span class="p">,</span>
                          <span class="n">supervised_epochs</span><span class="p">,</span>
                          <span class="n">supervised_bs</span><span class="p">,</span>
                          <span class="n">supervised_lr</span><span class="p">,</span> 
                          <span class="n">pct_argmax</span><span class="o">=</span><span class="n">pct_argmax</span><span class="p">)</span>

<span class="n">buffer</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">smiles</span><span class="o">.</span><span class="n">values</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Environment">Environment<a class="anchor-link" href="#Environment"> </a></h2><p>Now we set up our environment. This is the most simple case where we have a single reward term. The active learning framework can be expanded to integrate with generative models, different samplers, or multiple rewards</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">env</span> <span class="o">=</span> <span class="n">Environment</span><span class="p">(</span><span class="n">rewards</span><span class="o">=</span><span class="p">[</span><span class="n">aff_reward</span><span class="p">],</span> <span class="n">buffer</span><span class="o">=</span><span class="n">buffer</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Train">Train<a class="anchor-link" href="#Train"> </a></h2><p>Now we run the training process. We'll train for 60 batches of 128 compounds, for a total of 7680 compounds screened, about 3% of the library. Then we will evaluate how many of the top compounds were recovered</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">env</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">90</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>iterations</th>
      <th>rewards</th>
      <th>rewards_final</th>
      <th>new</th>
      <th>diversity</th>
      <th>bs</th>
      <th>predictive_buffer_loss</th>
      <th>predictive_buffer_preds</th>
      <th>affinity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>5.409</td>
      <td>5.409</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>9.311</td>
      <td>8.012</td>
      <td>5.409</td>
    </tr>
    <tr>
      <td>3</td>
      <td>5.273</td>
      <td>5.273</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>6.118</td>
      <td>7.240</td>
      <td>5.273</td>
    </tr>
    <tr>
      <td>6</td>
      <td>5.452</td>
      <td>5.452</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>2.711</td>
      <td>6.558</td>
      <td>5.452</td>
    </tr>
    <tr>
      <td>9</td>
      <td>5.299</td>
      <td>5.299</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>1.844</td>
      <td>6.026</td>
      <td>5.299</td>
    </tr>
    <tr>
      <td>12</td>
      <td>5.443</td>
      <td>5.443</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>0.824</td>
      <td>5.176</td>
      <td>5.443</td>
    </tr>
    <tr>
      <td>15</td>
      <td>5.350</td>
      <td>5.350</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>0.697</td>
      <td>5.077</td>
      <td>5.350</td>
    </tr>
    <tr>
      <td>18</td>
      <td>5.458</td>
      <td>5.458</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>0.741</td>
      <td>5.045</td>
      <td>5.458</td>
    </tr>
    <tr>
      <td>21</td>
      <td>5.684</td>
      <td>5.684</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>0.302</td>
      <td>5.449</td>
      <td>5.684</td>
    </tr>
    <tr>
      <td>24</td>
      <td>5.613</td>
      <td>5.613</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>0.312</td>
      <td>5.750</td>
      <td>5.613</td>
    </tr>
    <tr>
      <td>27</td>
      <td>5.649</td>
      <td>5.649</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>0.316</td>
      <td>5.901</td>
      <td>5.649</td>
    </tr>
    <tr>
      <td>30</td>
      <td>5.668</td>
      <td>5.668</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>0.250</td>
      <td>5.687</td>
      <td>5.668</td>
    </tr>
    <tr>
      <td>33</td>
      <td>5.987</td>
      <td>5.987</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>0.438</td>
      <td>5.463</td>
      <td>5.987</td>
    </tr>
    <tr>
      <td>36</td>
      <td>5.965</td>
      <td>5.965</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>0.283</td>
      <td>5.626</td>
      <td>5.965</td>
    </tr>
    <tr>
      <td>39</td>
      <td>5.854</td>
      <td>5.854</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>0.126</td>
      <td>5.914</td>
      <td>5.854</td>
    </tr>
    <tr>
      <td>42</td>
      <td>6.086</td>
      <td>6.086</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>0.385</td>
      <td>5.613</td>
      <td>6.086</td>
    </tr>
    <tr>
      <td>45</td>
      <td>6.016</td>
      <td>6.016</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>0.147</td>
      <td>5.918</td>
      <td>6.016</td>
    </tr>
    <tr>
      <td>48</td>
      <td>5.980</td>
      <td>5.980</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>0.159</td>
      <td>6.181</td>
      <td>5.980</td>
    </tr>
    <tr>
      <td>51</td>
      <td>6.171</td>
      <td>6.171</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>0.350</td>
      <td>5.687</td>
      <td>6.171</td>
    </tr>
    <tr>
      <td>54</td>
      <td>6.042</td>
      <td>6.042</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>0.190</td>
      <td>5.750</td>
      <td>6.042</td>
    </tr>
    <tr>
      <td>57</td>
      <td>6.069</td>
      <td>6.069</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>0.094</td>
      <td>6.015</td>
      <td>6.069</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Analysis">Analysis<a class="anchor-link" href="#Analysis"> </a></h2><p>We can see how many of the top compounds we found.</p>
<p>Looking at the environment log, we see we screened about 3% of the total library</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="mi">100</span><span class="o">*</span><span class="n">env</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># percent of compounds screened</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>3.0787115912689664</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This plot shows what percentage of compounds we found above a given score cutoff. The vertical red lines correspond to the 90th, 95th, 99th and 99.9th score percentiles in the dataset.</p>
<p>We can see from the plot that by screening 3% of the library, we found ~80% of the top 0.1% of compounds in the dataset</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cutoffs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">8.15</span><span class="p">))</span>
<span class="n">cutoffs</span> <span class="o">+=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">targs</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">90</span><span class="p">,</span> <span class="mi">95</span><span class="p">,</span> <span class="mi">99</span><span class="p">,</span> <span class="mf">99.9</span><span class="p">]]</span>
<span class="n">cutoffs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">cutoffs</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="p">[</span><span class="n">env</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">df</span><span class="p">[</span><span class="n">env</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">rewards</span><span class="o">&gt;</span><span class="n">cutoff</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">targs</span><span class="o">&gt;</span><span class="n">cutoff</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
 <span class="k">for</span> <span class="n">cutoff</span> <span class="ow">in</span> <span class="n">cutoffs</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cutoffs</span><span class="p">,</span><span class="n">scores</span><span class="p">)</span>
<span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">targs</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">80</span><span class="p">,</span> <span class="mi">90</span><span class="p">,</span> <span class="mi">95</span><span class="p">,</span> <span class="mi">99</span><span class="p">,</span> <span class="mf">99.9</span><span class="p">]]</span>
<span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;score cutoff&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;percent found&#39;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can of course continue sampling to get a deeper evaluation of the library</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">env</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">90</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>iterations</th>
      <th>rewards</th>
      <th>rewards_final</th>
      <th>new</th>
      <th>diversity</th>
      <th>bs</th>
      <th>predictive_buffer_loss</th>
      <th>predictive_buffer_preds</th>
      <th>affinity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>60</td>
      <td>5.987</td>
      <td>5.987</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>0.139</td>
      <td>6.219</td>
      <td>5.987</td>
    </tr>
    <tr>
      <td>63</td>
      <td>6.012</td>
      <td>6.012</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>0.110</td>
      <td>5.808</td>
      <td>6.012</td>
    </tr>
    <tr>
      <td>66</td>
      <td>6.006</td>
      <td>6.006</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>0.060</td>
      <td>6.033</td>
      <td>6.006</td>
    </tr>
    <tr>
      <td>69</td>
      <td>5.893</td>
      <td>5.893</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>0.127</td>
      <td>6.165</td>
      <td>5.893</td>
    </tr>
    <tr>
      <td>72</td>
      <td>5.946</td>
      <td>5.946</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>0.094</td>
      <td>5.768</td>
      <td>5.946</td>
    </tr>
    <tr>
      <td>75</td>
      <td>5.919</td>
      <td>5.919</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>0.063</td>
      <td>5.853</td>
      <td>5.919</td>
    </tr>
    <tr>
      <td>78</td>
      <td>5.944</td>
      <td>5.944</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>0.085</td>
      <td>6.032</td>
      <td>5.944</td>
    </tr>
    <tr>
      <td>81</td>
      <td>6.025</td>
      <td>6.025</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>0.123</td>
      <td>5.781</td>
      <td>6.025</td>
    </tr>
    <tr>
      <td>84</td>
      <td>5.878</td>
      <td>5.878</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>0.063</td>
      <td>5.822</td>
      <td>5.878</td>
    </tr>
    <tr>
      <td>87</td>
      <td>5.929</td>
      <td>5.929</td>
      <td>1.000</td>
      <td>1.000</td>
      <td>128</td>
      <td>0.047</td>
      <td>5.978</td>
      <td>5.929</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cutoffs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mf">8.15</span><span class="p">))</span>
<span class="n">cutoffs</span> <span class="o">+=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">targs</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">90</span><span class="p">,</span> <span class="mi">95</span><span class="p">,</span> <span class="mi">99</span><span class="p">,</span> <span class="mf">99.9</span><span class="p">]]</span>
<span class="n">cutoffs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">cutoffs</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="p">[</span><span class="n">env</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">df</span><span class="p">[</span><span class="n">env</span><span class="o">.</span><span class="n">log</span><span class="o">.</span><span class="n">df</span><span class="o">.</span><span class="n">rewards</span><span class="o">&gt;</span><span class="n">cutoff</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">/</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">targs</span><span class="o">&gt;</span><span class="n">cutoff</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
 <span class="k">for</span> <span class="n">cutoff</span> <span class="ow">in</span> <span class="n">cutoffs</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cutoffs</span><span class="p">,</span><span class="n">scores</span><span class="p">)</span>
<span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">targs</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">80</span><span class="p">,</span> <span class="mi">90</span><span class="p">,</span> <span class="mi">95</span><span class="p">,</span> <span class="mi">99</span><span class="p">,</span> <span class="mf">99.9</span><span class="p">]]</span>
<span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;score cutoff&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;percent found&#39;</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

