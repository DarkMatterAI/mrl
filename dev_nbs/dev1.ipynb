{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/karl/mrl/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/mrl/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: to-Python converter for boost::shared_ptr<RDKit::FilterCatalogEntry const> already registered; second conversion method ignored.\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from mrl.imports import *\n",
    "from mrl.core import *\n",
    "from mrl.chem import *\n",
    "from mrl.templates import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrl.torch_imports import *\n",
    "from mrl.torch_core import *\n",
    "from mrl.layers import *\n",
    "from mrl.dataloaders import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAEEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def get_latent(self, mu, logvar):\n",
    "        z = torch.randn(mu.shape).to(mu.device)\n",
    "        z = mu + z*torch.exp(0.5*logvar)\n",
    "        kl_loss = 0.5 * (logvar.exp() + mu.pow(2) - 1 - logvar).sum(1).mean()\n",
    "        return z, kl_loss\n",
    "        \n",
    "class VAELSTMEncoder(VAEEncoder):\n",
    "    def __init__(self, d_vocab, d_embedding, d_hidden, n_layers, d_latent, dropout=0.):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(d_vocab, d_embedding)\n",
    "        self.lstm_encoder = LSTM(d_embedding, d_hidden, d_hidden, n_layers, \n",
    "                                 bidir=True, batch_first=True, dropout=dropout)\n",
    "        self.transition = nn.Linear(d_hidden*2, d_latent*2)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, hiddens = self.lstm_encoder(x)\n",
    "        hidden = torch.cat(list(torch.cat(hiddens[-1], -1)), -1) # concatenate hidden/cell states of last layer\n",
    "        \n",
    "        mu, logvar = torch.chunk(self.transition(hidden), 2, dim=-1)\n",
    "        z, kl_loss = self.get_latent(mu, logvar)\n",
    "        \n",
    "        return z, kl_loss\n",
    "              \n",
    "class VAEConvEncoder(VAEEncoder):\n",
    "    def __init__(self, d_vocab, d_embedding, kernel_size, n_layers, d_latent, dropout=0.):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.embedding = nn.Embedding(d_vocab, d_embedding)\n",
    "\n",
    "        convs = []\n",
    "        input_size = d_embedding\n",
    "        for i in range(n_layers):\n",
    "            convs.append(Conv1d(input_size, input_size*2, ks=kernel_size, stride=2, \n",
    "                                act=True, bn=True, dropout=dropout))\n",
    "            input_size = input_size*2\n",
    "\n",
    "        self.convs = nn.Sequential(*convs)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.transition = nn.Linear(input_size, d_latent*2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(0,2,1)\n",
    "        x = self.convs(x)\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        \n",
    "        mu, logvar = torch.chunk(self.transition(x), 2, dim=-1)\n",
    "        z, kl_loss = self.get_latent(mu, logvar)\n",
    "        \n",
    "        return z, kl_loss\n",
    "              \n",
    "class VAELinEncoder(VAEEncoder):\n",
    "    def __init__(self, d_input, n_layers, d_latent, dropout=0.):\n",
    "        super().__init__()\n",
    "    \n",
    "        lins = []\n",
    "        input_size = d_input\n",
    "        for i in range(n_layers):\n",
    "            lins.append(Linear(input_size, input_size//2, act=True, bn=True, dropout=dropout))\n",
    "            input_size = input_size//2\n",
    "            \n",
    "        self.layers = nn.Sequential(*lins)\n",
    "        self.transition = nn.Linear(input_size, d_latent*2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        \n",
    "        mu, logvar = torch.chunk(self.transition(x), 2, dim=-1)\n",
    "        z, kl_loss = self.get_latent(mu, logvar)\n",
    "        \n",
    "        return z, kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAEDecoder(nn.Module):\n",
    "    def __init__(self, d_vocab, d_embedding, d_hidden, n_layers, d_latent,\n",
    "                condition_hidden=True, condition_output=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(d_vocab, d_embedding)\n",
    "        self.decoder = Conditional_LSTM(d_embedding, d_hidden, d_embedding, d_latent, 3, \n",
    "                                    condition_hidden=condition_hidden, condition_output=condition_output, \n",
    "                                    bidir=False, batch_first=True)\n",
    "        \n",
    "        self.head = Linear(d_embedding, d_vocab, act=False, bn=False, dropout=0.)\n",
    "        \n",
    "    def forward(self, x, z, hiddens=None):\n",
    "        bs, sl = x.shape\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        decoded, hiddens = self.decoder(x, z, hiddens)\n",
    "        output = self.head(decoded)\n",
    "        \n",
    "        return output, hiddens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, x, decoder_input=None):\n",
    "        z, kl_loss = self.encoder(x)\n",
    "        \n",
    "        if decoder_input is None:\n",
    "            decoder_input = x\n",
    "            \n",
    "        output, hiddens = self.decoder(decoder_input, z)\n",
    "        return output, kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../nbs/files/smiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = CharacterVocab(SMILES_CHAR_VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TextDataset(df.smiles.values, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = data.dataloader(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = VAELSTMEncoder(len(vocab.itos), 256, 1024, 3, 512)\n",
    "encoder = VAEConvEncoder(len(vocab.itos), 256, 7, 3, 512)\n",
    "decoder = VAEDecoder(len(vocab.itos), 256, 1024, 3, 512, condition_hidden=True, condition_output=True)\n",
    "model = VAE(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = FPReconstructionDataset(df.smiles.values, vocab, ECFP6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = data.dataloader(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 2048]), torch.Size([32, 67]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = VAELinEncoder(2048, 2, 512)\n",
    "decoder = VAEDecoder(len(vocab.itos), 256, 1024, 3, 512, condition_hidden=True, condition_output=True)\n",
    "model = VAE(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(66.2236)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 67, 42])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs:\n",
    "    None (sample prior)\n",
    "    latents (from somewhere)\n",
    "    smiles\n",
    "    \n",
    "sample outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, encoder, decoder, d_latent, bos_idx=0):\n",
    "        super().__init__(self)\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.bos_idx = bos_idx\n",
    "#         self.prior = Normal(torch.tensor([0.0]*d_latent), torch.tensor([1.0]*d_latent))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z, kl_loss = self.encoder(x)\n",
    "        output = self.decoder(x, z)\n",
    "        return output, kl_loss\n",
    "    \n",
    "    \n",
    "    def sample(self, bs, sl, temperature=1., multinomial=True):\n",
    "        \n",
    "        preds = idxs = to_device(torch.tensor([self.bos_idx]*bs).long().unsqueeze(-1))\n",
    "        lps = []\n",
    "\n",
    "        hiddens = None\n",
    "        z = self.prior.sample(bs)\n",
    "        \n",
    "        for i in range(sl):\n",
    "            x = self.decoder(idxs, z, hiddens)\n",
    "            x.div_(temperature)\n",
    "            \n",
    "            log_probs = F.log_softmax(x, -1).squeeze(1)\n",
    "            probs = log_probs.detach().exp()\n",
    "            \n",
    "            if multinomial:\n",
    "                idxs = torch.multinomial(probs, 1)\n",
    "            else:\n",
    "                idxs = x.argmax(-1)\n",
    "                \n",
    "            lps.append(torch.gather(log_probs, 1, idxs))\n",
    "            \n",
    "            preds = torch.cat([preds, idxs], -1)\n",
    "            \n",
    "        return preds[:, 1:], torch.cat(lps,-1)\n",
    "    \n",
    "    def sample_no_grad(self, bs, sl, temperature=1., multinomial=True):\n",
    "        with torch.no_grad():\n",
    "            return self.sample(bs, sl, temperature=temperature, multinomial=multinomial)\n",
    "        \n",
    "    def get_lps(self, x, y, temperature=1.):\n",
    "        x = self.forward(x)\n",
    "        x.div_(temperature)\n",
    "        \n",
    "        lps = F.log_softmax(x, -1)\n",
    "        lps = lps.gather(2, y.unsqueeze(-1)).squeeze(-1)\n",
    "        \n",
    "        return lps\n",
    "    \n",
    "class TrainablePrior(nn.Module):\n",
    "    def __init__(self, vae, d_latent, prior=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vae = vae\n",
    "        self.d_latent = d_latent\n",
    "        \n",
    "        if prior is None:\n",
    "            prior = Normal(torch.tensor([0.0]*d_latent), torch.tensor([1.0]*d_latent))\n",
    "            \n",
    "        self.prior = prior\n",
    "        \n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE questions\n",
    "\n",
    "sampling from nothing vs latents vs smiles\n",
    "\n",
    "best saampling procedure. ie we saample some from latent space (latent to smilles), some from explore straat (smiles to llatent to smilles)\n",
    "\n",
    "scale of noise on latent\n",
    "\n",
    "getting log prob of prior vs \n",
    "\n",
    "conditional LSTM class - condition on hidden or on decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../nbs/files/smiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = CharacterVocab(SMILES_CHAR_VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TextDataset(df.smiles.values, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = data.dataloader(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = VAELSTMEncoder(len(vocab.itos), 256, 1024, 3, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = enc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3213, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = VAEConvEncoder(len(vocab.itos), 256, 7, 3, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = enc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 512]), tensor(24.9031, grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].shape, out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = FPReconstructionDataset(df.smiles.values, vocab, ECFP6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = data.dataloader(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 2048]), torch.Size([32, 67]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(iter(dl))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = VAELinEncoder(2048, 3, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.7992,  0.8107, -0.6547,  ...,  0.3234,  1.5410, -0.3869],\n",
       "         [-1.7719, -0.4245,  1.9757,  ...,  0.7609, -0.6874,  0.3805],\n",
       "         [-1.7048,  1.0605,  2.8063,  ..., -1.6529, -0.7574, -0.9330],\n",
       "         ...,\n",
       "         [ 1.1450, -0.6193, -1.9589,  ..., -1.1366,  0.7022,  2.8290],\n",
       "         [ 1.2373,  3.1392, -0.9202,  ...,  0.5538,  1.6990, -1.0942],\n",
       "         [-0.0762,  0.0967,  2.3909,  ..., -0.3375,  1.1847,  0.1257]],\n",
       "        grad_fn=<AddBackward0>), tensor(64.6368, grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrl.dataloaders import *\n",
    "from mrl.chem import *\n",
    "from mrl.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = CharacterVocab(SMILES_CHAR_VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMLM(len(vocab.itos), 256, 1024, 3, vocab.stoi['pad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('untracked_files/smiles_lm.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrl.templates import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# template = Template([ValidityFilter(), SingleCompoundFilter()],\n",
    "#                     [QEDFilter(None, None, score=PassThroughScore()),\n",
    "#                      SAFilter(None, None, \n",
    "#                               score=PropertyFunctionScore(lambda x: (10-x)/9))], fail_score=-1.)\n",
    "\n",
    "template = Template([ValidityFilter(), SingleCompoundFilter()],\n",
    "                    [FPFilter.from_smiles(['CCN(CC)C(=O)C1CN(C2Cc3c[nH]c4c3c(ccc4)C2=C1)C',\n",
    "                                           'CCN(CC)C(=O)C1CN(C2Cc3c[nH]c4c3c(ccc4)C2=C1)C'],\n",
    "                        score=PropertyFunctionScore(lambda x: x.max()))], fail_score=-1.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, lps = model.sample_no_grad(100,100)\n",
    "smiles = [vocab.reconstruct(i) for i in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['ncpus'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2723e-01, -1.7745e+00, -8.4397e-01, -1.4067e-05, -4.9586e-02,\n",
       "        -5.0757e-02, -3.1345e-01, -5.1511e-01, -2.1337e+00, -4.2084e-01,\n",
       "        -2.9031e-02, -4.2183e-02, -4.1649e-02, -4.2915e-06, -9.7015e-01,\n",
       "        -7.6850e-01, -2.3939e-02, -4.6610e-05, -5.0068e-06, -4.6310e-03,\n",
       "        -1.2957e+00, -1.2310e-02, -1.6524e-01, -2.5445e+00, -4.6870e-01,\n",
       "        -4.6492e-06, -1.5020e-05, -8.2051e-01, -1.9669e-05, -5.8349e-02,\n",
       "        -2.2157e+00, -7.0333e-06, -5.9605e-07, -6.9516e-01, -3.3731e-04,\n",
       "        -2.7418e-06, -5.3541e-01, -2.4554e-04, -1.6570e-05, -8.4332e-02,\n",
       "        -7.7576e-01, -5.1260e-06, -3.1828e-05, -1.2875e-05, -1.0827e-02,\n",
       "        -4.4455e-01, -3.4791e-04, -2.1357e+00, -1.2579e+00, -3.5405e-05,\n",
       "        -1.5210e-04, -1.5497e-06, -3.9339e-06, -7.4573e-04, -1.8477e-05,\n",
       "        -4.4107e-06, -1.0014e-05, -3.5763e-07,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TextDataset(smiles, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = data.collate_function([data[i] for i in range(len(data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(x.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 71, 42])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 71])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 100])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = F.log_softmax(out, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2723e-01, -1.7745e+00, -8.4397e-01, -1.4067e-05, -4.9586e-02,\n",
       "        -5.0757e-02, -3.1345e-01, -5.1511e-01, -2.1337e+00, -4.2084e-01,\n",
       "        -2.9031e-02, -4.2183e-02, -4.1649e-02, -4.2915e-06, -9.7015e-01,\n",
       "        -7.6850e-01, -2.3939e-02, -4.6610e-05, -5.0068e-06, -4.6310e-03,\n",
       "        -1.2957e+00, -1.2310e-02, -1.6524e-01, -2.5445e+00, -4.6870e-01,\n",
       "        -4.6492e-06, -1.5020e-05, -8.2051e-01, -1.9669e-05, -5.8349e-02,\n",
       "        -2.2157e+00, -7.0333e-06, -5.9605e-07, -6.9516e-01, -3.3731e-04,\n",
       "        -2.7418e-06, -5.3541e-01, -2.4554e-04, -1.6570e-05, -8.4332e-02,\n",
       "        -7.7576e-01, -5.1260e-06, -3.1828e-05, -1.2875e-05, -1.0827e-02,\n",
       "        -4.4455e-01, -3.4791e-04, -2.1357e+00, -1.2579e+00, -3.5405e-05,\n",
       "        -1.5210e-04, -1.5497e-06, -3.9339e-06, -7.4573e-04, -1.8477e-05,\n",
       "        -4.4107e-06, -1.0014e-05, -3.5763e-07,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00], device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.gather(2, y.cuda().unsqueeze(-1)).squeeze(-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2723e-01, -1.7745e+00, -8.4397e-01, -1.4067e-05, -4.9586e-02,\n",
       "        -5.0757e-02, -3.1345e-01, -5.1511e-01, -2.1337e+00, -4.2084e-01,\n",
       "        -2.9031e-02, -4.2183e-02, -4.1649e-02, -4.2915e-06, -9.7015e-01,\n",
       "        -7.6850e-01, -2.3939e-02, -4.6610e-05, -5.0068e-06, -4.6310e-03,\n",
       "        -1.2957e+00, -1.2310e-02, -1.6524e-01, -2.5445e+00, -4.6870e-01,\n",
       "        -4.6492e-06, -1.5020e-05, -8.2051e-01, -1.9669e-05, -5.8349e-02,\n",
       "        -2.2157e+00, -7.0333e-06, -5.9605e-07, -6.9516e-01, -3.3731e-04,\n",
       "        -2.7418e-06, -5.3541e-01, -2.4554e-04, -1.6570e-05, -8.4332e-02,\n",
       "        -7.7576e-01, -5.1260e-06, -3.1828e-05, -1.2875e-05, -1.0827e-02,\n",
       "        -4.4455e-01, -3.4791e-04, -2.1357e+00, -1.2579e+00, -3.5405e-05,\n",
       "        -1.5210e-04, -1.5497e-06, -3.9339e-06, -7.4573e-04, -1.8477e-05,\n",
       "        -4.4107e-06, -1.0014e-05, -3.5763e-07,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.10146588268993592\n",
      "10 0.1338634037010431\n",
      "seeding\n",
      "20 0.273065905888256\n",
      "30 0.3125\n",
      "40 0.3478260869565218\n",
      "seeding\n",
      "seeding\n",
      "50 0.3492438563327031\n",
      "seeding\n",
      "seeding\n",
      "60 0.3462030604883481\n",
      "70 0.3478260869565217\n",
      "seeding\n",
      "80 0.3478260869565217\n",
      "seeding\n",
      "seeding\n",
      "90 0.34734440309388576\n"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "\n",
    "for i in range(100):\n",
    "        \n",
    "    preds, lps = model.sample_no_grad(512,90)\n",
    "    smiles = [vocab.reconstruct(i) for i in preds]\n",
    "    \n",
    "    if np.random.rand(1)<0.05:\n",
    "        print('seeding')\n",
    "        smiles.append('CCN(CC)C(=O)C1CN(C2Cc3c[nH]c4c3c(ccc4)C2=C1)C')\n",
    "\n",
    "    passes, fails = template.screen_mols(smiles)\n",
    "\n",
    "    if passes:\n",
    "        smiles = [i[0] for i in passes]\n",
    "        scores = np.array([i[1] for i in passes])\n",
    "\n",
    "        data = TextDataset(smiles, vocab)\n",
    "\n",
    "        x,y = data.collate_function([data[i] for i in range(len(data))])\n",
    "\n",
    "        lps = model(x.cuda())\n",
    "        lps = F.log_softmax(lps, -1)\n",
    "        lps = lps.gather(2, y.cuda().unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        all_scores.append(scores)\n",
    "        scores = scores - scores.mean()\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss = -(lps.sum(-1))*torch.from_numpy(scores).cuda()\n",
    "        loss = loss.mean()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    if i%10==0:\n",
    "        print(i, all_scores[-1].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>0</th>\n",
       "      <th>final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8527</th>\n",
       "      <td>CCN(CC)C(=O)C1C=C2c3cccc4[nH]cc(c34)CC2N(C)C1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8601</th>\n",
       "      <td>CCN(C(=O)c1c[nH]c2cccc(C(=O)O)c12)C1CN(C)C1</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8667</th>\n",
       "      <td>CCN(C(=O)c1c[nH]c2cccc(C(=O)O)c12)N1C[C@H](C)C...</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.303030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8668</th>\n",
       "      <td>CCN(C(=O)c1c[nH]c2cccc(C(=O)O)c12)C1CN(C)N1</td>\n",
       "      <td>0.309278</td>\n",
       "      <td>0.309278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8686</th>\n",
       "      <td>CCN(C(=O)c1c[nH]c2cccc(C(=O)O)c12)C1CN1C</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>CCN(C(=O)c1c[nH]c2cccc(C(=O)O)c12)C1CN(C)S1(=O)=O</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.313131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8693</th>\n",
       "      <td>CCN(C(=O)c1c[nH]c2cccc(C(=O)O)c12)C1CN1N</td>\n",
       "      <td>0.302083</td>\n",
       "      <td>0.302083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8696</th>\n",
       "      <td>CCN(CC)C(=O)c1c[nH]c2cccc(C(=O)O)c12</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.310345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8720</th>\n",
       "      <td>CCN(C(=O)C(=O)c1c[nH]c2cccc(C(=O)O)c12)C1CN1C</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.340426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 smiles         0     final\n",
       "8527      CCN(CC)C(=O)C1C=C2c3cccc4[nH]cc(c34)CC2N(C)C1  1.000000  1.000000\n",
       "8601        CCN(C(=O)c1c[nH]c2cccc(C(=O)O)c12)C1CN(C)C1  0.312500  0.312500\n",
       "8667  CCN(C(=O)c1c[nH]c2cccc(C(=O)O)c12)N1C[C@H](C)C...  0.303030  0.303030\n",
       "8668        CCN(C(=O)c1c[nH]c2cccc(C(=O)O)c12)C1CN(C)N1  0.309278  0.309278\n",
       "8686           CCN(C(=O)c1c[nH]c2cccc(C(=O)O)c12)C1CN1C  0.347826  0.347826\n",
       "8690  CCN(C(=O)c1c[nH]c2cccc(C(=O)O)c12)C1CN(C)S1(=O)=O  0.313131  0.313131\n",
       "8693           CCN(C(=O)c1c[nH]c2cccc(C(=O)O)c12)C1CN1N  0.302083  0.302083\n",
       "8696               CCN(CC)C(=O)c1c[nH]c2cccc(C(=O)O)c12  0.310345  0.310345\n",
       "8720      CCN(C(=O)C(=O)c1c[nH]c2cccc(C(=O)O)c12)C1CN1C  0.340426  0.340426"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template.soft_log[template.soft_log.final>0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<rdkit.Chem.rdchem.Mol at 0x1a08586cd00>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_mol('CCN(C(=O)C(=O)c1c[nH]c2cccc(C(=O)O)c12)C1CN1C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch/models roadmap\n",
    "\n",
    "torch_core\n",
    "    tensor operations\n",
    "    gather\n",
    "    \n",
    "dataloaders\n",
    "    vocab\n",
    "    dataset\n",
    "    dataloader\n",
    "\n",
    "models\n",
    "    LSTM LM\n",
    "    VAE\n",
    "    transformer\n",
    "    contain supervised training loop\n",
    "    dataset/dataloader\n",
    "\n",
    "fastai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "move onto torch/models\n",
    "get protein model running\n",
    "come back to chem/templates, remake with protein variants. code will hopefully be simpler\n",
    "\n",
    "\n",
    "get collab working\n",
    "get google search working\n",
    "\n",
    "torch core\n",
    "models (lstm, vae, transformer)\n",
    "    work in protein stuff here\n",
    "\n",
    "score functions\n",
    "\n",
    "training loop\n",
    "\n",
    "poicy gradients\n",
    "\n",
    "q-network\n",
    "\n",
    "diff-loss\n",
    "\n",
    "exploration strategies\n",
    "\n",
    "combichem\n",
    "\n",
    "pharmacophore \n",
    "\n",
    "\n",
    "pages\n",
    "overview\n",
    "\n",
    "generrative screening primerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(math.tanh((step - 15000)/1000) + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12f7a0438>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAa/klEQVR4nO3deXDb533n8feXBElREnVT90FJlmjJiRxbtOy6tR0naSJfVbvJZO1m05yrasfuNLOzM3bH26Qz/mfTTDq72zjWKqnG9qausmncRutV4nbWSez1EYuSLdmSJZnUSR0kSB28JJIAvvsHIAWmCRIkAfx+AD+vGQ7xOwB8/QD6+OHzOx5zd0REpPiVBV2AiIjkhgJdRKREKNBFREqEAl1EpEQo0EVESkQkqDeeM2eO19XVBfX2IiJFac+ePe3uXjvUtsACva6ujsbGxqDeXkSkKJnZiUzbNOQiIlIiFOgiIiVCgS4iUiIU6CIiJUKBLiJSIkYMdDPbbmZtZvZuhu1mZv/dzJrMbL+Z3Zz7MkVEZCTZ9NCfBjYOs/0eYFXqZzPw1PjLEhGR0RrxPHR3f9nM6obZZRPwrCfvw/uGmc0wswXufjZHNYqI5IW709sfp7svRteVGN19MXr7YgwknFg8wUA8wUDciSWSvwfiCWJxJ5Zw3B13cJyEc+3x1TuSJxKO88H17sl1t9TN4s7VQ14bNC65uLBoEXAqbbklte5DgW5mm0n24lm6dGkO3lpEJLOO7j4Ot3bR1NbN6YuXab10hXOdVzh36Qod3f1098co9JQQZrDlrpWhDXQbYt2QTeTu24BtAA0NDZpZQ0Ry6lh7D682tfN6cwdvHj9PtKvv2rbK8jLmTa9i/rRJfGTRdOZMrWLapAhTqiJMnRRhalWEmkkRqisiVEaMSFkZFeVlVJQbkfIyImVGZST5O1JWhpUlw6/MDDMwkr/5wDows9Tv5ON8ykWgtwBL0pYXA2dy8LoiIiO60NPPzn1n+MmeU7x7uhOA+dMm8XvXzeGGhdOon19D/bwaamuq8h6oQctFoO8EHjGzHcCtwCWNn4tIvp29dJnvvdTETxpb6I8nuGHhNL55/1ruvn4udbMnl3x4D2XEQDezfwA+DswxsxbgW0AFgLtvBXYB9wJNQC/wlXwVKyLSH0vwg1eO8rcvvU884Xxu/RK+eNsy1i6cFnRpgcvmLJeHRtjuwMM5q0hEJIOTHb382Y632HfqIhtvmM/j961hyazJQZcVGoHdPldEZDR2Hz/P159pJOHO979wM/d+dEHQJYWOAl1EQu+lQ61s+dFeFs+s5ukvb2DpbPXKh6JAF5FQe725gy0/2kv9vBqe/eoGZk6pDLqk0NLNuUQktI5Gu9n8bCPLZk3mGYX5iBToIhJKPX0xtvxoDxWRMp7+6gZmKcxHpEAXkVB64oWDNLV187cP3cSiGdVBl1MUFOgiEjqvvB9lx+5TbL5zJb973ZygyykaCnQRCZUrA3H+4vl3WDFnCt/41KqgyykqOstFREJl+6vHaLlwmef+/a1MqigPupyioh66iIRGR3cfT/2ymU+tmcvtKzXUMloKdBEJjad+1UzvQJzH7rk+6FKKkgJdRELhQk8/z715kk03LuS6uTVBl1OUFOgiEgrPvn6C3v44f3rXyqBLKVoKdBEJ3JWBOM+8fpxPXj+X+vnqnY+VAl1EAvd/9p/lfE8/X7tjedClFDUFuogEbsfukyyfM4XfWTE76FKKmgJdRAL1fmsXu49f4KENSybktHG5pEAXkUD9ePcpKsqNz968OOhSip4CXUQCE084O/ed4eP1c5k9tSrocoqeAl1EArP7+Hnauvp44MaFQZdSEhToIhKYF/afobqinE+tmRt0KSVBgS4igYjFE/z8nXN8Ys1cJlfqPoG5oEAXkUDsPn6Bjp5+7v/ogqBLKRkKdBEJxEuHWqksL+OO1bVBl1IyFOgiEoiXDrVx64pZTK3ScEuuKNBFpOCOt/fQHO3hE9frYGguKdBFpOBeOtQGoEDPMQW6iBTcr45EWVE7hWWzpwRdSklRoItIQfXHEuw+dp47rtMUc7mmQBeRgnr71EUuD8S5XYGecwp0ESmo15rbKTO4bblulZtrWQW6mW00s8Nm1mRmjw2xfbqZ/W8z22dmB8zsK7kvVURKwWtNHXxk0XSmT64IupSSM2Kgm1k58CRwD7AWeMjM1g7a7WHgoLvfCHwc+K6ZVea4VhEpcr39Md46dYHfWaneeT5k00PfADS5+1F37wd2AJsG7eNAjSXvTj8VOA/EclqpiBS9vScuMhB3zUyUJ9kE+iLgVNpyS2pduu8Ba4AzwDvAn7t7YvALmdlmM2s0s8ZoNDrGkkWkWDWeOI8Z3LxsZtCllKRsAn2oOaF80PJngLeBhcDHgO+Z2bQPPcl9m7s3uHtDba3u3yAy0ew5cYH6eTVMm6Tx83zIJtBbgCVpy4tJ9sTTfQV43pOagGPA9bkpUURKQTzhvHXyIg116p3nSzaBvhtYZWbLUwc6HwR2DtrnJPBJADObB9QDR3NZqIgUt0PnOunui9GwbFbQpZSsEW9z5u4xM3sEeBEoB7a7+wEz25LavhV4AnjazN4hOUTzqLu357FuESkye09cAGC9xs/zJqv7Vrr7LmDXoHVb0x6fAT6d29JEpJQ0nrjAvGlVLJ5ZHXQpJUtXiopIQbx96iI3LZlJ8uxmyQcFuojk3cXefk509LJuyfSgSylpCnQRybv9LZcAuHHxjIArKW0KdBHJu/0tFwH4yCL10PNJgS4iebe/5RIr5kxherUuKMonBbqI5N3+lkt8dLF65/mmQBeRvGrrvMK5zius0/h53inQRSSv3jmdPCC6Tj30vFOgi0heHTrXBcD182sCrqT0KdBFJK8Onu1kyaxqanSHxbxToItIXh0628ma+R+6m7bkgQJdRPLmykCcY+09XL9AgV4ICnQRyZsjrV0kHNYu0Ph5ISjQRSRvDp29ekBUPfRCUKCLSN4cPNvJ5Mpyls6aHHQpE4ICXUTy5tC5Turn11BWplvmFoICXUTywt1572yXhlsKSIEuInlxrvMKly4P6IBoASnQRSQvrh0Q1SmLBaNAF5G8OHi2E4B6XfJfMAp0EcmLQ+e6WDyzmmm65L9gFOgikheHznbqgGiBKdBFJOeuDMQ52t6jA6IFpkAXkZxrausmnnAdEC0wBbqI5NzVe6DrgGhhKdBFJOeao91UlBvLdMl/QSnQRSTnmtq6qZs9hUi5IqaQ1NoiknPN0W6umzs16DImHAW6iORUfyzBiY5eVtYq0AtNgS4iOXXyfA/xhKuHHoCsAt3MNprZYTNrMrPHMuzzcTN728wOmNmvc1umiBSLprZuAPXQAxAZaQczKweeBH4faAF2m9lOdz+Yts8M4PvARnc/aWZz81WwiIRbc7QHgBW1UwKuZOLJpoe+AWhy96Pu3g/sADYN2uePgefd/SSAu7fltkwRKRZNbd0snD6JKVUj9hclx7IJ9EXAqbTlltS6dKuBmWb2KzPbY2Z/MtQLmdlmM2s0s8ZoNDq2ikUk1Jraulmp8fNAZBPoQ80d5YOWI8B64D7gM8BfmtnqDz3JfZu7N7h7Q21t7aiLFZFwc3eao90aPw9INn8TtQBL0pYXA2eG2Kfd3XuAHjN7GbgROJKTKkWkKJy9dIXe/rjOcAlINj303cAqM1tuZpXAg8DOQfv8DLjDzCJmNhm4FXgvt6WKSNg1R3WGS5BG7KG7e8zMHgFeBMqB7e5+wMy2pLZvdff3zOwXwH4gAfzQ3d/NZ+EiEj5XT1lUDz0YWR2GdvddwK5B67YOWv4O8J3clSYixaY52s20SRHmTK0MupQJSVeKikjONLUl7+FiNtS5FJJvCnQRyZnmaI/GzwOkQBeRnLh0eYBoV5/GzwOkQBeRnNAZLsFToItITugMl+Ap0EUkJ5qj3VSWl7F4ZnXQpUxYCnQRyYnmtm6Wz9G0c0FSy4tITjRHe1g5V7fMDZICXUTGrS8W50RHD9fpgGigFOgiMm7H23tJOLptbsAU6CIybjplMRwU6CIybppHNBwU6CIybs3RbhbNqKa6sjzoUiY0BbqIjNvVm3JJsBToIjIuiYRzVDflCgUFuoiMy5lLl7k8oGnnwkCBLiLj0hztAWBlrS4qCpoCXUTGRTflCg8FuoiMS3O0mxmTK5g1RdPOBU2BLiLj0tTWzXW1mnYuDBToIjIuR6PdOsMlJBToIjJmF3v7ae/u1/h5SCjQRWTMrt3DRbfNDQUFuoiM2bUzXGprAq5EQIEuIuPQ1NZNZaSMRZp2LhQU6CIyZs3RHlbMmUJ5mc5wCQMFuoiMWVNbtya1CBEFuoiMyZWBOKcu9GrauRBRoIvImBxr78E17VyoKNBFZEyunrKoHnp4KNBFZEya2roxgxW6y2JoZBXoZrbRzA6bWZOZPTbMfreYWdzMPpe7EkUkjJqjPSyeWc2kCk07FxYjBrqZlQNPAvcAa4GHzGxthv2+DbyY6yJFJHya2nQPl7DJpoe+AWhy96Pu3g/sADYNsd+fAT8F2nJYn4iEUDzhHI12a/w8ZLIJ9EXAqbTlltS6a8xsEfBHwNbhXsjMNptZo5k1RqPR0dYqIiFx6nwvfbEEq+fpkv8wySbQh7oEzAct/1fgUXePD/dC7r7N3RvcvaG2tjbbGkUkZI60dgGwap566GESyWKfFmBJ2vJi4MygfRqAHakb3M8B7jWzmLv/c06qFJFQ+W2gq4ceJtkE+m5glZktB04DDwJ/nL6Duy+/+tjMngZeUJiLlK4jrd0smlHN1KpsIkQKZcRPw91jZvYIybNXyoHt7n7AzLaktg87bi4ipedIaxerNdwSOln979XddwG7Bq0bMsjd/cvjL0tEwioWT3A02sNd9ToOFja6UlRERuV4Ry/98QSr52r8PGwU6CIyKlcPiNbPV6CHjQJdREblSGsXZugq0RBSoIvIqBxp7WLZrMlUV+oeLmGjQBeRUTnS2q3zz0NKgS4iWeuLxTne3qNTFkNKgS4iWTvW3kMs4bqHS0gp0EUka0dak7MUKdDDSYEuIlk7cq6L8jLTLEUhpUAXkawdae2ibvZkqiI6wyWMFOgikrXkPVw03BJWCnQRycrl/jgnz/fqlMUQU6CLSFYOt3aRcFi7YFrQpUgGCnQRycrBM50A3LBQgR5WCnQRycrBs5eomRRh8czqoEuRDBToIpKVA2c6WbtgGqmpJiWEFOgiMqJ4wjl0tou1Gm4JNQW6iIzoeEcPlwfiOiAacgp0ERnR1QOi6qGHmwJdREZ04EwnFeXGKk07F2oKdBEZ0TunL1I/v4bKiCIjzPTpiMiwEglnf8sl1i2eEXQpMgIFuogM63hHD11XYty4eHrQpcgIFOgiMqx3Tl8CUA+9CCjQRWRY+05dYlJFGavmatq5sFOgi8iw9rdc5IaF04mUKy7CTp+QiGQUiyc4cKaTdRo/LwoKdBHJ6NC5Li4PxPnYEo2fFwMFuohktOfEBQDWL5sZcCWSDQW6iGS058QF5k+bxKIZumVuMcgq0M1so5kdNrMmM3tsiO1fMLP9qZ/XzOzG3JcqIoW258QF1tfN1C1zi8SIgW5m5cCTwD3AWuAhM1s7aLdjwF3uvg54AtiW60JFpLDOXrrM6YuXWb9Uwy3FIpse+gagyd2Puns/sAPYlL6Du7/m7hdSi28Ai3NbpogUWuPx5D/phjoFerHIJtAXAafSlltS6zL5GvDzoTaY2WYzazSzxmg0mn2VIlJwe05coLqinDW6B3rRyCbQhxo88yF3NLubZKA/OtR2d9/m7g3u3lBbW5t9lSJScK83d9BQN5MKXVBUNLL5pFqAJWnLi4Ezg3cys3XAD4FN7t6Rm/JEJAjRrj4Ot3Zx+8o5QZcio5BNoO8GVpnZcjOrBB4EdqbvYGZLgeeBL7r7kdyXKSKF9PrRZJ/s9pWzA65ERiMy0g7uHjOzR4AXgXJgu7sfMLMtqe1bgW8Cs4Hvp05virl7Q/7KFpF8er25nZpJET6ySJf8F5MRAx3A3XcBuwat25r2+OvA13NbmogE5dWmDm5bMZvyMp1/Xkx0tENEPuDU+V5Onu/VcEsRUqCLyAf88nAbAHet1ploxUaBLiIf8NKhNpbPmcKKWk1oUWwU6CJyTW9/jNeaO7i7fm7QpcgYKNBF5JpXmzrojyX45BoFejFSoIvINS8damVqVYRb6mYFXYqMgQJdRAAYiCd48UArd18/l8qIoqEY6VMTEQBea+7gfE8/D6xbEHQpMkYKdBEB4IV9Z6ipinBXvU5XLFYKdBGhLxbnFwfO8ekb5lMVKQ+6HBkjBbqI8NJ7bXRdifHAjRpuKWYKdBHhuTdPsnD6JO5YpeGWYqZAF5ngTp3v5ZX32/n8LUt0M64ip0AXmeB27D5JmcHnG5aMvLOEmgJdZALr7Y/x3G9O8onr57JwRnXQ5cg4KdBFJrD/tfsUF3oH+NO7VgZdiuSAAl1kghqIJ/jBK8doWDZTl/qXCAW6yAT10z0tnL54mS3qnZcMBbrIBNTbH+Nv/vUINy+doTsrlhAFusgE9IOXj9HW1cfj960hNbG7lAAFusgEc6y9h+//qol7Pzqf9cs0dl5KFOgiE0gi4Tz6j/upipTxrQduCLocyTEFusgE8j9ePsqbx8/zl/evZd60SUGXIzmmQBeZIF5tauc7Lx7ivnUL+Nz6xUGXI3mgQBeZAA6f6+Lh5/ayonYqf/3ZdToQWqIU6CIl7lh7D1/8u99QWV7G9i/dwpSqSNAlSZ7okxUpYW+dvMDXnmkEYMfm21g6e3LAFUk+qYcuUoLcnWdfP86/3fYGNZMiPP8fbmf1vJqgy5I8Uw9dpMQ0R7v51s8O8P+a2rm7vpbvfv5jzJpSGXRZUgAKdJES8X5rFz985Rg/3dtCdWU5T2y6gS/cuowyTVoxYSjQRYpYe3cfv3j3HD/Z08K+UxepjJTx725bxsN3X0dtTVXQ5UmBZRXoZrYR+G9AOfBDd/8vg7Zbavu9QC/wZXffm+NaRSa0/liC5mg3R1q7eOvkRV5v7uBwaxcA9fNq+M/3reEPb1rEnKkK8olqxEA3s3LgSeD3gRZgt5ntdPeDabvdA6xK/dwKPJX6LSIpiYTTH08wEE8wEHf6Y8nHfbEEPX0xOq8McOnyb386L8eIdvVx5uJlzly6zOkLl4klHIBJFWXcUjeLTTct5M5VtdywcJrOLZeseugbgCZ3PwpgZjuATUB6oG8CnnV3B94wsxlmtsDdz+a64F8fifLECweH3JZ8+yHWD/eCw2zMtCnT+wz/nOHeZ5jXy7BpuNcbzljaKGMNY6h7uPca/r9pDG003KvlsB1Ger1Y3BmIJ66FcbYqy8uYPbWShTOqWbd4BvevW0D9/GnUz6thRe0UKsp1kpp8UDaBvgg4lbbcwod730Ptswj4QKCb2WZgM8DSpUtHWysAU6si1A93+lWGTspwfZfhejaZtgzXGcr8nNG/z3AbbZhnja2+4Z4z9MZhnzOG/6ix1D3c88bSRmP9rmRSUW5URsqoKE/+VKUe/3adMbUqwrTqCqan/VRFytTrllHJJtCH+kYN7mpksw/uvg3YBtDQ0DCmPub6ZTNZv2zmWJ4qIlLSsvmbrQVYkra8GDgzhn1ERCSPsgn03cAqM1tuZpXAg8DOQfvsBP7Ekm4DLuVj/FxERDIbccjF3WNm9gjwIsnTFre7+wEz25LavhXYRfKUxSaSpy1+JX8li4jIULI6D93dd5EM7fR1W9MeO/BwbksTEZHR0HlPIiIlQoEuIlIiFOgiIiVCgS4iUiJsuMvY8/rGZlHgxBifPgdoz2E5uRTW2lTX6IS1LghvbaprdMZa1zJ3rx1qQ2CBPh5m1ujuDUHXMZSw1qa6RiesdUF4a1Ndo5OPujTkIiJSIhToIiIlolgDfVvQBQwjrLWprtEJa10Q3tpU1+jkvK6iHEMXEZEPK9YeuoiIDKJAFxEpEUUX6Ga20cwOm1mTmT0WYB1LzOyXZvaemR0wsz9Prf8rMzttZm+nfu4NoLbjZvZO6v0bU+tmmdm/mtn7qd8FnyXEzOrT2uVtM+s0s28E0WZmtt3M2szs3bR1GdvIzP4i9Z07bGafKXBd3zGzQ2a238z+ycxmpNbXmdnltHbbmvmV81JXxs+tUO01TG0/TqvruJm9nVpfkDYbJh/y+x1z96L5IXn73mZgBVAJ7APWBlTLAuDm1OMa4AiwFvgr4D8F3E7HgTmD1v018Fjq8WPAt0PwWZ4DlgXRZsCdwM3AuyO1Uepz3QdUActT38HyAtb1aSCSevzttLrq0vcLoL2G/NwK2V6Zahu0/bvANwvZZsPkQ16/Y8XWQ782YbW79wNXJ6wuOHc/6+57U4+7gPdIzqMaVpuAZ1KPnwH+MMBaAD4JNLv7WK8WHhd3fxk4P2h1pjbaBOxw9z53P0byvv8bClWXu/+Lu8dSi2+QnBGsoDK0VyYFa6+RarPkpKyfB/4hX++foaZM+ZDX71ixBXqmyagDZWZ1wE3Ab1KrHkn9ebw9iKENkvO5/ouZ7bHkxNwA8zw1i1Tq99wA6kr3IB/8RxZ0m0HmNgrT9+6rwM/Tlpeb2Vtm9mszuyOAeob63MLUXncAre7+ftq6grbZoHzI63es2AI9q8moC8nMpgI/Bb7h7p3AU8BK4GPAWZJ/7hXa77r7zcA9wMNmdmcANWRkyakM/wD4SWpVGNpsOKH43pnZ40AM+PvUqrPAUne/CfiPwHNmNq2AJWX63ELRXikP8cGOQ0HbbIh8yLjrEOtG3WbFFuihmozazCpIflh/7+7PA7h7q7vH3T0B/IA8/qmZibufSf1uA/4pVUOrmS1I1b0AaCt0XWnuAfa6eyuEo81SMrVR4N87M/sScD/wBU8Nuqb+PO9IPd5Dctx1daFqGuZzC7y9AMwsAvwb4MdX1xWyzYbKB/L8HSu2QM9mwuqCSI3N/R3wnrv/Tdr6BWm7/RHw7uDn5rmuKWZWc/UxyQNq75Jspy+ldvsS8LNC1jXIB3pNQbdZmkxttBN40MyqzGw5sAp4s1BFmdlG4FHgD9y9N219rZmVpx6vSNV1tIB1ZfrcAm2vNJ8CDrl7y9UVhWqzTPlAvr9j+T7am4ejx/eSPGLcDDweYB2/R/JPov3A26mfe4H/CbyTWr8TWFDgulaQPFq+DzhwtY2A2cD/Bd5P/Z4VULtNBjqA6WnrCt5mJP+HchYYINk7+tpwbQQ8nvrOHQbuKXBdTSTHV69+z7am9v1s6jPeB+wFHihwXRk/t0K1V6baUuufBrYM2rcgbTZMPuT1O6ZL/0VESkSxDbmIiEgGCnQRkRKhQBcRKREKdBGREqFAFxEpEQp0EZESoUAXESkR/x/4sXZCQ2Jk0gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([(math.tanh((step - 15000)/1000) + 1) / 2 for step in range(0,20000,100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
