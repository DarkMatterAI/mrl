{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmai/miniconda3/envs/mrl/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: to-Python converter for boost::shared_ptr<RDKit::FilterCatalogEntry const> already registered; second conversion method ignored.\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from mrl.imports import *\n",
    "from mrl.core import *\n",
    "from mrl.chem import *\n",
    "from mrl.templates import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrl.torch_imports import *\n",
    "from mrl.torch_core import *\n",
    "from mrl.layers import *\n",
    "from mrl.dataloaders import *\n",
    "from mrl.g_models import *\n",
    "from mrl.agent import *\n",
    "from mrl.vocab import *\n",
    "from mrl.callbacks import *\n",
    "from mrl.callbacks.template_cb import *\n",
    "from mrl.agent import *\n",
    "from mrl.policy_gradient import *\n",
    "from mrl.loss import *\n",
    "from mrl.sampler import *\n",
    "from mrl.environment import *\n",
    "from mrl.reward import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['ncpus'] = '0'\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoolingHead(nn.Module):\n",
    "    def __init__(self, d_in, dims, d_out, drops, outrange=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = MLP_Encoder(d_in, dims, d_out, drops)\n",
    "        self.outrange = outrange\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        # x - bs, sl, d\n",
    "        # mask - bs, sl\n",
    "        if mask is not None:\n",
    "            lengths = mask.sum(-1)\n",
    "            final_vals = x[torch.arange(x.shape[0]), lengths-1]\n",
    "            pool1 = x.masked_fill(mask.unsqueeze(-1), 0).sum(1)/lengths.unsqueeze(-1)\n",
    "            pool2 = x.masked_fill(mask.unsqueeze(-1), -float('inf')).max(1)[0]\n",
    "        else:\n",
    "            final_vals = x[:,-1]\n",
    "            pool1 = x.mean(1)\n",
    "            pool2 = x.max(1)[0]\n",
    "            \n",
    "        x = torch.cat([final_vals, pool1, pool2], 1)\n",
    "        x = self.layers(x)\n",
    "        \n",
    "        if self.outrange is not None:\n",
    "            x = torch.sigmoid(x) * (self.outrange[1]-self.outrange[0]) + self.outrange[0]\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class Predictive_LSTM(nn.Module):\n",
    "    def __init__(self, d_vocab, d_embedding, d_hidden, n_layers, d_out_lstm,\n",
    "                 head_dims, head_drops, d_out, outrange=None,\n",
    "                 lstm_drop=0., bidir=False,):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(d_vocab, d_embedding)\n",
    "        self.lstm = LSTM(d_embedding, d_hidden, d_out_lstm, n_layers,\n",
    "                                     bidir=bidir, dropout=lstm_drop)\n",
    "        \n",
    "        self.head = PoolingHead(d_out_lstm*3, head_dims, d_out, head_drops, outrange)\n",
    "\n",
    "        \n",
    "    def forward(self, x, hiddens=None, mask=None):\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        encoded, hiddens = self.lstm(x, hiddens)\n",
    "        output = self.head(encoded, mask)\n",
    "        return output\n",
    "    \n",
    "    def freeze_encoder(self):\n",
    "        for p in self.embedding.parameters():\n",
    "            p.requires_grad_(False)\n",
    "            \n",
    "        for p in self.lstm.parameters():\n",
    "            p.requires_grad_(False)\n",
    "    \n",
    "    def load_from_lm(self, lm_model):\n",
    "        if hasattr(lm_model, 'block'):\n",
    "            self.embedding.load_state_dict(lm_model.block.embedding.state_dict())\n",
    "            self.lstm.load_state_dict(lm_model.block.lstm.state_dict())\n",
    "        else:\n",
    "            if hasattr(lm_model, 'lstm'):\n",
    "                self.lstm.load_state_dict(lm_model.lstm.state_dict())\n",
    "                \n",
    "            if hasattr(lm_model, 'embedding'):\n",
    "                self.embedding.load_state_dict(lm_model.embedding.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "current roadmap\n",
    "    python 3.7 upgrade?\n",
    "    Do PR\n",
    "    new branch\n",
    "        change buffer\n",
    "            hold sample aand score\n",
    "            new event workflow\n",
    "        update rewards\n",
    "            make template callback a subset of reward\n",
    "            put standardize/filter functions into new filtering events\n",
    "    Do PR\n",
    "    now we do documentation/update site\n",
    "    combichem\n",
    "    jtnnvae\n",
    "    model zoo\n",
    "    start working on other docs\n",
    "        guides\n",
    "        examples\n",
    "    move to release v0\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "future modules\n",
    "    combichem\n",
    "    pharmacophore\n",
    "    active learning\n",
    "    new models\n",
    "        jtnnvae\n",
    "        flow based\n",
    "    chemprop hooks\n",
    "    huggingface hooks\n",
    "    basic docking\n",
    "        \n",
    "project quality\n",
    "    collab links\n",
    "    google search on site\n",
    "    more documentation\n",
    "\n",
    "Use cases/examples\n",
    "    basic drug design\n",
    "    iterative drug design with dataset building\n",
    "    drug design with docking proxy\n",
    "    proteins/antibodies\n",
    "    polymers\n",
    "    catalyst\n",
    "    materials\n",
    "    \n",
    "guides\n",
    "    generative screening primer\n",
    "    basics\n",
    "        stuff about how bad score functions can be\n",
    "    how to use callbacks\n",
    "    basic drug design\n",
    "    contrastive optimization\n",
    "    latent/prior optimization\n",
    "    training tips/tricks (callback stuff)\n",
    "    \n",
    "paapers to implement\n",
    "    fastai guy - conditional lstm, contrastive\n",
    "    moldqn - dqn sampler (rollout), agent is score function, dqn loss\n",
    "    synthesis constrained? really same as DQN with different rolllout\n",
    "    stoned selfies/genetic algorithm examples\n",
    "    deep drug decoder/paul paper/other conditional generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mrl)",
   "language": "python",
   "name": "mrl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
