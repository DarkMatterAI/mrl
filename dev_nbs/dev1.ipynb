{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmai/miniconda3/envs/mrl/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: to-Python converter for boost::shared_ptr<RDKit::FilterCatalogEntry const> already registered; second conversion method ignored.\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from mrl.imports import *\n",
    "from mrl.core import *\n",
    "from mrl.chem import *\n",
    "from mrl.templates import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrl.torch_imports import *\n",
    "from mrl.torch_core import *\n",
    "from mrl.layers import *\n",
    "from mrl.dataloaders import *\n",
    "from mrl.g_models import *\n",
    "from mrl.agent import *\n",
    "from mrl.vocab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../nbs/files/smiles.csv')\n",
    "# vocab = CharacterVocab(SMILES_CHAR_VOCAB)\n",
    "\n",
    "# vocab = CharacterVocab(AMINO_ACID_VOCAB)\n",
    "\n",
    "vocab = FuncVocab(SELFIES_VOCAB, split_selfie,\n",
    "                  prefunc=smile_to_selfie, postfunc=selfie_to_smile)\n",
    "\n",
    "ds = Text_Dataset(df.smiles.values, vocab)\n",
    "dl = ds.dataloader(16, num_workers=0)\n",
    "loss = CrossEntropy()\n",
    "\n",
    "# encoder = MLP_Encoder(2048, [1024, 512], 512, [0.1, 0.1])\n",
    "# d_vocab = len(vocab.itos)\n",
    "# d_embedding = 256\n",
    "# d_hidden = 1024\n",
    "# d_latent = 512\n",
    "# n_layers = 3\n",
    "# input_dropout = 0.3\n",
    "# lstm_dropout = 0.3\n",
    "# condition_hidden = True\n",
    "# condition_output = False\n",
    "# bos_idx = vocab.stoi['bos']\n",
    "# norm_latent = True\n",
    "\n",
    "# model = Conditional_LSTM_LM(encoder, \n",
    "#                                d_vocab, \n",
    "#                                d_embedding, \n",
    "#                                d_hidden, \n",
    "#                                d_latent, \n",
    "#                                n_layers,\n",
    "#                                input_dropout, \n",
    "#                                lstm_dropout, \n",
    "#                                norm_latent,\n",
    "#                                condition_hidden, \n",
    "#                                condition_output, \n",
    "#                                bos_idx)\n",
    "\n",
    "# d_vocab = len(vocab.itos)\n",
    "# d_embedding = 256\n",
    "# d_hidden = 1024\n",
    "# n_layers = 3\n",
    "# input_dropout = 0.3\n",
    "# lstm_dropout = 0.3\n",
    "# bos_idx = vocab.stoi['bos']\n",
    "# bidir = False\n",
    "# tie_weights = True\n",
    "\n",
    "# model = LSTM_LM(d_vocab, \n",
    "#                 d_embedding,\n",
    "#                 d_hidden, \n",
    "#                 n_layers,\n",
    "#                 input_dropout,\n",
    "#                 lstm_dropout,\n",
    "#                 bos_idx, \n",
    "#                 bidir, \n",
    "#                 tie_weights)\n",
    "\n",
    "d_vocab = len(vocab.itos)\n",
    "d_embedding = 256\n",
    "encoder_d_in = 2048\n",
    "encoder_dims = [1024, 512]\n",
    "encoder_drops = [0.1, 0.1]\n",
    "d_hidden = 1024\n",
    "d_latent = 512\n",
    "n_layers = 3\n",
    "input_dropout = 0.3\n",
    "lstm_dropout = 0.3\n",
    "bidir = False\n",
    "condition_hidden = True\n",
    "condition_output = True\n",
    "bos_idx = vocab.stoi['bos']\n",
    "\n",
    "model = MLP_VAE(\n",
    "            d_vocab,\n",
    "            d_embedding,\n",
    "            encoder_d_in,\n",
    "            encoder_dims,\n",
    "            encoder_drops,\n",
    "            d_hidden,\n",
    "            n_layers,\n",
    "            d_latent,\n",
    "            input_dropout=input_dropout,\n",
    "            lstm_dropout=lstm_dropout,\n",
    "            condition_hidden=condition_hidden,\n",
    "            condition_output=condition_output,\n",
    "            prior=None,\n",
    "            bos_idx=bos_idx,\n",
    "            transition=None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_weights = torch.load('../nbs/untracked_files/fp_vae_chembl_selfies.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weights = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([1024, 2048]),\n",
       " torch.Size([1024]),\n",
       " torch.Size([1024]),\n",
       " torch.Size([1024]),\n",
       " torch.Size([1024]),\n",
       " torch.Size([1024]),\n",
       " torch.Size([]),\n",
       " torch.Size([512, 1024]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([]),\n",
       " torch.Size([512, 512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([79, 256]),\n",
       " torch.Size([4096, 768]),\n",
       " torch.Size([4096, 1024]),\n",
       " torch.Size([4096]),\n",
       " torch.Size([4096]),\n",
       " torch.Size([4096, 1024]),\n",
       " torch.Size([4096, 1024]),\n",
       " torch.Size([4096]),\n",
       " torch.Size([4096]),\n",
       " torch.Size([1024, 1024]),\n",
       " torch.Size([1024, 256]),\n",
       " torch.Size([1024]),\n",
       " torch.Size([1024]),\n",
       " torch.Size([2048, 512]),\n",
       " torch.Size([2048]),\n",
       " torch.Size([2048, 512]),\n",
       " torch.Size([2048]),\n",
       " torch.Size([512, 512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([79, 256]),\n",
       " torch.Size([79]),\n",
       " torch.Size([1024, 512]),\n",
       " torch.Size([1024]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512])]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.shape for k,v in old_weights.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_keys = list(old_weights.keys())\n",
    "new_keys = list(new_weights.keys())\n",
    "\n",
    "for i in range(len(old_keys)):\n",
    "    new_weights[new_keys[i]] = old_weights[old_keys[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_device(model);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, _ = model.sample_no_grad(512, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = [vocab.reconstruct(i) for i in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols = [to_mol(i) for i in smiles]\n",
    "# mols = [to_protein(i) for i in smiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98828125"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([i for i in mols if i is not None])/len(mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.990234375"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(smiles))/len(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../nbs/untracked_files/fp_vae_chembl_selfies.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoolingHead(nn.Module):\n",
    "    def __init__(self, d_in, dims, d_out, drops, outrange=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = MLP_Encoder(d_in, dims, d_out, drops)\n",
    "        self.outrange = outrange\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        # x - bs, sl, d\n",
    "        # mask - bs, sl\n",
    "        if mask is not None:\n",
    "            lengths = mask.sum(-1)\n",
    "            final_vals = x[torch.arange(x.shape[0]), lengths-1]\n",
    "            pool1 = x.masked_fill(mask.unsqueeze(-1), 0).sum(1)/lengths.unsqueeze(-1)\n",
    "            pool2 = x.masked_fill(mask.unsqueeze(-1), -float('inf')).max(1)[0]\n",
    "        else:\n",
    "            final_vals = x[:,-1]\n",
    "            pool1 = x.mean(1)\n",
    "            pool2 = x.max(1)[0]\n",
    "            \n",
    "        x = torch.cat([final_vals, pool1, pool2], 1)\n",
    "        x = self.layers(x)\n",
    "        \n",
    "        if self.outrange is not None:\n",
    "            x = torch.sigmoid(x) * (self.outrange[1]-self.outrange[0]) + self.outrange[0]\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class Predictive_LSTM(nn.Module):\n",
    "    def __init__(self, d_vocab, d_embedding, d_hidden, n_layers, d_out_lstm,\n",
    "                 head_dims, head_drops, d_out, outrange=None,\n",
    "                 lstm_drop=0., bidir=False,):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(d_vocab, d_embedding)\n",
    "        self.lstm = LSTM(d_embedding, d_hidden, d_out_lstm, n_layers,\n",
    "                                     bidir=bidir, dropout=lstm_drop)\n",
    "        \n",
    "        self.head = PoolingHead(d_out_lstm*3, head_dims, d_out, head_drops, outrange)\n",
    "\n",
    "        \n",
    "    def forward(self, x, hiddens=None, mask=None):\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        encoded, hiddens = self.lstm(x, hiddens)\n",
    "        output = self.head(encoded, mask)\n",
    "        return output\n",
    "    \n",
    "    def freeze_encoder(self):\n",
    "        for p in self.embedding.parameters():\n",
    "            p.requires_grad_(False)\n",
    "            \n",
    "        for p in self.lstm.parameters():\n",
    "            p.requires_grad_(False)\n",
    "    \n",
    "    def load_from_lm(self, lm_model):\n",
    "        if hasattr(lm_model, 'block'):\n",
    "            self.embedding.load_state_dict(lm_model.block.embedding.state_dict())\n",
    "            self.lstm.load_state_dict(lm_model.block.lstm.state_dict())\n",
    "        else:\n",
    "            if hasattr(lm_model, 'lstm'):\n",
    "                self.lstm.load_state_dict(lm_model.lstm.state_dict())\n",
    "                \n",
    "            if hasattr(lm_model, 'embedding'):\n",
    "                self.embedding.load_state_dict(lm_model.embedding.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = CharacterVocab(SMILES_CHAR_VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = TextDataset(['CCC'], vocab)\n",
    "\n",
    "d_vocab = len(vocab.itos)\n",
    "d_embedding = 256\n",
    "d_hidden = 1024\n",
    "n_layers = 3\n",
    "lstm_drop = 0.\n",
    "lin_drop = 0.\n",
    "bos_idx = vocab.stoi['bos']\n",
    "bidir = False\n",
    "tie_weights = True\n",
    "\n",
    "lm_model = LSTM_LM(d_vocab, d_embedding, d_hidden, n_layers,\n",
    "                lstm_drop, lin_drop, bos_idx, bidir, tie_weights)\n",
    "\n",
    "lm_model.load_state_dict(torch.load('../nbs/untracked_files/lstm_lm_small.pt', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Predictive_LSTM(d_vocab, d_embedding, d_hidden, n_layers, d_embedding,\n",
    "                        [512, 256], [0.1, 0.1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_from_lm(lm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0181,  0.0324,  0.0202,  ...,  0.0010,  0.0047,  0.0283],\n",
       "        [-0.0101,  0.0228,  0.0193,  ..., -0.0366,  0.0038, -0.0540],\n",
       "        [ 0.0537, -0.0437, -0.0073,  ...,  0.0270, -0.0121,  0.0504],\n",
       "        ...,\n",
       "        [ 0.0567,  0.0338, -0.0113,  ..., -0.0163,  0.0104,  0.0140],\n",
       "        [ 0.0025,  0.0101,  0.0410,  ..., -0.0130, -0.0164, -0.0144],\n",
       "        [ 0.0174,  0.0205,  0.0073,  ...,  0.0442, -0.0021,  0.0154]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.lstm.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "current roadmap\n",
    "    start big rewrite\n",
    "        do reward functions\n",
    "        revisit mol/protein distinctions in template/block\n",
    "    buffer changes\n",
    "        decide rewards will be nondifferentiable, string derived, and hashed\n",
    "        build buffer\n",
    "        score buffer\n",
    "        on batch\n",
    "            live sample\n",
    "            score live sample\n",
    "            buffer sample (scored)\n",
    "            get model outputs\n",
    "            continue\n",
    "    now we do documentation/update site\n",
    "    combichem\n",
    "    jtnnvae\n",
    "    start working on other docs\n",
    "        guides\n",
    "        examples\n",
    "    move to release v0\n",
    "    \n",
    "\n",
    "\n",
    "environment    \n",
    "callbacks (base)\n",
    "log/buffer callbacks\n",
    "samplers\n",
    "agent\n",
    "rewards\n",
    "losses\n",
    "policy gradient\n",
    "\n",
    "callbacks\n",
    "    core\n",
    "    logging\n",
    "    template\n",
    "    \n",
    "agent\n",
    "PG\n",
    "losses\n",
    "samplers\n",
    "rewards\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "future modules\n",
    "    combichem\n",
    "    pharmacophore\n",
    "    active learning\n",
    "    new models\n",
    "        jtnnvae\n",
    "        flow based\n",
    "    chemprop hooks\n",
    "    huggingface hooks\n",
    "        \n",
    "project quality\n",
    "    collab links\n",
    "    google search on site\n",
    "    more documentation\n",
    "\n",
    "Use cases/examples\n",
    "    basic drug design\n",
    "    iterative drug design with dataset building\n",
    "    drug design with docking proxy\n",
    "    proteins/antibodies\n",
    "    polymers\n",
    "    catalyst\n",
    "    materials\n",
    "    \n",
    "guides\n",
    "    generative screening primer\n",
    "    basics\n",
    "        stuff about how bad score functions can be\n",
    "    how to use callbacks\n",
    "    basic drug design\n",
    "    contrastive optimization\n",
    "    latent/prior optimization\n",
    "    training tips/tricks (callback stuff)\n",
    "    \n",
    "paapers to implement\n",
    "    fastai guy - conditional lstm, contrastive\n",
    "    moldqn - dqn sampler (rollout), agent is score function, dqn loss\n",
    "    synthesis constrained? really same as DQN with different rolllout\n",
    "    stoned selfies/genetic algorithm examples\n",
    "    deep drug decoder/paul paper/other conditional generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mrl)",
   "language": "python",
   "name": "mrl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
