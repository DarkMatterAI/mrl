{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/karl/mrl/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/mrl/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: to-Python converter for boost::shared_ptr<RDKit::FilterCatalogEntry const> already registered; second conversion method ignored.\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from mrl.imports import *\n",
    "from mrl.core import *\n",
    "from mrl.chem import *\n",
    "from mrl.templates import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrl.torch_imports import *\n",
    "from mrl.torch_core import *\n",
    "from mrl.layers import *\n",
    "from mrl.dataloaders import *\n",
    "from mrl.g_models import *\n",
    "from mrl.agent import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = torch.rand((32, 90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.ones(values.shape)\n",
    "mask[:, 75:] = 0\n",
    "mask = mask.bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        ...,\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7341, 0.1199, 0.7577,  ..., 0.3650, 0.2875, 0.1340],\n",
       "        [0.1224, 0.0810, 0.0088,  ..., 0.1404, 0.8838, 0.7014],\n",
       "        [0.1240, 0.1228, 0.1735,  ..., 0.6357, 0.5716, 0.8272],\n",
       "        ...,\n",
       "        [0.0856, 0.8900, 0.5229,  ..., 0.4426, 0.8995, 0.6533],\n",
       "        [0.2605, 0.3823, 0.8008,  ..., 0.5164, 0.8860, 0.3829],\n",
       "        [0.2991, 0.2311, 0.8919,  ..., 0.3108, 0.4898, 0.6336]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8125, -1.3386,  0.8953,  ..., -0.4803, -0.7517, -1.2892],\n",
       "        [-1.3297, -1.4749, -1.7278,  ..., -1.2667,  1.3369,  0.6980],\n",
       "        [-1.3244, -1.3284, -1.1509,  ...,  0.4678,  0.2433,  1.1388],\n",
       "        ...,\n",
       "        [-1.4587,  1.3587,  0.0729,  ..., -0.2084,  1.3918,  0.5296],\n",
       "        [-0.8462, -0.4195,  1.0463,  ...,  0.0501,  1.3445, -0.4174],\n",
       "        [-0.7110, -0.9490,  1.3654,  ..., -0.6700, -0.0429,  0.4606]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whiten(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(values - values.mean()).pow(2).sum()/(values.numel()-1)-values.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0815)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5021)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5021)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.sum()/values.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5024)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(values*mask).sum()/mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2880"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whiten2(values, shift_mean=True, mask=None):\n",
    "    if mask is None:\n",
    "        mean = values.mean()\n",
    "        var = values.var()\n",
    "    else:\n",
    "        mean = (values*mask).sum()/mask.sum()\n",
    "        var = ((values-mean)*mask).pow(2).sum()/(mask.sum()-1)\n",
    "        \n",
    "    whitened = (values - mean) * torch.rsqrt(var + 1e-8)\n",
    "    \n",
    "    if not shift_mean:\n",
    "        whitened += mean\n",
    "        \n",
    "    if mask is not None:\n",
    "        whitened = whitened*mask\n",
    "        \n",
    "    return whitened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8125, -1.3386,  0.8953,  ..., -0.4803, -0.7517, -1.2892],\n",
       "        [-1.3297, -1.4749, -1.7278,  ..., -1.2667,  1.3369,  0.6980],\n",
       "        [-1.3244, -1.3284, -1.1509,  ...,  0.4678,  0.2433,  1.1388],\n",
       "        ...,\n",
       "        [-1.4587,  1.3587,  0.0729,  ..., -0.2084,  1.3918,  0.5296],\n",
       "        [-0.8462, -0.4195,  1.0463,  ...,  0.0501,  1.3445, -0.4174],\n",
       "        [-0.7110, -0.9490,  1.3654,  ..., -0.6700, -0.0429,  0.4606]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whiten2(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8125, -1.3386,  0.8953,  ..., -0.4803, -0.7517, -1.2892],\n",
       "        [-1.3297, -1.4749, -1.7278,  ..., -1.2667,  1.3369,  0.6980],\n",
       "        [-1.3244, -1.3284, -1.1509,  ...,  0.4678,  0.2433,  1.1388],\n",
       "        ...,\n",
       "        [-1.4587,  1.3587,  0.0729,  ..., -0.2084,  1.3918,  0.5296],\n",
       "        [-0.8462, -0.4195,  1.0463,  ...,  0.0501,  1.3445, -0.4174],\n",
       "        [-0.7110, -0.9490,  1.3654,  ..., -0.6700, -0.0429,  0.4606]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whiten2(values, mask=torch.ones(values.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(whiten2(values)==whiten2(values, mask=torch.ones(values.shape))).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8113, -1.3390,  0.8941,  ..., -0.0000, -0.0000, -0.0000],\n",
       "        [-1.3302, -1.4754, -1.7282,  ..., -0.0000,  0.0000,  0.0000],\n",
       "        [-1.3248, -1.3289, -1.1514,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [-1.4592,  1.3574,  0.0720,  ..., -0.0000,  0.0000,  0.0000],\n",
       "        [-0.8468, -0.4203,  1.0450,  ...,  0.0000,  0.0000, -0.0000],\n",
       "        [-0.7116, -0.9496,  1.3641,  ..., -0.0000, -0.0000,  0.0000]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whiten2(values, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7341, 0.1199, 0.7577,  ..., 0.3650, 0.2875, 0.1340],\n",
       "        [0.1224, 0.0810, 0.0088,  ..., 0.1404, 0.8838, 0.7014],\n",
       "        [0.1240, 0.1228, 0.1735,  ..., 0.6357, 0.5716, 0.8272],\n",
       "        ...,\n",
       "        [0.0856, 0.8900, 0.5229,  ..., 0.4426, 0.8995, 0.6533],\n",
       "        [0.2605, 0.3823, 0.8008,  ..., 0.5164, 0.8860, 0.3829],\n",
       "        [0.2991, 0.2311, 0.8919,  ..., 0.3108, 0.4898, 0.6336]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    mean, var = torch.mean(values), torch.var(values)\n",
    "    whitened = (values - mean) * torch.rsqrt(var + 1e-8)\n",
    "    if not shift_mean:\n",
    "        whitened += mean\n",
    "    return whitened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoolingHead(nn.Module):\n",
    "    def __init__(self, d_in, dims, d_out, drops, outrange=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = MLP_Encoder(d_in, dims, d_out, drops)\n",
    "        self.outrange = outrange\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        # x - bs, sl, d\n",
    "        # mask - bs, sl\n",
    "        if mask is not None:\n",
    "            lengths = mask.sum(-1)\n",
    "            final_vals = x[torch.arange(x.shape[0]), lengths-1]\n",
    "            pool1 = x.masked_fill(mask.unsqueeze(-1), 0).sum(1)/lengths.unsqueeze(-1)\n",
    "            pool2 = x.masked_fill(mask.unsqueeze(-1), -float('inf')).max(1)[0]\n",
    "        else:\n",
    "            final_vals = x[:,-1]\n",
    "            pool1 = x.mean(1)\n",
    "            pool2 = x.max(1)[0]\n",
    "            \n",
    "        x = torch.cat([final_vals, pool1, pool2], 1)\n",
    "        x = self.layers(x)\n",
    "        \n",
    "        if self.outrange is not None:\n",
    "            x = torch.sigmoid(x) * (self.outrange[1]-self.outrange[0]) + self.outrange[0]\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class Predictive_LSTM(nn.Module):\n",
    "    def __init__(self, d_vocab, d_embedding, d_hidden, n_layers, d_out_lstm,\n",
    "                 head_dims, head_drops, d_out, outrange=None,\n",
    "                 lstm_drop=0., bidir=False,):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(d_vocab, d_embedding)\n",
    "        self.lstm = LSTM(d_embedding, d_hidden, d_out_lstm, n_layers,\n",
    "                                     bidir=bidir, dropout=lstm_drop)\n",
    "        \n",
    "        self.head = PoolingHead(d_out_lstm*3, head_dims, d_out, head_drops, outrange)\n",
    "\n",
    "        \n",
    "    def forward(self, x, hiddens=None, mask=None):\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        encoded, hiddens = self.lstm(x, hiddens)\n",
    "        output = self.head(encoded, mask)\n",
    "        return output\n",
    "    \n",
    "    def freeze_encoder(self):\n",
    "        for p in self.embedding.parameters():\n",
    "            p.requires_grad_(False)\n",
    "            \n",
    "        for p in self.lstm.parameters():\n",
    "            p.requires_grad_(False)\n",
    "    \n",
    "    def load_from_lm(self, lm_model):\n",
    "        if hasattr(lm_model, 'block'):\n",
    "            self.embedding.load_state_dict(lm_model.block.embedding.state_dict())\n",
    "            self.lstm.load_state_dict(lm_model.block.lstm.state_dict())\n",
    "        else:\n",
    "            if hasattr(lm_model, 'lstm'):\n",
    "                self.lstm.load_state_dict(lm_model.lstm.state_dict())\n",
    "                \n",
    "            if hasattr(lm_model, 'embedding'):\n",
    "                self.embedding.load_state_dict(lm_model.embedding.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = CharacterVocab(SMILES_CHAR_VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = TextDataset(['CCC'], vocab)\n",
    "\n",
    "d_vocab = len(vocab.itos)\n",
    "d_embedding = 256\n",
    "d_hidden = 1024\n",
    "n_layers = 3\n",
    "lstm_drop = 0.\n",
    "lin_drop = 0.\n",
    "bos_idx = vocab.stoi['bos']\n",
    "bidir = False\n",
    "tie_weights = True\n",
    "\n",
    "lm_model = LSTM_LM(d_vocab, d_embedding, d_hidden, n_layers,\n",
    "                lstm_drop, lin_drop, bos_idx, bidir, tie_weights)\n",
    "\n",
    "lm_model.load_state_dict(torch.load('../nbs/untracked_files/lstm_lm_small.pt', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Predictive_LSTM(d_vocab, d_embedding, d_hidden, n_layers, d_embedding,\n",
    "                        [512, 256], [0.1, 0.1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_from_lm(lm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0181,  0.0324,  0.0202,  ...,  0.0010,  0.0047,  0.0283],\n",
       "        [-0.0101,  0.0228,  0.0193,  ..., -0.0366,  0.0038, -0.0540],\n",
       "        [ 0.0537, -0.0437, -0.0073,  ...,  0.0270, -0.0121,  0.0504],\n",
       "        ...,\n",
       "        [ 0.0567,  0.0338, -0.0113,  ..., -0.0163,  0.0104,  0.0140],\n",
       "        [ 0.0025,  0.0101,  0.0410,  ..., -0.0130, -0.0164, -0.0144],\n",
       "        [ 0.0174,  0.0205,  0.0073,  ...,  0.0442, -0.0021,  0.0154]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.lstm.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../nbs/files/smiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_sequence_prediction_collate(batch, pad_idx, batch_first=True):\n",
    "    \n",
    "    x,y = sequence_prediction_collate(batch, pad_idx, batch_first)\n",
    "    mask = ~(x==pad_idx)\n",
    "    return ((x,None,mask), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = partial(masked_sequence_prediction_collate, pad_idx=vocab.stoi['pad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = TextPredictionDataset(df.smiles.values, np.array([0.]*df.shape[0]), vocab,\n",
    "                          collate_function=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0, 22, 26, 33, 11, 36, 33,  5, 29, 22, 22,  5, 19, 27,  6, 26, 33, 12,\n",
       "         33, 33,  5, 22, 35,  6, 33, 33, 33, 12, 27, 22,  6, 36, 33, 12, 33, 33,\n",
       "         33, 33, 33, 11, 12,  1]), tensor([0.]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(ds.dataloader(16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0, 22, 26,  ...,  2,  2,  2],\n",
       "         [ 0, 22, 27,  ...,  2,  2,  2],\n",
       "         [ 0, 22, 33,  ...,  2,  2,  2],\n",
       "         ...,\n",
       "         [ 0, 22, 33,  ...,  2,  2,  2],\n",
       "         [ 0, 22, 22,  ...,  2,  2,  2],\n",
       "         [ 0, 27, 19,  ...,  2,  2,  2]]),\n",
       " None,\n",
       " tensor([[ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         ...,\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False],\n",
       "         [ True,  True,  True,  ..., False, False, False]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2800],\n",
       "        [ 0.0608],\n",
       "        [-0.1827],\n",
       "        [-0.2925],\n",
       "        [ 0.2265],\n",
       "        [ 0.2253],\n",
       "        [ 0.0656],\n",
       "        [-0.0847],\n",
       "        [-0.8578],\n",
       "        [-0.3824],\n",
       "        [-0.1353],\n",
       "        [-0.4450],\n",
       "        [ 0.0713],\n",
       "        [ 0.5608],\n",
       "        [ 0.3842],\n",
       "        [-0.3874]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3943830166921718"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.99907**1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = CharacterVocab(SMILES_CHAR_VOCAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = TextDataset(['CCC'], vocab)\n",
    "\n",
    "d_vocab = len(vocab.itos)\n",
    "d_embedding = 256\n",
    "d_hidden = 1024\n",
    "n_layers = 3\n",
    "lstm_drop = 0.\n",
    "lin_drop = 0.\n",
    "bos_idx = vocab.stoi['bos']\n",
    "bidir = False\n",
    "tie_weights = True\n",
    "\n",
    "model = LSTM_LM(d_vocab, d_embedding, d_hidden, n_layers,\n",
    "                lstm_drop, lin_drop, bos_idx, bidir, tie_weights)\n",
    "\n",
    "model.load_state_dict(torch.load('../nbs/untracked_files/lstm_lm_small.pt', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(model, 'block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_LM(\n",
       "  (block): LSTM_Block(\n",
       "    (embedding): Embedding(42, 256)\n",
       "    (lstm): LSTM(\n",
       "      (lstms): ModuleList(\n",
       "        (0): LSTM(256, 1024, batch_first=True)\n",
       "        (1): LSTM(1024, 1024, batch_first=True)\n",
       "        (2): LSTM(1024, 256, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (head): Linear(in_features=256, out_features=42, bias=True)\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueHead(nn.Module):\n",
    "    def __init__(self, d_in, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.layer = nn.Linear(d_in, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer(self.drop(x)).squeeze(-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vh = ValueHead(256)\n",
    "# vh = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = GenerativeAgent(model, vocab, CrossEntropy(), ds, value_head=vh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1016, -0.0330,  0.0345,  ..., -0.0337,  0.1236,  0.0771],\n",
       "        [ 0.4183, -0.0701, -0.2043,  ...,  0.5718,  0.0684,  0.4263],\n",
       "        [ 0.0120, -0.1297,  0.2431,  ...,  0.4713,  0.0100, -0.1059],\n",
       "        ...,\n",
       "        [ 0.2554,  0.3921, -0.3530,  ...,  0.4462,  0.2011,  0.5215],\n",
       "        [-0.0203, -0.0836, -0.0156,  ...,  0.0513,  0.0746,  0.0285],\n",
       "        [-0.0364, -0.0647,  0.0147,  ...,  0.0118,  0.0850, -0.0063]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(agent.model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1016, -0.0330,  0.0345,  ..., -0.0337,  0.1236,  0.0771],\n",
       "        [ 0.4183, -0.0701, -0.2043,  ...,  0.5718,  0.0684,  0.4263],\n",
       "        [ 0.0120, -0.1297,  0.2431,  ...,  0.4713,  0.0100, -0.1059],\n",
       "        ...,\n",
       "        [ 0.2554,  0.3921, -0.3530,  ...,  0.4462,  0.2011,  0.5215],\n",
       "        [-0.0203, -0.0836, -0.0156,  ...,  0.0513,  0.0746,  0.0285],\n",
       "        [-0.0364, -0.0647,  0.0147,  ...,  0.0118,  0.0850, -0.0063]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(agent.base_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0140,  0.0069, -0.0449,  0.0479, -0.0507,  0.0434, -0.0438,  0.0026,\n",
       "          0.0118,  0.0359,  0.0568, -0.0576,  0.0605,  0.0242, -0.0431,  0.0614,\n",
       "         -0.0378, -0.0133,  0.0037,  0.0421, -0.0426, -0.0187,  0.0436,  0.0538,\n",
       "          0.0446,  0.0256, -0.0123, -0.0343, -0.0336,  0.0550, -0.0334, -0.0427,\n",
       "          0.0075,  0.0466, -0.0471,  0.0495,  0.0090,  0.0018,  0.0119,  0.0143,\n",
       "          0.0589,  0.0125, -0.0606, -0.0584,  0.0426,  0.0563, -0.0590,  0.0511,\n",
       "         -0.0495,  0.0025,  0.0070,  0.0402, -0.0433,  0.0615, -0.0368, -0.0112,\n",
       "         -0.0046, -0.0002,  0.0043, -0.0556,  0.0393, -0.0159,  0.0137,  0.0244,\n",
       "         -0.0609, -0.0475,  0.0141, -0.0191, -0.0018,  0.0452, -0.0250,  0.0153,\n",
       "         -0.0199, -0.0003,  0.0340,  0.0619, -0.0260, -0.0436,  0.0372,  0.0199,\n",
       "          0.0144,  0.0066,  0.0513, -0.0189, -0.0090,  0.0267,  0.0505, -0.0304,\n",
       "          0.0537,  0.0531, -0.0265, -0.0515,  0.0482,  0.0437,  0.0426, -0.0016,\n",
       "         -0.0037,  0.0494, -0.0037,  0.0480,  0.0151, -0.0487, -0.0238, -0.0016,\n",
       "         -0.0131,  0.0346, -0.0585,  0.0207, -0.0074,  0.0353, -0.0125, -0.0426,\n",
       "         -0.0528,  0.0302,  0.0210, -0.0533,  0.0183, -0.0027,  0.0314,  0.0246,\n",
       "         -0.0493, -0.0168,  0.0217,  0.0525,  0.0146,  0.0096, -0.0182,  0.0260,\n",
       "          0.0068, -0.0338, -0.0212, -0.0207, -0.0520,  0.0053,  0.0117, -0.0210,\n",
       "         -0.0201,  0.0036,  0.0184,  0.0224, -0.0008,  0.0181,  0.0055,  0.0206,\n",
       "         -0.0278,  0.0471, -0.0121, -0.0562,  0.0589, -0.0382, -0.0050, -0.0293,\n",
       "          0.0152, -0.0556,  0.0095,  0.0435, -0.0297, -0.0086, -0.0114,  0.0234,\n",
       "         -0.0025, -0.0358,  0.0272, -0.0318,  0.0597,  0.0405,  0.0360,  0.0158,\n",
       "         -0.0460, -0.0249, -0.0412, -0.0356, -0.0452,  0.0455, -0.0276,  0.0602,\n",
       "          0.0016, -0.0485,  0.0100,  0.0445, -0.0497,  0.0034, -0.0523, -0.0197,\n",
       "         -0.0306, -0.0584,  0.0568, -0.0051,  0.0229, -0.0494,  0.0232, -0.0157,\n",
       "         -0.0407,  0.0611, -0.0597, -0.0238,  0.0602, -0.0227,  0.0443,  0.0600,\n",
       "          0.0506,  0.0343,  0.0155,  0.0596, -0.0051,  0.0239, -0.0603, -0.0599,\n",
       "          0.0387, -0.0204,  0.0344,  0.0399,  0.0602,  0.0216,  0.0233,  0.0217,\n",
       "          0.0202, -0.0018,  0.0616, -0.0017, -0.0114, -0.0296, -0.0459, -0.0580,\n",
       "         -0.0172, -0.0504,  0.0254,  0.0270,  0.0220,  0.0055,  0.0097, -0.0193,\n",
       "          0.0310,  0.0183, -0.0605, -0.0558, -0.0215,  0.0309, -0.0178,  0.0477,\n",
       "          0.0129,  0.0228,  0.0315, -0.0313,  0.0543, -0.0152,  0.0624,  0.0090,\n",
       "         -0.0436,  0.0520,  0.0617, -0.0264, -0.0150,  0.0137, -0.0495, -0.0252]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(agent.value_head.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, _ = agent.model.sample_no_grad(32, 80)\n",
    "smiles = agent.reconstruct(preds)\n",
    "smiles = [i for i in smiles if to_mol(i) is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_ds = agent.dataset.new(smiles)\n",
    "buffer_dl = buffer_ds.dataloader(16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(buffer_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = ModelOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_idx = vocab.stoi['pad']\n",
    "\n",
    "mask = ~(y==pad_idx)\n",
    "lengths = mask.sum(-1)\n",
    "sl = y.shape[-1]\n",
    "\n",
    "model_output['x'] = x\n",
    "model_output['y'] = y\n",
    "model_output['mask'] = mask\n",
    "model_output['lengths'] = lengths\n",
    "model_output['sl'] = sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = agent.get_model_outputs(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 69])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output['state_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output['sequences'] = agent.reconstruct(x)\n",
    "model_output['mols'] = to_mols(model_output['sequences'])\n",
    "model_output['source'] = ['model']*x.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 69])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = torch.tensor([qed(i) for i in model_output['mols']])\n",
    "rewards_scaled = rewards - rewards.mean()\n",
    "\n",
    "model_output['rewards'] = rewards\n",
    "model_output['rewards_scaled'] = rewards_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrl.policy_gradient import PolicyGradient, TRPO, PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pg = PolicyGradient(discount=False)\n",
    "# pg = PolicyGradient(discount=True)\n",
    "# pg = TRPO(0.98, 2)\n",
    "pg = PPO(0.98, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = pg(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output['pg_loss'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0931, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output['pg_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model_output['pg_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1026, -0.0340,  0.0355,  ..., -0.0347,  0.1226,  0.0761],\n",
       "        [ 0.4193, -0.0691, -0.2033,  ...,  0.5708,  0.0674,  0.4253],\n",
       "        [ 0.0130, -0.1287,  0.2441,  ...,  0.4723,  0.0090, -0.1069],\n",
       "        ...,\n",
       "        [ 0.2544,  0.3911, -0.3540,  ...,  0.4472,  0.2001,  0.5225],\n",
       "        [-0.0196, -0.0838, -0.0153,  ...,  0.0516,  0.0745,  0.0281],\n",
       "        [-0.0357, -0.0649,  0.0151,  ...,  0.0120,  0.0849, -0.0067]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(agent.model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1016, -0.0330,  0.0345,  ..., -0.0337,  0.1236,  0.0771],\n",
       "        [ 0.4183, -0.0701, -0.2043,  ...,  0.5718,  0.0684,  0.4263],\n",
       "        [ 0.0120, -0.1297,  0.2431,  ...,  0.4713,  0.0100, -0.1059],\n",
       "        ...,\n",
       "        [ 0.2554,  0.3921, -0.3530,  ...,  0.4462,  0.2011,  0.5215],\n",
       "        [-0.0203, -0.0836, -0.0156,  ...,  0.0513,  0.0746,  0.0285],\n",
       "        [-0.0364, -0.0647,  0.0147,  ...,  0.0118,  0.0850, -0.0063]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(agent.base_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0130,  0.0059, -0.0439,  0.0469, -0.0497,  0.0444, -0.0428,  0.0036,\n",
       "          0.0128,  0.0349,  0.0578, -0.0566,  0.0595,  0.0252, -0.0421,  0.0624,\n",
       "         -0.0368, -0.0123,  0.0047,  0.0431, -0.0416, -0.0197,  0.0426,  0.0528,\n",
       "          0.0456,  0.0246, -0.0133, -0.0333, -0.0346,  0.0540, -0.0324, -0.0417,\n",
       "          0.0085,  0.0476, -0.0481,  0.0485,  0.0100,  0.0008,  0.0109,  0.0133,\n",
       "          0.0599,  0.0115, -0.0616, -0.0574,  0.0416,  0.0553, -0.0580,  0.0521,\n",
       "         -0.0485,  0.0035,  0.0080,  0.0392, -0.0423,  0.0605, -0.0358, -0.0102,\n",
       "         -0.0036,  0.0008,  0.0053, -0.0566,  0.0383, -0.0169,  0.0147,  0.0234,\n",
       "         -0.0599, -0.0465,  0.0151, -0.0181, -0.0028,  0.0462, -0.0240,  0.0143,\n",
       "         -0.0189, -0.0013,  0.0330,  0.0629, -0.0250, -0.0446,  0.0362,  0.0209,\n",
       "          0.0134,  0.0076,  0.0523, -0.0179, -0.0080,  0.0277,  0.0495, -0.0314,\n",
       "          0.0547,  0.0521, -0.0255, -0.0525,  0.0492,  0.0427,  0.0436, -0.0026,\n",
       "         -0.0027,  0.0484, -0.0027,  0.0490,  0.0141, -0.0477, -0.0248, -0.0006,\n",
       "         -0.0141,  0.0356, -0.0575,  0.0197, -0.0084,  0.0343, -0.0135, -0.0416,\n",
       "         -0.0538,  0.0292,  0.0220, -0.0523,  0.0173, -0.0017,  0.0304,  0.0256,\n",
       "         -0.0503, -0.0158,  0.0227,  0.0515,  0.0156,  0.0086, -0.0192,  0.0270,\n",
       "          0.0078, -0.0328, -0.0202, -0.0217, -0.0530,  0.0043,  0.0127, -0.0200,\n",
       "         -0.0191,  0.0026,  0.0174,  0.0214, -0.0018,  0.0171,  0.0045,  0.0216,\n",
       "         -0.0288,  0.0461, -0.0131, -0.0572,  0.0599, -0.0372, -0.0040, -0.0303,\n",
       "          0.0162, -0.0546,  0.0085,  0.0445, -0.0307, -0.0076, -0.0124,  0.0224,\n",
       "         -0.0015, -0.0348,  0.0282, -0.0308,  0.0607,  0.0395,  0.0370,  0.0168,\n",
       "         -0.0450, -0.0239, -0.0402, -0.0366, -0.0462,  0.0445, -0.0266,  0.0592,\n",
       "          0.0006, -0.0495,  0.0110,  0.0455, -0.0507,  0.0044, -0.0533, -0.0207,\n",
       "         -0.0316, -0.0574,  0.0558, -0.0041,  0.0219, -0.0504,  0.0242, -0.0147,\n",
       "         -0.0397,  0.0601, -0.0587, -0.0248,  0.0592, -0.0217,  0.0453,  0.0610,\n",
       "          0.0496,  0.0333,  0.0145,  0.0586, -0.0041,  0.0229, -0.0593, -0.0589,\n",
       "          0.0377, -0.0214,  0.0334,  0.0389,  0.0592,  0.0226,  0.0223,  0.0207,\n",
       "          0.0192, -0.0028,  0.0606, -0.0007, -0.0104, -0.0286, -0.0449, -0.0570,\n",
       "         -0.0182, -0.0494,  0.0264,  0.0280,  0.0210,  0.0065,  0.0107, -0.0203,\n",
       "          0.0300,  0.0193, -0.0615, -0.0568, -0.0205,  0.0319, -0.0168,  0.0487,\n",
       "          0.0119,  0.0218,  0.0325, -0.0323,  0.0553, -0.0142,  0.0614,  0.0100,\n",
       "         -0.0426,  0.0510,  0.0607, -0.0274, -0.0160,  0.0147, -0.0485, -0.0242]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(agent.value_head.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sequences', 'mols', 'source', 'x', 'y', 'mask', 'lengths', 'sl', 'model_output', 'model_encoded', 'model_logprobs', 'model_gathered_logprobs', 'state_values', 'reference_output', 'reference_encoded', 'reference_logprobs', 'reference_gathered_logprobs', 'rewards', 'rewards_dict', 'rewards_scaled', 'trajectory_rewards', 'diff_loss', 'diff_loss_dict', 'pg_loss', 'pg_dict'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pg_discounted': tensor([[-0.1271, -0.1297, -0.1324,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0212, -0.0216, -0.0221,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0297,  0.0303,  0.0310,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0823,  0.0840,  0.0857,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0858,  0.0876,  0.0894,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0336, -0.0343, -0.0350,  ...,  0.0000,  0.0000,  0.0000]]),\n",
       " 'pg_advantage': tensor([[-1.9058, -2.2628, -2.3443,  ..., -0.1343, -0.1625, -0.1959],\n",
       "         [ 0.4370,  0.1088, -0.3839,  ..., -0.2189, -0.2605, -0.3029],\n",
       "         [ 1.4972,  1.1780,  0.8214,  ..., -0.0632, -0.0540, -0.0557],\n",
       "         ...,\n",
       "         [ 2.5539,  2.2412,  2.1674,  ..., -0.1722, -0.2109, -0.2519],\n",
       "         [ 2.6634,  2.3540,  2.0062,  ..., -0.2369, -0.2802, -0.3318],\n",
       "         [ 0.1938, -0.1355, -0.5012,  ...,  0.0108, -0.0298, -0.0798]]),\n",
       " 'ratios': tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]]),\n",
       " 'loss': tensor(-0.0764),\n",
       " 'v_loss': tensor(0.1974),\n",
       " 'entropy': tensor(2.7895)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output['pg_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 72, 256])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output['model_encoded'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueHead(nn.module):\n",
    "    def __init__(self, d_in, dropout=0.):\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.layer = nn.Linear(d_in, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer(self.drop(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpecialDict(dict):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def __setitem__(self, key, item):\n",
    "        super().__setitem__(key, item)\n",
    "        super().__setattr__(key, item)\n",
    "    \n",
    "    def __setattr__(self, key, item):\n",
    "        super().__setitem__(key, item)\n",
    "        super().__setattr__(key, item)\n",
    "        \n",
    "#     def __setitem__(self, key, item):\n",
    "#         super().__setitem__(key, item)\n",
    "#         self.__setattr__(key, item)\n",
    "    \n",
    "#     def __setattr_(self, key, item):\n",
    "#         super().__setattr__(key, item)\n",
    "#         self.__setitem__(key, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = SpecialDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['_5'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_5': 2}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d._5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['event'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_5': 2, 'event': 'test'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_5 2\n",
      "event test\n"
     ]
    }
   ],
   "source": [
    "for (k,v) in d.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.rest = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_5': 2, 'event': 'test', 'rest': 5}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env():\n",
    "    \n",
    "    def fit(self, bs, buffer_size,):\n",
    "        self.bs = bs\n",
    "        self.buffer_size = buffer_size\n",
    "        self.iterations\n",
    "        self.build_buffer() # automatically as before batch?\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before rewrite\n",
    "    get more rewards working\n",
    "        batch vs paarallel\n",
    "        logging in rewaard plus lookup \n",
    "            index grab\n",
    "    get contrastive working\n",
    "    compute rewards in bulk from buffer\n",
    "    diff loss on learned latents\n",
    "    break out samples\n",
    "    timers during fit loop\n",
    "    protein LM\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "current roadmap\n",
    "    get contrastive working\n",
    "    write better reward function module\n",
    "        logging\n",
    "        parallel processing\n",
    "    start basic protein LM\n",
    "    start big rewrite\n",
    "        everything from torch core on gets rewritten\n",
    "        scrap encoder/decoder class\n",
    "        make VAE its own thing (untangle conditional lstm lm)\n",
    "        think about handling inputs to vae vs conditional lstm\n",
    "        after layers, go straight to callbacks/environment\n",
    "            keep things lean\n",
    "        merge double agent thing we have going on\n",
    "        do reward functions\n",
    "        revisit mol/protein distinctions in template/block\n",
    "    now we do documentation/update site\n",
    "    combichem\n",
    "    selies\n",
    "    jtnnvae\n",
    "    start working on other docs\n",
    "        guides\n",
    "        examples\n",
    "    move to release v0\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "future modules\n",
    "    combichem\n",
    "    selfies support\n",
    "    pharmacophore\n",
    "    new models\n",
    "        jtnnvae\n",
    "        flow based\n",
    "    chemprop hooks\n",
    "    huggingface hooks\n",
    "        \n",
    "project quality\n",
    "    collab links\n",
    "    google search on site\n",
    "    more documentation\n",
    "\n",
    "Use cases/examples\n",
    "    basic drug design\n",
    "    iterative drug design with dataset building\n",
    "    drug design with docking proxy\n",
    "    proteins/antibodies\n",
    "    polymers\n",
    "    catalyst\n",
    "    materials\n",
    "    \n",
    "guides\n",
    "    generative screening primer\n",
    "    basics\n",
    "        stuff about how bad score functions can be\n",
    "    how to use callbacks\n",
    "    basic drug design\n",
    "    contrastive optimization\n",
    "    latent/prior optimization\n",
    "    training tips/tricks (callback stuff)\n",
    "    \n",
    "paapers to implement\n",
    "    fastai guy - conditional lstm, contrastive\n",
    "    moldqn - dqn sampler (rollout), agent is score function, dqn loss\n",
    "    synthesis constrained? really same as DQN with different rolllout\n",
    "    stoned selfies/genetic algorithm examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
